{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4560ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#dataset preprocessing with newband1 and 2\n",
    "\n",
    "\n",
    "\n",
    "!pip install rasterio\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "\n",
    "class ResUNetPreprocessor:\n",
    "    def __init__(self, base_path, output_path, img_size=256):\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Initialize normalization parameters (will be calculated from data)\n",
    "        self.norm_means = None\n",
    "        self.norm_stds = None\n",
    "        \n",
    "        self.create_output_dirs()\n",
    "        \n",
    "        # Define ResUNet dataset structure for Kaggle environment\n",
    "        self.image_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'S1Hand')\n",
    "        self.mask_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'LabelHand')\n",
    "        self.splits_dir = os.path.join('splits', 'flood_handlabeled')\n",
    "        \n",
    "        # Statistics dictionary to track dataset properties\n",
    "        self.stats = {\n",
    "            'train': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0},\n",
    "            'val': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0},\n",
    "            'test': {'count': 0, 'flood_pixels': 0, 'total_pixels': 0}\n",
    "        }\n",
    "\n",
    "    def create_output_dirs(self):\n",
    "        # In Kaggle, we can write to /kaggle/working\n",
    "        if os.path.exists(self.output_path):\n",
    "            shutil.rmtree(self.output_path)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'masks'), exist_ok=True)\n",
    "            \n",
    "        print(f\"Created output directories at {self.output_path}\")\n",
    "\n",
    "    def read_csv_file(self, csv_path):\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "            \n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader, None)  # Skip header\n",
    "            return [(row[0], row[1]) for row in reader]\n",
    "\n",
    "    def compute_bands(self, vh, vv):\n",
    "        \"\"\"\n",
    "        Compute the three bands according to the specified formulas:\n",
    "        Band 1: VV\n",
    "        Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        \"\"\"\n",
    "        eps = 1e-8\n",
    "        \n",
    "        # Band 1: VV\n",
    "        band1 = vv\n",
    "        \n",
    "        # Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        band2 = np.divide(vh - vv, vh + vv + eps)\n",
    "        \n",
    "        # Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        band3 = np.sqrt((vh**2 + vv**2) / 2)\n",
    "        \n",
    "        return band1, band2, band3\n",
    "\n",
    "    def process_image_for_stats(self, im_path):\n",
    "        \"\"\"Process image to collect statistics (first pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                return arr_x\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image for stats {im_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_normalization_params(self, train_csv_path):\n",
    "        \"\"\"Calculate mean and std from training data\"\"\"\n",
    "        print(\"Calculating normalization parameters from training data...\")\n",
    "        \n",
    "        file_pairs = self.read_csv_file(train_csv_path)\n",
    "        \n",
    "        # Collect all pixel values for each band\n",
    "        all_pixels = [[] for _ in range(3)]\n",
    "        \n",
    "        for im_fname, _ in tqdm(file_pairs, desc=\"Collecting statistics\"):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path):\n",
    "                continue\n",
    "                \n",
    "            arr_x = self.process_image_for_stats(im_path)\n",
    "            if arr_x is not None:\n",
    "                for i in range(3):\n",
    "                    # Flatten and append pixels\n",
    "                    all_pixels[i].append(arr_x[i].flatten())\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            if all_pixels[i]:\n",
    "                combined_pixels = np.concatenate(all_pixels[i])\n",
    "                means.append(np.mean(combined_pixels))\n",
    "                stds.append(np.std(combined_pixels))\n",
    "            else:\n",
    "                means.append(0.0)\n",
    "                stds.append(1.0)\n",
    "        \n",
    "        self.norm_means = np.array(means)\n",
    "        self.norm_stds = np.array(stds)\n",
    "        \n",
    "        print(f\"Calculated normalization parameters:\")\n",
    "        print(f\"Band 1 (VV): mean={self.norm_means[0]:.4f}, std={self.norm_stds[0]:.4f}\")\n",
    "        print(f\"Band 2 (NewBand1): mean={self.norm_means[1]:.4f}, std={self.norm_stds[1]:.4f}\")\n",
    "        print(f\"Band 3 (NewBand2): mean={self.norm_means[2]:.4f}, std={self.norm_stds[2]:.4f}\")\n",
    "        \n",
    "        # Save normalization parameters\n",
    "        norm_params_path = os.path.join(self.output_path, 'normalization_params.npy')\n",
    "        np.save(norm_params_path, {'means': self.norm_means, 'stds': self.norm_stds})\n",
    "        print(f\"Normalization parameters saved to: {norm_params_path}\")\n",
    "\n",
    "    def process_image(self, im_path):\n",
    "        \"\"\"Process image with normalization (second pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                # Normalize using calculated means and stds\n",
    "                if self.norm_means is not None and self.norm_stds is not None:\n",
    "                    arr_x = (arr_x - self.norm_means.reshape(3, 1, 1)) / self.norm_stds.reshape(3, 1, 1)\n",
    "                \n",
    "                # Convert to HWC format for saving as image\n",
    "                arr_x = np.transpose(arr_x, (1, 2, 0))\n",
    "                \n",
    "                # Scale to 0-1 range for visualization\n",
    "                eps = 1e-8\n",
    "                arr_x_viz = (arr_x - arr_x.min()) / (arr_x.max() - arr_x.min() + eps)\n",
    "                \n",
    "                return arr_x, arr_x_viz\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {im_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def process_mask(self, mask_path):\n",
    "        try:\n",
    "            with rasterio.open(mask_path) as src:\n",
    "                arr_y = src.read(1)\n",
    "            \n",
    "            # Clean mask values (-1 to 0, ensure binary)\n",
    "            arr_y[arr_y == -1] = 0\n",
    "            arr_y = (arr_y > 0).astype(np.uint8)\n",
    "            \n",
    "            # Resize to target dimensions\n",
    "            arr_y = resize(arr_y, (self.img_size, self.img_size), order=0, preserve_range=True).astype(np.uint8)\n",
    "            \n",
    "            return arr_y\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mask {mask_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def save_png(self, arr, save_path, mode='RGB'):\n",
    "        \"\"\"Save array as PNG image\"\"\"\n",
    "        # Scale to 0-255 range for 8-bit image\n",
    "        img = Image.fromarray((arr * 255).astype(np.uint8), mode=mode)\n",
    "        img.save(save_path)\n",
    "\n",
    "    def save_npy(self, arr, save_path):\n",
    "        \"\"\"Save raw array data as NPY file for preserving exact values\"\"\"\n",
    "        np.save(save_path, arr)\n",
    "\n",
    "    def update_stats(self, split, mask):\n",
    "        \"\"\"Update dataset statistics\"\"\"\n",
    "        self.stats[split]['count'] += 1\n",
    "        self.stats[split]['flood_pixels'] += mask.sum()\n",
    "        self.stats[split]['total_pixels'] += mask.size\n",
    "\n",
    "    def process_dataset(self, split_name, csv_path):\n",
    "        print(f\"Processing {split_name} dataset...\")\n",
    "        file_pairs = self.read_csv_file(csv_path)\n",
    "        output_dir = os.path.join(self.output_path, split_name)\n",
    "        \n",
    "        for idx, (im_fname, mask_fname) in enumerate(tqdm(file_pairs, desc=f\"Processing {split_name}\")):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            mask_path = os.path.join(self.base_path, self.mask_dir, mask_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path) or not os.path.exists(mask_path):\n",
    "                print(f\"Warning: Files not found - {im_path} or {mask_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Process image (get both normalized data and visualization)\n",
    "            arr_x, arr_x_viz = self.process_image(im_path)\n",
    "            if arr_x is not None:\n",
    "                # Save visualization as PNG\n",
    "                img_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(arr_x_viz, img_save_path, mode='RGB')\n",
    "                \n",
    "                # Optionally save raw normalized data for exact values\n",
    "                raw_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.npy')\n",
    "                self.save_npy(arr_x, raw_save_path)\n",
    "            \n",
    "            # Process mask\n",
    "            arr_y = self.process_mask(mask_path)\n",
    "            if arr_y is not None:\n",
    "                # Save mask as PNG\n",
    "                mask_save_path = os.path.join(output_dir, 'masks', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(arr_y, mask_save_path, mode='L')\n",
    "                \n",
    "                # Update statistics\n",
    "                self.update_stats(split_name, arr_y)\n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"Print dataset statistics\"\"\"\n",
    "        print(\"\\nDataset Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        for split, stat in self.stats.items():\n",
    "            if stat['count'] > 0:\n",
    "                flood_percentage = 100 * stat['flood_pixels'] / stat['total_pixels']\n",
    "                print(f\"{split.upper()} set: {stat['count']} samples, \"\n",
    "                      f\"Flood pixels: {flood_percentage:.2f}%\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights to handle imbalance\"\"\"\n",
    "        if self.stats['train']['total_pixels'] > 0:\n",
    "            pos_ratio = self.stats['train']['flood_pixels'] / self.stats['train']['total_pixels']\n",
    "            neg_ratio = 1 - pos_ratio\n",
    "            \n",
    "            # Class weights inversely proportional to class frequency\n",
    "            weight_non_flood = 1.0\n",
    "            weight_flood = neg_ratio / pos_ratio if pos_ratio > 0 else 1.0\n",
    "            \n",
    "            print(f\"\\nClass weights for handling imbalance:\")\n",
    "            print(f\"Weight for non-flood (0): {weight_non_flood:.4f}\")\n",
    "            print(f\"Weight for flood (1): {weight_flood:.4f}\")\n",
    "            \n",
    "            # Save weights for model training\n",
    "            return np.array([weight_non_flood, weight_flood])\n",
    "        return np.array([1.0, 1.0])\n",
    "\n",
    "# Kaggle environment setup\n",
    "print(\"Setting up ResUNet preprocessing for Kaggle environment...\")\n",
    "print(\"Input path:\", \"/kaggle/input/sen1floods11-essentials/v1.2\")\n",
    "print(\"Output path:\", \"/kaggle/working/preprocessed\")\n",
    "print(\"\\nBand Configuration:\")\n",
    "print(\"Band 1: VV\")\n",
    "print(\"Band 2: NewBand1 = (VH - VV) / (VH + VV)\")\n",
    "print(\"Band 3: NewBand2 = sqrt((VH² + VV²) / 2)\")\n",
    "\n",
    "# Kaggle paths\n",
    "base_path = \"/kaggle/input/sen1floods11-essentials/v1.2\"\n",
    "output_path = \"/kaggle/working/preprocessed\"\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ResUNetPreprocessor(base_path, output_path)\n",
    "\n",
    "# Step 1: Calculate normalization parameters from training data\n",
    "train_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_train_data.csv')\n",
    "preprocessor.calculate_normalization_params(train_csv_path)\n",
    "\n",
    "print(\"\\nStarting dataset preprocessing with calculated normalization parameters...\")\n",
    "\n",
    "# Step 2: Process all datasets using calculated normalization\n",
    "# Process train set\n",
    "preprocessor.process_dataset('train', train_csv_path)\n",
    "\n",
    "# Process validation set\n",
    "val_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_val_data.csv')\n",
    "preprocessor.process_dataset('val', val_csv_path)\n",
    "\n",
    "# Process test set\n",
    "test_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_test_data.csv')\n",
    "preprocessor.process_dataset('test', test_csv_path)\n",
    "\n",
    "# Print statistics and calculate class weights\n",
    "preprocessor.print_stats()\n",
    "weights = preprocessor.calculate_class_weights()\n",
    "\n",
    "# Save class weights for later use\n",
    "weights_path = os.path.join(output_path, 'class_weights.npy')\n",
    "np.save(weights_path, weights)\n",
    "print(f\"\\nClass weights saved to: {weights_path}\")\n",
    "\n",
    "print(f\"\\nPreprocessing complete! Processed data saved to: {output_path}\")\n",
    "print(\"\\nOutput structure:\")\n",
    "print(\"preprocessed/\")\n",
    "print(\"├── train/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "print(\"│   └── masks/ (PNG files)\")\n",
    "print(\"├── val/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "print(\"│   └── masks/ (PNG files)\")\n",
    "print(\"├── test/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "print(\"│   └── masks/ (PNG files)\")\n",
    "print(\"├── class_weights.npy\")\n",
    "print(\"└── normalization_params.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dc759",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train GAC-Unet\n",
    "!pip install torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GATConv, ChebConv\n",
    "from torch_geometric.data import Data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss implementation for segmentation\"\"\"\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class CenterOfMassLayer(nn.Module):\n",
    "    \"\"\"Center of Mass layer for spatial feature distribution\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(CenterOfMassLayer, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # Create coordinate grids\n",
    "        y_coords = torch.arange(height, dtype=torch.float32, device=x.device).view(1, 1, height, 1)\n",
    "        x_coords = torch.arange(width, dtype=torch.float32, device=x.device).view(1, 1, 1, width)\n",
    "        \n",
    "        # Calculate center of mass for each channel\n",
    "        total_mass = x.sum(dim=(2, 3), keepdim=True) + 1e-8\n",
    "        \n",
    "        # Center of mass coordinates\n",
    "        y_com = (x * y_coords).sum(dim=(2, 3), keepdim=True) / total_mass\n",
    "        x_com = (x * x_coords).sum(dim=(2, 3), keepdim=True) / total_mass\n",
    "        \n",
    "        # Normalize coordinates\n",
    "        y_com = y_com / height\n",
    "        x_com = x_com / width\n",
    "        \n",
    "        # Create centered features\n",
    "        y_grid = (y_coords / height) - y_com\n",
    "        x_grid = (x_coords / width) - x_com\n",
    "        \n",
    "        # Apply spatial attention based on distance from center of mass\n",
    "        distance = torch.sqrt(y_grid**2 + x_grid**2)\n",
    "        attention = torch.exp(-distance)\n",
    "        \n",
    "        return x * attention\n",
    "\n",
    "class GraphConvBlock(nn.Module):\n",
    "    \"\"\"Graph convolutional block with GAT and Chebyshev convolutions\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, k=3):\n",
    "        super(GraphConvBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        \n",
    "        # Reduce spatial dimensions for graph processing\n",
    "        self.spatial_reduce = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.spatial_restore = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        \n",
    "        # Graph attention and Chebyshev convolutions\n",
    "        self.gat_conv = GATConv(out_channels, out_channels, heads=4, concat=False, dropout=0.1)\n",
    "        self.cheb_conv = ChebConv(out_channels, out_channels, K=k)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm1d(out_channels)\n",
    "        self.norm2 = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_graph_from_feature_map(self, x, k_neighbors=8):\n",
    "        \"\"\"Convert feature map to graph representation\"\"\"\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # Reshape to nodes\n",
    "        x_nodes = x.view(batch_size, channels, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        num_nodes = height * width\n",
    "        \n",
    "        # Create coordinate grid for spatial connections\n",
    "        coords = torch.stack(torch.meshgrid(\n",
    "            torch.arange(height, device=x.device),\n",
    "            torch.arange(width, device=x.device),\n",
    "            indexing='ij'\n",
    "        ), dim=-1).float()\n",
    "        coords = coords.view(-1, 2)  # [H*W, 2]\n",
    "        \n",
    "        # Create edges based on spatial proximity (simplified version)\n",
    "        edge_indices = []\n",
    "        for i in range(num_nodes):\n",
    "            y, x_coord = coords[i]\n",
    "            \n",
    "            # Connect to spatial neighbors\n",
    "            neighbors = []\n",
    "            for dy in [-1, 0, 1]:\n",
    "                for dx in [-1, 0, 1]:\n",
    "                    if dy == 0 and dx == 0:\n",
    "                        continue\n",
    "                    ny, nx = y + dy, x_coord + dx\n",
    "                    if 0 <= ny < height and 0 <= nx < width:\n",
    "                        neighbor_idx = int(ny * width + nx)\n",
    "                        neighbors.append([i, neighbor_idx])\n",
    "            \n",
    "            edge_indices.extend(neighbors)\n",
    "        \n",
    "        if edge_indices:\n",
    "            edge_index = torch.tensor(edge_indices, device=x.device).t().contiguous()\n",
    "        else:\n",
    "            # Fallback: create self-loops\n",
    "            edge_index = torch.arange(num_nodes, device=x.device).unsqueeze(0).repeat(2, 1)\n",
    "        \n",
    "        return x_nodes, edge_index\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        \n",
    "        # Reduce channels for graph processing\n",
    "        x_reduced = self.spatial_reduce(x)\n",
    "        \n",
    "        # Process each item in batch separately\n",
    "        graph_outputs = []\n",
    "        for b in range(batch_size):\n",
    "            x_batch = x_reduced[b:b+1]\n",
    "            \n",
    "            # Convert to graph\n",
    "            x_nodes, edge_index = self.create_graph_from_feature_map(x_batch)\n",
    "            x_nodes = x_nodes.squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            # Apply graph attention\n",
    "            x_gat = self.gat_conv(x_nodes, edge_index)\n",
    "            x_gat = F.relu(self.norm1(x_gat))\n",
    "            x_gat = self.dropout(x_gat)\n",
    "            \n",
    "            # Apply Chebyshev convolution\n",
    "            x_cheb = self.cheb_conv(x_gat, edge_index)\n",
    "            x_cheb = F.relu(self.norm2(x_cheb))\n",
    "            \n",
    "            # Reshape back to spatial format\n",
    "            x_output = x_cheb.view(1, self.out_channels, height, width)\n",
    "            graph_outputs.append(x_output)\n",
    "        \n",
    "        # Concatenate batch results\n",
    "        graph_output = torch.cat(graph_outputs, dim=0)\n",
    "        \n",
    "        # Restore spatial dimensions\n",
    "        output = self.spatial_restore(graph_output)\n",
    "        \n",
    "        return output + x_reduced  # Residual connection\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block used in U-Net\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Handle dimension mismatch\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        \n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class GACUNET(nn.Module):\n",
    "    \"\"\"Graph Attention Convolutional U-NET\"\"\"\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=True):\n",
    "        super(GACUNET, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        \n",
    "        # Graph layers (between encoder and decoder)\n",
    "        self.graph_conv = GraphConvBlock(1024 // factor, 1024 // factor)\n",
    "        self.center_of_mass = CenterOfMassLayer(1024 // factor)\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Graph processing\n",
    "        x5 = self.graph_conv(x5)\n",
    "        x5 = self.center_of_mass(x5)\n",
    "        \n",
    "        # Decoder path with skip connections\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class FloodDataset(Dataset):\n",
    "    \"\"\"Dataset class for flood segmentation\"\"\"\n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.images_dir = os.path.join(data_dir, split, 'images')\n",
    "        self.masks_dir = os.path.join(data_dir, split, 'masks')\n",
    "        \n",
    "        # Get all .npy files (containing exact normalized values)\n",
    "        self.image_files = [f for f in os.listdir(self.images_dir) if f.endswith('.npy')]\n",
    "        self.image_files.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load normalized image data (NPY file for exact values)\n",
    "        img_file = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_file)\n",
    "        \n",
    "        # Load mask (PNG file)\n",
    "        mask_file = img_file.replace('.npy', '.png')\n",
    "        mask_path = os.path.join(self.masks_dir, mask_file)\n",
    "        \n",
    "        # Load image as numpy array and convert to tensor\n",
    "        image = np.load(img_path).astype(np.float32)  # Shape: (H, W, 3)\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # Convert to (3, H, W)\n",
    "        \n",
    "        # Load mask\n",
    "        mask = np.array(Image.open(mask_path).convert('L')).astype(np.float32)\n",
    "        mask = mask / 255.0  # Normalize to [0, 1]\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)  # Add channel dimension\n",
    "        \n",
    "        if self.transform:\n",
    "            # Apply same transform to both image and mask\n",
    "            seed = torch.randint(0, 2**32, (1,)).item()\n",
    "            torch.manual_seed(seed)\n",
    "            image = self.transform(image)\n",
    "            torch.manual_seed(seed)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    \"\"\"Calculate segmentation metrics\"\"\"\n",
    "    pred_binary = (torch.sigmoid(pred) > threshold).float()\n",
    "    target_binary = (target > threshold).float()\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    pred_np = pred_binary.cpu().numpy().flatten()\n",
    "    target_np = target_binary.cpu().numpy().flatten()\n",
    "    \n",
    "    # IoU (Jaccard Index)\n",
    "    iou = jaccard_score(target_np, pred_np, average='binary', zero_division=1)\n",
    "    \n",
    "    # Dice Score\n",
    "    intersection = (pred_binary * target_binary).sum().item()\n",
    "    dice = (2. * intersection) / (pred_binary.sum().item() + target_binary.sum().item() + 1e-8)\n",
    "    \n",
    "    return iou, dice\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=100, learning_rate=1e-4, device='cuda'):\n",
    "    \"\"\"Training function for GAC-UNET\"\"\"\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_bce = nn.BCEWithLogitsLoss()\n",
    "    criterion_dice = DiceLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)\n",
    "    \n",
    "    # Tensorboard logging\n",
    "    writer = SummaryWriter('runs/gac_unet_flood')\n",
    "    \n",
    "    best_val_dice = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        train_dice = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for batch_idx, (images, masks) in enumerate(progress_bar):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Combined loss (BCE + Dice)\n",
    "            loss_bce = criterion_bce(outputs, masks)\n",
    "            loss_dice = criterion_dice(outputs, masks)\n",
    "            loss = 0.3 * loss_bce + 0.7 * loss_dice  # Weight dice loss more heavily\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            iou, dice = calculate_metrics(outputs, masks)\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_iou += iou\n",
    "            train_dice += dice\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Dice': f'{dice:.4f}',\n",
    "                'IoU': f'{iou:.4f}'\n",
    "            })\n",
    "        \n",
    "        # Average training metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_iou = train_iou / len(train_loader)\n",
    "        avg_train_dice = train_dice / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        val_dice = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss_bce = criterion_bce(outputs, masks)\n",
    "                loss_dice = criterion_dice(outputs, masks)\n",
    "                loss = 0.3 * loss_bce + 0.7 * loss_dice\n",
    "                \n",
    "                # Calculate metrics\n",
    "                iou, dice = calculate_metrics(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_iou += iou\n",
    "                val_dice += dice\n",
    "        \n",
    "        # Average validation metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_iou = val_iou / len(val_loader)\n",
    "        avg_val_dice = val_dice / len(val_loader)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Log metrics\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Dice/Train', avg_train_dice, epoch)\n",
    "        writer.add_scalar('Dice/Validation', avg_val_dice, epoch)\n",
    "        writer.add_scalar('IoU/Train', avg_train_iou, epoch)\n",
    "        writer.add_scalar('IoU/Validation', avg_val_iou, epoch)\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_dice > best_val_dice:\n",
    "            best_val_dice = avg_val_dice\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_dice': best_val_dice,\n",
    "            }, 'best_gac_unet_model.pth')\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Dice: {avg_train_dice:.4f}, Train IoU: {avg_train_iou:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}, Val IoU: {avg_val_iou:.4f}')\n",
    "        print(f'  Best Val Dice: {best_val_dice:.4f}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "    \n",
    "    writer.close()\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def visualize_predictions(model, dataset, device, num_samples=4):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            # Get random sample\n",
    "            idx = np.random.randint(0, len(dataset))\n",
    "            image, mask = dataset[idx]\n",
    "            \n",
    "            # Add batch dimension\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = model(image_batch)\n",
    "            pred = torch.sigmoid(pred).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Convert tensors to numpy for visualization\n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            mask_np = mask.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Normalize image for display\n",
    "            image_display = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(image_display)\n",
    "            axes[i, 0].set_title('Input Image')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(mask_np, cmap='gray')\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(pred, cmap='gray')\n",
    "            axes[i, 2].set_title('Prediction')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Overlay\n",
    "            overlay = image_display.copy()\n",
    "            overlay[:, :, 0] = np.where(pred > 0.5, 1, overlay[:, :, 0])\n",
    "            axes[i, 3].imshow(overlay)\n",
    "            axes[i, 3].set_title('Overlay')\n",
    "            axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Main training script\n",
    "def main():\n",
    "    # Configuration\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-4\n",
    "    DATA_DIR = \"/kaggle/working/preprocessed\"  # Path to preprocessed data\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "    \n",
    "    # Data transforms for augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset = FloodDataset(DATA_DIR, split='train', transform=train_transform)\n",
    "    val_dataset = FloodDataset(DATA_DIR, split='val', transform=None)\n",
    "    test_dataset = FloodDataset(DATA_DIR, split='test', transform=None)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"Creating GAC-UNET model...\")\n",
    "    model = GACUNET(n_channels=3, n_classes=1, bilinear=True)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, train_loader, val_loader, \n",
    "        num_epochs=NUM_EPOCHS, \n",
    "        learning_rate=LEARNING_RATE, \n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    print(\"Loading best model for evaluation...\")\n",
    "    checkpoint = torch.load('best_gac_unet_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"Evaluating on test set...\")\n",
    "    model.eval()\n",
    "    test_iou = 0.0\n",
    "    test_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            iou, dice = calculate_metrics(outputs, masks)\n",
    "            test_iou += iou\n",
    "            test_dice += dice\n",
    "    \n",
    "    avg_test_iou = test_iou / len(test_loader)\n",
    "    avg_test_dice = test_dice / len(test_loader)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"  Test IoU: {avg_test_iou:.4f}\")\n",
    "    print(f\"  Test Dice: {avg_test_dice:.4f}\")\n",
    "    \n",
    "    # Visualize some predictions\n",
    "    print(\"Generating prediction visualizations...\")\n",
    "    visualize_predictions(model, test_dataset, DEVICE)\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(len(train_losses)), [avg_test_dice] * len(train_losses), \n",
    "             label=f'Test Dice: {avg_test_dice:.4f}', linestyle='--')\n",
    "    plt.title('Final Test Performance')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
