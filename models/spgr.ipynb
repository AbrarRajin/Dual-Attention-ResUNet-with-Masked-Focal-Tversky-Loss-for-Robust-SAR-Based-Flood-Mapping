{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cd9ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#dataset preprocessing with newband1 and newband2\n",
    "\n",
    "!pip install rasterio\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "\n",
    "class ResUNetPreprocessor:\n",
    "    def __init__(self, base_path, output_path, img_size=256):\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Initialize normalization parameters (will be calculated from data)\n",
    "        self.norm_means = None\n",
    "        self.norm_stds = None\n",
    "        \n",
    "        self.create_output_dirs()\n",
    "        \n",
    "        # Define ResUNet dataset structure for Kaggle environment\n",
    "        self.image_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'S1Hand')\n",
    "        self.mask_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'LabelHand')\n",
    "        self.splits_dir = os.path.join('splits', 'flood_handlabeled')\n",
    "        \n",
    "        # Statistics dictionary to track dataset properties (only valid pixels)\n",
    "        self.stats = {\n",
    "            'train': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0},\n",
    "            'val': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0},\n",
    "            'test': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0}\n",
    "        }\n",
    "\n",
    "    def create_output_dirs(self):\n",
    "        # In Kaggle, we can write to /kaggle/working\n",
    "        if os.path.exists(self.output_path):\n",
    "            shutil.rmtree(self.output_path)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'masks'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'validity_masks'), exist_ok=True)\n",
    "            \n",
    "        print(f\"Created output directories at {self.output_path}\")\n",
    "\n",
    "    def read_csv_file(self, csv_path):\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "            \n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader, None)  # Skip header\n",
    "            return [(row[0], row[1]) for row in reader]\n",
    "\n",
    "    def compute_bands(self, vh, vv):\n",
    "        \"\"\"\n",
    "        Compute the three bands according to the specified formulas:\n",
    "        Band 1: VV\n",
    "        Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        \"\"\"\n",
    "        eps = 1e-8\n",
    "        \n",
    "        # Band 1: VV\n",
    "        band1 = vv\n",
    "        \n",
    "        # Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        band2 = np.divide(vh - vv, vh + vv + eps)\n",
    "        \n",
    "        # Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        band3 = np.sqrt((vh**2 + vv**2) / 2)\n",
    "        \n",
    "        return band1, band2, band3\n",
    "\n",
    "    def process_image_for_stats(self, im_path):\n",
    "        \"\"\"Process image to collect statistics (first pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                return arr_x\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image for stats {im_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_normalization_params(self, train_csv_path):\n",
    "        \"\"\"Calculate mean and std from training data\"\"\"\n",
    "        print(\"Calculating normalization parameters from training data...\")\n",
    "        \n",
    "        file_pairs = self.read_csv_file(train_csv_path)\n",
    "        \n",
    "        # Collect all pixel values for each band\n",
    "        all_pixels = [[] for _ in range(3)]\n",
    "        \n",
    "        for im_fname, _ in tqdm(file_pairs, desc=\"Collecting statistics\"):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path):\n",
    "                continue\n",
    "                \n",
    "            arr_x = self.process_image_for_stats(im_path)\n",
    "            if arr_x is not None:\n",
    "                for i in range(3):\n",
    "                    # Flatten and append pixels\n",
    "                    all_pixels[i].append(arr_x[i].flatten())\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            if all_pixels[i]:\n",
    "                combined_pixels = np.concatenate(all_pixels[i])\n",
    "                means.append(np.mean(combined_pixels))\n",
    "                stds.append(np.std(combined_pixels))\n",
    "            else:\n",
    "                means.append(0.0)\n",
    "                stds.append(1.0)\n",
    "        \n",
    "        self.norm_means = np.array(means)\n",
    "        self.norm_stds = np.array(stds)\n",
    "        \n",
    "        print(f\"Calculated normalization parameters:\")\n",
    "        print(f\"Band 1 (VV): mean={self.norm_means[0]:.4f}, std={self.norm_stds[0]:.4f}\")\n",
    "        print(f\"Band 2 (NewBand1): mean={self.norm_means[1]:.4f}, std={self.norm_stds[1]:.4f}\")\n",
    "        print(f\"Band 3 (NewBand2): mean={self.norm_means[2]:.4f}, std={self.norm_stds[2]:.4f}\")\n",
    "        \n",
    "        # Save normalization parameters\n",
    "        norm_params_path = os.path.join(self.output_path, 'normalization_params.npy')\n",
    "        np.save(norm_params_path, {'means': self.norm_means, 'stds': self.norm_stds})\n",
    "        print(f\"Normalization parameters saved to: {norm_params_path}\")\n",
    "\n",
    "    def process_image(self, im_path):\n",
    "        \"\"\"Process image with normalization (second pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                # Normalize using calculated means and stds\n",
    "                if self.norm_means is not None and self.norm_stds is not None:\n",
    "                    arr_x = (arr_x - self.norm_means.reshape(3, 1, 1)) / self.norm_stds.reshape(3, 1, 1)\n",
    "                \n",
    "                # Convert to HWC format for saving as image\n",
    "                arr_x = np.transpose(arr_x, (1, 2, 0))\n",
    "                \n",
    "                # Scale to 0-1 range for visualization\n",
    "                eps = 1e-8\n",
    "                arr_x_viz = (arr_x - arr_x.min()) / (arr_x.max() - arr_x.min() + eps)\n",
    "                \n",
    "                return arr_x, arr_x_viz\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {im_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def process_mask(self, mask_path):\n",
    "        \"\"\"\n",
    "        Process mask preserving -1 values and creating validity mask\n",
    "        Returns: (ground_truth_mask, validity_mask)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with rasterio.open(mask_path) as src:\n",
    "                arr_y = src.read(1)\n",
    "            \n",
    "            # Resize to target dimensions using nearest neighbor to preserve labels\n",
    "            arr_y = resize(arr_y, (self.img_size, self.img_size), order=0, preserve_range=True)\n",
    "            \n",
    "            # Create validity mask: True for valid pixels (0 or 1), False for invalid (-1)\n",
    "            validity_mask = (arr_y != -1).astype(np.uint8)\n",
    "            \n",
    "            # Create ground truth mask: convert -1 to 0 for network compatibility,\n",
    "            # but we'll use the validity mask to ignore these during training\n",
    "            ground_truth_mask = arr_y.copy()\n",
    "            ground_truth_mask[arr_y == -1] = 0  # Temporary conversion for network\n",
    "            ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n",
    "            \n",
    "            return ground_truth_mask, validity_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mask {mask_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def save_png(self, arr, save_path, mode='RGB'):\n",
    "        \"\"\"Save array as PNG image\"\"\"\n",
    "        # Scale to 0-255 range for 8-bit image\n",
    "        img = Image.fromarray((arr * 255).astype(np.uint8), mode=mode)\n",
    "        img.save(save_path)\n",
    "\n",
    "    def save_npy(self, arr, save_path):\n",
    "        \"\"\"Save raw array data as NPY file for preserving exact values\"\"\"\n",
    "        np.save(save_path, arr)\n",
    "\n",
    "    def update_stats(self, split, ground_truth_mask, validity_mask):\n",
    "        \"\"\"Update dataset statistics - only count valid pixels\"\"\"\n",
    "        valid_pixels = validity_mask.astype(bool)\n",
    "        \n",
    "        self.stats[split]['count'] += 1\n",
    "        self.stats[split]['flood_pixels'] += ground_truth_mask[valid_pixels].sum()\n",
    "        self.stats[split]['total_valid_pixels'] += valid_pixels.sum()\n",
    "        self.stats[split]['invalid_pixels'] += (~valid_pixels).sum()\n",
    "\n",
    "    def process_dataset(self, split_name, csv_path):\n",
    "        print(f\"Processing {split_name} dataset...\")\n",
    "        file_pairs = self.read_csv_file(csv_path)\n",
    "        output_dir = os.path.join(self.output_path, split_name)\n",
    "        \n",
    "        for idx, (im_fname, mask_fname) in enumerate(tqdm(file_pairs, desc=f\"Processing {split_name}\")):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            mask_path = os.path.join(self.base_path, self.mask_dir, mask_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path) or not os.path.exists(mask_path):\n",
    "                print(f\"Warning: Files not found - {im_path} or {mask_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Process image (get both normalized data and visualization)\n",
    "            arr_x, arr_x_viz = self.process_image(im_path)\n",
    "            if arr_x is not None:\n",
    "                # Save visualization as PNG\n",
    "                img_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(arr_x_viz, img_save_path, mode='RGB')\n",
    "                \n",
    "                # Save raw normalized data for exact values\n",
    "                raw_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.npy')\n",
    "                self.save_npy(arr_x, raw_save_path)\n",
    "            \n",
    "            # Process mask - now returns both ground truth and validity masks\n",
    "            result = self.process_mask(mask_path)\n",
    "            if result is not None:\n",
    "                ground_truth_mask, validity_mask = result\n",
    "                \n",
    "                # Save ground truth mask as PNG\n",
    "                mask_save_path = os.path.join(output_dir, 'masks', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(ground_truth_mask, mask_save_path, mode='L')\n",
    "                \n",
    "                # Save validity mask as PNG\n",
    "                validity_save_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(validity_mask, validity_save_path, mode='L')\n",
    "                \n",
    "                # Also save as NPY for exact values\n",
    "                mask_npy_path = os.path.join(output_dir, 'masks', f'{split_name}_{idx:04d}.npy')\n",
    "                validity_npy_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{idx:04d}.npy')\n",
    "                self.save_npy(ground_truth_mask, mask_npy_path)\n",
    "                self.save_npy(validity_mask, validity_npy_path)\n",
    "                \n",
    "                # Update statistics\n",
    "                self.update_stats(split_name, ground_truth_mask, validity_mask)\n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"Print dataset statistics\"\"\"\n",
    "        print(\"\\nDataset Statistics (Only Valid Pixels):\")\n",
    "        print(\"=\" * 70)\n",
    "        for split, stat in self.stats.items():\n",
    "            if stat['count'] > 0:\n",
    "                flood_percentage = 100 * stat['flood_pixels'] / stat['total_valid_pixels'] if stat['total_valid_pixels'] > 0 else 0\n",
    "                invalid_percentage = 100 * stat['invalid_pixels'] / (stat['total_valid_pixels'] + stat['invalid_pixels'])\n",
    "                print(f\"{split.upper()} set: {stat['count']} samples\")\n",
    "                print(f\"  Valid pixels: {stat['total_valid_pixels']:,} ({100-invalid_percentage:.1f}%)\")\n",
    "                print(f\"  Invalid pixels: {stat['invalid_pixels']:,} ({invalid_percentage:.1f}%)\")\n",
    "                print(f\"  Flood pixels (of valid): {stat['flood_pixels']:,} ({flood_percentage:.2f}%)\")\n",
    "                print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights to handle imbalance (only for valid pixels)\"\"\"\n",
    "        if self.stats['train']['total_valid_pixels'] > 0:\n",
    "            pos_ratio = self.stats['train']['flood_pixels'] / self.stats['train']['total_valid_pixels']\n",
    "            neg_ratio = 1 - pos_ratio\n",
    "            \n",
    "            # Class weights inversely proportional to class frequency\n",
    "            weight_non_flood = 1.0\n",
    "            weight_flood = neg_ratio / pos_ratio if pos_ratio > 0 else 1.0\n",
    "            \n",
    "            print(f\"\\nClass weights for handling imbalance (valid pixels only):\")\n",
    "            print(f\"Weight for non-flood (0): {weight_non_flood:.4f}\")\n",
    "            print(f\"Weight for flood (1): {weight_flood:.4f}\")\n",
    "            \n",
    "            # Save weights for model training\n",
    "            return np.array([weight_non_flood, weight_flood])\n",
    "        return np.array([1.0, 1.0])\n",
    "\n",
    "# Kaggle environment setup\n",
    "print(\"Setting up ResUNet preprocessing for Kaggle environment...\")\n",
    "print(\"Input path:\", \"/kaggle/input/sen1floods11-essentials/v1.2\")\n",
    "print(\"Output path:\", \"/kaggle/working/preprocessed\")\n",
    "print(\"\\nBand Configuration:\")\n",
    "print(\"Band 1: VV\")\n",
    "print(\"Band 2: NewBand1 = (VH - VV) / (VH + VV)\")\n",
    "print(\"Band 3: NewBand2 = sqrt((VHÂ² + VVÂ²) / 2)\")\n",
    "print(\"\\nðŸ”§ GROUND TRUTH HANDLING:\")\n",
    "print(\"âœ… Preserving -1 (invalid) labels\")\n",
    "print(\"âœ… Creating validity masks to exclude invalid pixels from training\")\n",
    "print(\"âœ… Statistics calculated only on valid pixels (0 and 1)\")\n",
    "\n",
    "# Kaggle paths\n",
    "base_path = \"/kaggle/input/sen1floods11-essentials/v1.2\"\n",
    "output_path = \"/kaggle/working/preprocessed\"\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ResUNetPreprocessor(base_path, output_path)\n",
    "\n",
    "# Step 1: Calculate normalization parameters from training data\n",
    "train_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_train_data.csv')\n",
    "preprocessor.calculate_normalization_params(train_csv_path)\n",
    "\n",
    "print(\"\\nStarting dataset preprocessing with calculated normalization parameters...\")\n",
    "\n",
    "# Step 2: Process all datasets using calculated normalization\n",
    "# Process train set\n",
    "preprocessor.process_dataset('train', train_csv_path)\n",
    "\n",
    "# Process validation set\n",
    "val_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_val_data.csv')\n",
    "preprocessor.process_dataset('val', val_csv_path)\n",
    "\n",
    "# Process test set\n",
    "test_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_test_data.csv')\n",
    "preprocessor.process_dataset('test', test_csv_path)\n",
    "\n",
    "# Print statistics and calculate class weights\n",
    "preprocessor.print_stats()\n",
    "weights = preprocessor.calculate_class_weights()\n",
    "\n",
    "# Save class weights for later use\n",
    "weights_path = os.path.join(output_path, 'class_weights.npy')\n",
    "np.save(weights_path, weights)\n",
    "print(f\"\\nClass weights saved to: {weights_path}\")\n",
    "\n",
    "print(f\"\\nPreprocessing complete! Processed data saved to: {output_path}\")\n",
    "print(\"\\nOutput structure:\")\n",
    "print(\"preprocessed/\")\n",
    "print(\"â”œâ”€â”€ train/\")\n",
    "print(\"â”‚   â”œâ”€â”€ images/ (PNG and NPY files)\")\n",
    "print(\"â”‚   â”œâ”€â”€ masks/ (PNG and NPY files - ground truth)\")\n",
    "print(\"â”‚   â””â”€â”€ validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "print(\"â”œâ”€â”€ val/\")\n",
    "print(\"â”‚   â”œâ”€â”€ images/ (PNG and NPY files)\")\n",
    "print(\"â”‚   â”œâ”€â”€ masks/ (PNG and NPY files - ground truth)\")\n",
    "print(\"â”‚   â””â”€â”€ validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "print(\"â”œâ”€â”€ test/\")\n",
    "print(\"â”‚   â”œâ”€â”€ images/ (PNG and NPY files)\")\n",
    "print(\"â”‚   â”œâ”€â”€ masks/ (PNG and NPY files - ground truth)\")\n",
    "print(\"â”‚   â””â”€â”€ validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "print(\"â”œâ”€â”€ class_weights.npy\")\n",
    "print(\"â””â”€â”€ normalization_params.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7884552",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resunet+SPGR\n",
    "!pip install torch_geometric\n",
    "!pip install scikit-image\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import glob\n",
    "from tensorflow.keras import backend as K\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = \"/kaggle/working/preprocessed\"\n",
    "OUTPUT_PATH = \"/kaggle/working/flood_resunet_spgr\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# ==================== SPGR IMPLEMENTATION ====================\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    \"\"\"Graph Convolution Layer using Chebyshev polynomials\"\"\"\n",
    "    \n",
    "    def __init__(self, output_channels, chebyshev_order=3, **kwargs):\n",
    "        super(GraphConvLayer, self).__init__(**kwargs)\n",
    "        self.output_channels = output_channels\n",
    "        self.chebyshev_order = chebyshev_order\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Create learnable weights for each Chebyshev polynomial order\n",
    "        self.kernels = []\n",
    "        for k in range(self.chebyshev_order):\n",
    "            self.kernels.append(\n",
    "                self.add_weight(\n",
    "                    name=f'cheb_kernel_{k}',\n",
    "                    shape=(input_shape[-1], self.output_channels),\n",
    "                    initializer='glorot_uniform',\n",
    "                    trainable=True\n",
    "                )\n",
    "            )\n",
    "        super(GraphConvLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs, adjacency_matrix):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, num_nodes, input_channels)\n",
    "        adjacency_matrix: (num_nodes, num_nodes) - normalized adjacency\n",
    "        \"\"\"\n",
    "        # Compute Chebyshev polynomials of the normalized Laplacian\n",
    "        cheb_polynomials = self._compute_chebyshev_polynomials(adjacency_matrix)\n",
    "        \n",
    "        outputs = []\n",
    "        for k in range(self.chebyshev_order):\n",
    "            # Apply k-th order Chebyshev polynomial: T_k(L) * X\n",
    "            filtered = tf.matmul(cheb_polynomials[k], inputs)\n",
    "            \n",
    "            # Apply learnable transformation: (T_k(L) * X) * W_k\n",
    "            transformed = tf.matmul(filtered, self.kernels[k])\n",
    "            outputs.append(transformed)\n",
    "        \n",
    "        # Sum all polynomial orders\n",
    "        result = tf.add_n(outputs)\n",
    "        return result\n",
    "    \n",
    "    def _compute_chebyshev_polynomials(self, normalized_laplacian):\n",
    "        \"\"\"Compute Chebyshev polynomials T_0, T_1, ..., T_{K-1}\"\"\"\n",
    "        num_nodes = tf.shape(normalized_laplacian)[0]\n",
    "        \n",
    "        # T_0(L) = I\n",
    "        polynomials = [tf.eye(num_nodes, dtype=tf.float32)]\n",
    "        \n",
    "        if self.chebyshev_order > 1:\n",
    "            # T_1(L) = L\n",
    "            polynomials.append(normalized_laplacian)\n",
    "        \n",
    "        # T_k(L) = 2 * L * T_{k-1}(L) - T_{k-2}(L)\n",
    "        for k in range(2, self.chebyshev_order):\n",
    "            T_k = 2.0 * tf.matmul(normalized_laplacian, polynomials[k-1]) - polynomials[k-2]\n",
    "            polynomials.append(T_k)\n",
    "        \n",
    "        return polynomials\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return the config of the layer for serialization\"\"\"\n",
    "        config = super(GraphConvLayer, self).get_config()\n",
    "        config.update({\n",
    "            'output_channels': self.output_channels,\n",
    "            'chebyshev_order': self.chebyshev_order\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Create layer from config\"\"\"\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "class SPGR(layers.Layer):\n",
    "    \"\"\"\n",
    "    Spatial Pyramid Graph Reasoning Layer\n",
    "    \n",
    "    Implements a three-level pyramid (1/4, 1/8, 1/16 scales) with graph reasoning\n",
    "    at each level and progressive feature fusion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_channels, **kwargs):\n",
    "        super(SPGR, self).__init__(**kwargs)\n",
    "        self.output_channels = output_channels\n",
    "        self.scale_factors = [4, 8, 16]  # 1/4, 1/8, 1/16 scales\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Channel projection layers for each scale\n",
    "        self.projections = []\n",
    "        self.graph_convs = []\n",
    "        self.batch_norms = []\n",
    "        self.activations = []\n",
    "        \n",
    "        for i, scale in enumerate(self.scale_factors):\n",
    "            # Project input channels to output channels\n",
    "            projection_layer = layers.Conv2D(\n",
    "                self.output_channels,\n",
    "                kernel_size=1,\n",
    "                padding='same',\n",
    "                name=f'projection_scale_{scale}'\n",
    "            )\n",
    "            self.projections.append(projection_layer)\n",
    "            \n",
    "            # Graph convolution layer for this scale\n",
    "            graph_conv_layer = GraphConvLayer(\n",
    "                self.output_channels,\n",
    "                chebyshev_order=3,\n",
    "                name=f'graph_conv_scale_{scale}'\n",
    "            )\n",
    "            self.graph_convs.append(graph_conv_layer)\n",
    "            \n",
    "            # Batch normalization and activation\n",
    "            bn_layer = layers.BatchNormalization(name=f'bn_scale_{scale}')\n",
    "            self.batch_norms.append(bn_layer)\n",
    "            \n",
    "            relu_layer = layers.ReLU(name=f'relu_scale_{scale}')\n",
    "            self.activations.append(relu_layer)\n",
    "        \n",
    "        # Final projection to ensure output channels\n",
    "        self.final_projection = layers.Conv2D(\n",
    "            self.output_channels,\n",
    "            kernel_size=1,\n",
    "            padding='same',\n",
    "            name='final_projection'\n",
    "        )\n",
    "        \n",
    "        super(SPGR, self).build(input_shape)\n",
    "        \n",
    "        # Build all sublayers with realistic dummy inputs to ensure proper serialization\n",
    "        try:\n",
    "            # Get realistic dimensions for building\n",
    "            if input_shape[1] is not None and input_shape[2] is not None:\n",
    "                height, width = input_shape[1], input_shape[2]\n",
    "            else:\n",
    "                height, width = 32, 32  # Default fallback\n",
    "                \n",
    "            channels = input_shape[3] if input_shape[3] is not None else 512\n",
    "            batch_size = 1  # Use dummy batch size for building\n",
    "            \n",
    "            # Build projection and graph conv layers for each scale\n",
    "            for i, scale_factor in enumerate(self.scale_factors):\n",
    "                target_h = max(1, height // scale_factor)\n",
    "                target_w = max(1, width // scale_factor)\n",
    "                \n",
    "                # Build projection layer\n",
    "                dummy_input = tf.zeros((batch_size, target_h, target_w, channels))\n",
    "                projected = self.projections[i](dummy_input)\n",
    "                \n",
    "                # Build graph conv layer\n",
    "                dummy_adjacency = tf.eye(target_h * target_w, dtype=tf.float32)\n",
    "                dummy_graph_input = tf.zeros((batch_size, target_h * target_w, self.output_channels))\n",
    "                graph_output = self.graph_convs[i](dummy_graph_input, dummy_adjacency)\n",
    "                \n",
    "                # Build batch norm and activation layers\n",
    "                dummy_spatial = tf.zeros((batch_size, target_h, target_w, self.output_channels))\n",
    "                bn_output = self.batch_norms[i](dummy_spatial, training=False)\n",
    "                _ = self.activations[i](bn_output)\n",
    "            \n",
    "            # Build final projection layer\n",
    "            dummy_final_input = tf.zeros((batch_size, height, width, self.output_channels))\n",
    "            _ = self.final_projection(dummy_final_input)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If building fails, just continue - the layers will be built on first use\n",
    "            print(f\"Warning: Could not pre-build SPGR sublayers: {e}\")\n",
    "            pass\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"Compute the output shape of the layer\"\"\"\n",
    "        return (input_shape[0], input_shape[1], input_shape[2], self.output_channels)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: (B, H, W, C) feature map\n",
    "        returns: (B, H, W, output_channels) refined features\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        orig_height = tf.shape(inputs)[1]\n",
    "        orig_width = tf.shape(inputs)[2]\n",
    "        \n",
    "        scale_features = []\n",
    "        \n",
    "        # Process each scale level\n",
    "        for i, scale_factor in enumerate(self.scale_factors):\n",
    "            # Calculate target dimensions\n",
    "            target_h = orig_height // scale_factor\n",
    "            target_w = orig_width // scale_factor\n",
    "            \n",
    "            # Downsample to current scale\n",
    "            downsampled = tf.image.resize(\n",
    "                inputs,\n",
    "                [target_h, target_w],\n",
    "                method='bilinear'\n",
    "            )\n",
    "            \n",
    "            # Project to output channels\n",
    "            projected = self.projections[i](downsampled)\n",
    "            \n",
    "            # Create grid graph adjacency matrix for this scale\n",
    "            adjacency = self._create_grid_adjacency_tf(target_h, target_w)\n",
    "            \n",
    "            # Reshape for graph convolution: (B, H*W, C)\n",
    "            num_nodes = target_h * target_w\n",
    "            graph_input = tf.reshape(projected, [batch_size, num_nodes, self.output_channels])\n",
    "            \n",
    "            # Apply graph convolution\n",
    "            graph_output = self.graph_convs[i](graph_input, adjacency)\n",
    "            \n",
    "            # Reshape back to spatial format: (B, H, W, C)\n",
    "            spatial_output = tf.reshape(graph_output, [batch_size, target_h, target_w, self.output_channels])\n",
    "            \n",
    "            # Apply batch normalization and activation\n",
    "            spatial_output = self.batch_norms[i](spatial_output)\n",
    "            spatial_output = self.activations[i](spatial_output)\n",
    "            \n",
    "            scale_features.append(spatial_output)\n",
    "        \n",
    "        # Progressive feature fusion (coarse to fine)\n",
    "        # Start with the coarsest scale (1/16)\n",
    "        fused_features = scale_features[-1]  # 1/16 scale\n",
    "        \n",
    "        # Progressively add finer scales with skip connections\n",
    "        for i in range(len(scale_features) - 2, -1, -1):\n",
    "            # Upsample to match current scale\n",
    "            current_h = tf.shape(scale_features[i])[1]\n",
    "            current_w = tf.shape(scale_features[i])[2]\n",
    "            \n",
    "            upsampled = tf.image.resize(\n",
    "                fused_features,\n",
    "                [current_h, current_w],\n",
    "                method='bilinear'\n",
    "            )\n",
    "            \n",
    "            # Add skip connection (U-Net style)\n",
    "            fused_features = upsampled + scale_features[i]\n",
    "        \n",
    "        # Upsample to original resolution\n",
    "        final_features = tf.image.resize(\n",
    "            fused_features,\n",
    "            [orig_height, orig_width],\n",
    "            method='bilinear'\n",
    "        )\n",
    "        \n",
    "        # Final projection to ensure correct output channels\n",
    "        output = self.final_projection(final_features)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _create_grid_adjacency_tf(self, height, width):\n",
    "        \"\"\"Create normalized adjacency matrix for 2D grid graph using XLA-compatible dense ops\"\"\"\n",
    "        num_nodes = height * width\n",
    "        \n",
    "        # Create adjacency matrix using dense operations (XLA-compatible)\n",
    "        adjacency = tf.zeros([num_nodes, num_nodes], dtype=tf.float32)\n",
    "        \n",
    "        # Create coordinate mappings\n",
    "        indices = tf.range(num_nodes, dtype=tf.int32)\n",
    "        i_coords = indices // width  # row coordinates\n",
    "        j_coords = indices % width   # column coordinates\n",
    "        \n",
    "        # Stack coordinates for vectorized operations\n",
    "        coords = tf.stack([i_coords, j_coords], axis=1)  # [num_nodes, 2]\n",
    "        \n",
    "        # Create all pairwise differences\n",
    "        coord_diff = tf.expand_dims(coords, 1) - tf.expand_dims(coords, 0)  # [num_nodes, num_nodes, 2]\n",
    "        \n",
    "        # Calculate Manhattan distance between all pairs\n",
    "        manhattan_dist = tf.reduce_sum(tf.abs(coord_diff), axis=2)  # [num_nodes, num_nodes]\n",
    "        \n",
    "        # Create adjacency matrix: connect nodes with Manhattan distance = 1 (4-connectivity)\n",
    "        adjacency = tf.cast(tf.equal(manhattan_dist, 1), tf.float32)\n",
    "        \n",
    "        # Add self-loops (distance = 0)\n",
    "        self_loops = tf.cast(tf.equal(manhattan_dist, 0), tf.float32)\n",
    "        adjacency = adjacency + self_loops\n",
    "        \n",
    "        # Symmetric normalization: D^(-1/2) * A * D^(-1/2)\n",
    "        degree = tf.reduce_sum(adjacency, axis=1)\n",
    "        degree_inv_sqrt = tf.pow(degree + 1e-8, -0.5)  # Add epsilon for numerical stability\n",
    "        \n",
    "        # Apply normalization using broadcasting\n",
    "        degree_inv_sqrt_expanded = tf.expand_dims(degree_inv_sqrt, 1)  # [num_nodes, 1]\n",
    "        degree_inv_sqrt_transposed = tf.expand_dims(degree_inv_sqrt, 0)  # [1, num_nodes]\n",
    "        \n",
    "        normalized_adj = adjacency * degree_inv_sqrt_expanded * degree_inv_sqrt_transposed\n",
    "        \n",
    "        return normalized_adj\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"Return the config of the layer for serialization\"\"\"\n",
    "        config = super(SPGR, self).get_config()\n",
    "        config.update({\n",
    "            'output_channels': self.output_channels\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Create layer from config\"\"\"\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "# ==================== MODIFIED RESUNET WITH SPGR ====================\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size=3, strides=1, padding='same'):\n",
    "    \"\"\"Convolutional block with batch normalization and activation\"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def channel_attention(inputs, ratio=16):\n",
    "    \"\"\"Squeeze and Excitation Block for channel attention\"\"\"\n",
    "    channels = int(inputs.shape[-1])\n",
    "    reduced_channels = max(channels // ratio, 8)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.Reshape((1, 1, channels))(x)\n",
    "    x = layers.Conv2D(reduced_channels, kernel_size=1, activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    output = layers.Multiply()([inputs, x])\n",
    "    return output\n",
    "\n",
    "def spatial_attention(inputs):\n",
    "    \"\"\"Spatial attention module\"\"\"\n",
    "    avg_pool = layers.Conv2D(1, kernel_size=1, padding='same', use_bias=False, \n",
    "                            kernel_initializer='ones')(inputs)\n",
    "    max_features = layers.Conv2D(1, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_features])\n",
    "    attention_map = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "    output = layers.Multiply()([inputs, attention_map])\n",
    "    return output\n",
    "\n",
    "def attention_residual_block(inputs, filters, kernel_size=3, strides=1):\n",
    "    \"\"\"Residual block with channel and spatial attention\"\"\"\n",
    "    x = conv_block(inputs, filters, kernel_size, strides)\n",
    "    x = conv_block(x, filters, kernel_size, 1)\n",
    "    x = channel_attention(x)\n",
    "    x = spatial_attention(x)\n",
    "    \n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_spgr_attention_resunet(input_shape=(256, 256, 3), num_classes=1):\n",
    "    \"\"\"Build ResUNet model with SPGR and attention mechanisms\"\"\"\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    x = conv_block(inputs, 64, kernel_size=7, strides=1)\n",
    "\n",
    "    # Encoder blocks\n",
    "    skip1 = attention_residual_block(x, 64)\n",
    "    x = layers.MaxPooling2D(2)(skip1)\n",
    "\n",
    "    skip2 = attention_residual_block(x, 128)\n",
    "    x = layers.MaxPooling2D(2)(skip2)\n",
    "\n",
    "    skip3 = attention_residual_block(x, 256)\n",
    "    x = layers.MaxPooling2D(2)(skip3)\n",
    "\n",
    "    # Bridge with SPGR\n",
    "    bridge = attention_residual_block(x, 512)\n",
    "    \n",
    "    #  SPGR INTEGRATION: Apply SPGR between encoder and decoder\n",
    "    print(\" Adding SPGR (Spatial Pyramid Graph Reasoning) layer...\")\n",
    "    spgr_features = SPGR(output_channels=512, name='spgr_bridge')(bridge)\n",
    "    \n",
    "    # Combine original bridge features with SPGR features\n",
    "    enhanced_bridge = layers.Add(name='spgr_fusion')([bridge, spgr_features])\n",
    "    enhanced_bridge = layers.BatchNormalization()(enhanced_bridge)\n",
    "    enhanced_bridge = layers.ReLU()(enhanced_bridge)\n",
    "\n",
    "    # Decoder blocks (using enhanced bridge features)\n",
    "    x = layers.UpSampling2D(2)(enhanced_bridge)\n",
    "    x = conv_block(x, 256)\n",
    "    x = layers.Concatenate()([x, skip3])\n",
    "    x = attention_residual_block(x, 256)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = layers.Concatenate()([x, skip2])\n",
    "    x = attention_residual_block(x, 128)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = conv_block(x, 64)\n",
    "    x = layers.Concatenate()([x, skip1])\n",
    "    x = attention_residual_block(x, 64)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name='SPGR_ResUNet')\n",
    "    return model\n",
    "\n",
    "# ==================== DATA LOADING FUNCTIONS ====================\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load normalized image data from .npy file\"\"\"\n",
    "    if isinstance(image_path, tf.Tensor):\n",
    "        image_path = image_path.numpy().decode('utf-8')\n",
    "    return np.load(image_path).astype(np.float32)\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Load mask from NPY file (preserves exact values)\"\"\"\n",
    "    if isinstance(mask_path, tf.Tensor):\n",
    "        mask_path = mask_path.numpy().decode('utf-8')\n",
    "    mask = np.load(mask_path)\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "def load_validity_mask(validity_path):\n",
    "    \"\"\"Load validity mask from NPY file\"\"\"\n",
    "    if isinstance(validity_path, tf.Tensor):\n",
    "        validity_path = validity_path.numpy().decode('utf-8')\n",
    "    validity_mask = np.load(validity_path)\n",
    "    return validity_mask.astype(np.float32)\n",
    "\n",
    "def augment_data(image, mask, validity_mask):\n",
    "    \"\"\"Apply data augmentation to image, mask, and validity mask\"\"\"\n",
    "    # Random horizontal flip\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "        validity_mask = tf.image.flip_left_right(validity_mask)\n",
    "    \n",
    "    # Random vertical flip\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        mask = tf.image.flip_up_down(mask)\n",
    "        validity_mask = tf.image.flip_up_down(validity_mask)\n",
    "    \n",
    "    # Random rotation (90, 180, 270 degrees)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        k = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int32)\n",
    "        image = tf.image.rot90(image, k=k)\n",
    "        mask = tf.image.rot90(mask, k=k)\n",
    "        validity_mask = tf.image.rot90(validity_mask, k=k)\n",
    "    \n",
    "    # Random brightness adjustment (only for image)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    \n",
    "    # Random contrast adjustment (only for image)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    \n",
    "    return image, mask, validity_mask\n",
    "\n",
    "def create_dataset(base_path, split, batch_size=16, shuffle=True, augment=False):\n",
    "    \"\"\"Create a TensorFlow dataset for the specified split with validity masks\"\"\"\n",
    "    img_paths = sorted(glob.glob(os.path.join(base_path, split, 'images', '*.npy')))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(base_path, split, 'masks', '*.npy')))\n",
    "    validity_paths = sorted(glob.glob(os.path.join(base_path, split, 'validity_masks', '*.npy')))\n",
    "\n",
    "    if len(img_paths) == 0 or len(mask_paths) == 0 or len(validity_paths) == 0:\n",
    "        raise ValueError(f\"No images, masks, or validity masks found in {base_path}/{split}\")\n",
    "\n",
    "    print(f\"Found {len(img_paths)} images, {len(mask_paths)} masks, and {len(validity_paths)} validity masks for {split}\")\n",
    "\n",
    "    # Create datasets of paths\n",
    "    img_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
    "    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
    "    validity_dataset = tf.data.Dataset.from_tensor_slices(validity_paths)\n",
    "\n",
    "    # Combine all paths\n",
    "    dataset = tf.data.Dataset.zip((img_dataset, mask_dataset, validity_dataset))\n",
    "\n",
    "    # Shuffle if needed\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(img_paths), seed=42)\n",
    "\n",
    "    # Map loading function to the dataset\n",
    "    dataset = dataset.map(\n",
    "        lambda img_path, mask_path, validity_path: (\n",
    "            tf.py_function(\n",
    "                func=load_image,\n",
    "                inp=[img_path],\n",
    "                Tout=tf.float32\n",
    "            ),\n",
    "            tf.py_function(\n",
    "                func=load_mask,\n",
    "                inp=[mask_path],\n",
    "                Tout=tf.float32\n",
    "            ),\n",
    "            tf.py_function(\n",
    "                func=load_validity_mask,\n",
    "                inp=[validity_path],\n",
    "                Tout=tf.float32\n",
    "            )\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Set shapes\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y, v: (\n",
    "            tf.ensure_shape(x, [256, 256, 3]),\n",
    "            tf.ensure_shape(y, [256, 256]),\n",
    "            tf.ensure_shape(v, [256, 256])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add channel dimension to masks\n",
    "    dataset = dataset.map(lambda x, y, v: (x, tf.expand_dims(y, axis=-1), tf.expand_dims(v, axis=-1)))\n",
    "\n",
    "    # Apply data augmentation for training set\n",
    "    if augment and split == 'train':\n",
    "        print(f\"Applying data augmentation to {split} dataset\")\n",
    "        dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Important: Add repeat to prevent dataset exhaustion\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, len(img_paths)\n",
    "\n",
    "# ==================== MASKED LOSS AND METRICS ====================\n",
    "\n",
    "def masked_dice_coefficient(y_true, y_pred, validity_mask, smooth=1e-6):\n",
    "    \"\"\"Calculate Dice coefficient only for valid pixels\"\"\"\n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    # Only consider valid pixels\n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f)\n",
    "    \n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_dice_loss(y_true_and_validity, y_pred):\n",
    "    \"\"\"Masked Dice loss function that ignores invalid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    return 1 - masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "def masked_focal_tversky_loss(y_true_and_validity, y_pred, alpha=0.7, beta=0.3, gamma=1.5, smooth=1e-6):\n",
    "    \"\"\"Masked Focal Tversky Loss that ignores invalid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    # Flatten the inputs\n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    # Calculate true positives, false negatives, and false positives (only for valid pixels)\n",
    "    true_pos = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    false_neg = K.sum(y_true_f * (1 - y_pred_f) * validity_f)\n",
    "    false_pos = K.sum((1 - y_true_f) * y_pred_f * validity_f)\n",
    "    \n",
    "    # Calculate Tversky index\n",
    "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
    "    \n",
    "    # Apply focal parameter to focus on hard examples\n",
    "    focal_tversky = K.pow((1 - tversky), gamma)\n",
    "    \n",
    "    return focal_tversky\n",
    "\n",
    "def masked_iou_score(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate IoU score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f) - intersection\n",
    "    \n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_binary_accuracy(y_true_and_validity, y_pred):\n",
    "    \"\"\"Calculate binary accuracy only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    # Threshold predictions\n",
    "    y_pred_binary = K.cast(y_pred_masked > 0.5, K.floatx())\n",
    "    \n",
    "    # Calculate accuracy only for valid pixels\n",
    "    correct = K.cast(K.equal(y_true_masked, y_pred_binary), K.floatx()) * validity_mask\n",
    "    total_valid = K.sum(validity_mask)\n",
    "    \n",
    "    return K.sum(correct) / (total_valid + K.epsilon())\n",
    "\n",
    "def masked_f1_score_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate F1 score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    # Calculate precision and recall for valid pixels only\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    return f1\n",
    "\n",
    "def masked_precision_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate precision only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    return precision\n",
    "\n",
    "def masked_recall_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate recall only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "    return recall\n",
    "\n",
    "# Wrapper functions to use with compile (need specific names)\n",
    "def masked_dice_coefficient_metric(y_true_and_validity, y_pred):\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    return masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "# ==================== LEARNING RATE SCHEDULING ====================\n",
    "\n",
    "def cosine_annealing_warm_restarts(epoch, initial_lr=0.001, min_lr=1e-6, T_0=50, T_mult=2):\n",
    "    \"\"\"Cosine annealing with warm restarts function for LearningRateScheduler\"\"\"\n",
    "    T_cur = epoch\n",
    "    T_i = T_0\n",
    "    \n",
    "    while T_cur >= T_i:\n",
    "        T_cur -= T_i\n",
    "        T_i *= T_mult\n",
    "    \n",
    "    lr = min_lr + (initial_lr - min_lr) * (1 + math.cos(math.pi * T_cur / T_i)) / 2\n",
    "    return lr\n",
    "\n",
    "def prepare_labels_for_training(dataset):\n",
    "    \"\"\"Prepare dataset to combine ground truth and validity masks for masked loss\"\"\"\n",
    "    def combine_masks(image, gt_mask, validity_mask):\n",
    "        # Combine ground truth and validity masks into a single tensor\n",
    "        combined_mask = tf.concat([gt_mask, validity_mask], axis=-1)\n",
    "        return image, combined_mask\n",
    "    \n",
    "    return dataset.map(combine_masks)\n",
    "\n",
    "def load_spgr_model(weights_path, input_shape=(256, 256, 3)):\n",
    "    \"\"\"\n",
    "    Helper function to load SPGR model from weights\n",
    "    \n",
    "    Args:\n",
    "        weights_path: Path to the saved weights file (.weights.h5)\n",
    "        input_shape: Input shape for the model\n",
    "    \n",
    "    Returns:\n",
    "        Loaded SPGR model\n",
    "    \"\"\"\n",
    "    # Build the model architecture\n",
    "    model = build_spgr_attention_resunet(input_shape)\n",
    "    \n",
    "    # Compile with dummy optimizer (you can recompile later with proper settings)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Build the model by running a forward pass\n",
    "    dummy_input = tf.zeros((1, *input_shape))\n",
    "    _ = model(dummy_input)\n",
    "    \n",
    "    # Load the weights\n",
    "    model.load_weights(weights_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "\n",
    "# Configuration\n",
    "COSINE_ANNEALING_CONFIG = {\n",
    "    \"method\": \"warm_restarts_scheduler\",\n",
    "    \"initial_lr\": 0.0005,\n",
    "    \"min_lr\": 5e-7,\n",
    "    \"T_max\": 200,\n",
    "    \"T_0\": 50,\n",
    "    \"T_mult\": 2,\n",
    "}\n",
    "\n",
    "print(\" TRAINING SPGR-ENHANCED RESUNET WITH MASKED LOSS\")\n",
    "print(\"=\" * 60)\n",
    "print(\" Spatial Pyramid Graph Reasoning (SPGR) integrated at bridge\")\n",
    "print(\" Three-level pyramid: 1/4, 1/8, 1/16 scales\")\n",
    "print(\" Graph convolution with Chebyshev polynomials (order=3)\")\n",
    "print(\" Progressive feature fusion with skip connections\")\n",
    "print(\" Masked loss excluding invalid ground truth pixels\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use a batch size that fits in GPU memory\n",
    "BATCH_SIZE = 16  \n",
    "# Create datasets with validity masks\n",
    "print(\"Creating datasets with validity mask support...\")\n",
    "train_dataset, train_size = create_dataset(BASE_PATH, 'train', batch_size=BATCH_SIZE, augment=True)\n",
    "val_dataset, val_size = create_dataset(BASE_PATH, 'val', batch_size=BATCH_SIZE, augment=False)\n",
    "test_dataset, test_size = create_dataset(BASE_PATH, 'test', batch_size=BATCH_SIZE, augment=False)\n",
    "\n",
    "print(f\"Training dataset size: {train_size} images\")\n",
    "print(f\"Validation dataset size: {val_size} images\")\n",
    "print(f\"Test dataset size: {test_size} images\")\n",
    "\n",
    "# Build SPGR-enhanced model\n",
    "print(\"\\n Building SPGR-Enhanced ResUNet...\")\n",
    "input_shape = (256, 256, 3)\n",
    "model = build_spgr_attention_resunet(input_shape)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = max(1, train_size // BATCH_SIZE)\n",
    "validation_steps = max(1, val_size // BATCH_SIZE)\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "\n",
    "# Setup optimizer and learning rate scheduling\n",
    "initial_lr = COSINE_ANNEALING_CONFIG[\"initial_lr\"]\n",
    "optimizer = optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "lr_schedule_func = lambda epoch: cosine_annealing_warm_restarts(\n",
    "    epoch,\n",
    "    initial_lr=initial_lr,\n",
    "    min_lr=COSINE_ANNEALING_CONFIG[\"min_lr\"],\n",
    "    T_0=COSINE_ANNEALING_CONFIG[\"T_0\"],\n",
    "    T_mult=COSINE_ANNEALING_CONFIG[\"T_mult\"]\n",
    ")\n",
    "lr_callback = callbacks.LearningRateScheduler(lr_schedule_func, verbose=1)\n",
    "\n",
    "# Prepare datasets for training with combined masks\n",
    "print(\"Preparing datasets for masked training...\")\n",
    "train_dataset_prepared = prepare_labels_for_training(train_dataset)\n",
    "val_dataset_prepared = prepare_labels_for_training(val_dataset)\n",
    "test_dataset_prepared = prepare_labels_for_training(test_dataset)\n",
    "\n",
    "# Compile model with masked loss and metrics\n",
    "print(\"Compiling SPGR model with MASKED loss and metrics...\")\n",
    "\n",
    "# Disable XLA compilation to avoid sparse operation issues\n",
    "compile_kwargs = {\n",
    "    'optimizer': optimizer,\n",
    "    'loss': masked_focal_tversky_loss,\n",
    "    'metrics': [\n",
    "        masked_dice_coefficient_metric,\n",
    "        masked_iou_score,\n",
    "        masked_binary_accuracy,\n",
    "        masked_f1_score_metric,\n",
    "        masked_precision_metric,\n",
    "        masked_recall_metric\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Try to disable XLA compilation if available\n",
    "try:\n",
    "    # For newer TensorFlow versions\n",
    "    compile_kwargs['jit_compile'] = False\n",
    "    print(\" Disabled XLA/JIT compilation for sparse operations compatibility\")\n",
    "except:\n",
    "    print(\" Could not disable XLA compilation (older TF version)\")\n",
    "\n",
    "model.compile(**compile_kwargs)\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nSPGR-Enhanced ResUNet Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_path = os.path.join(OUTPUT_PATH, \"best_spgr_model_masked.keras\")\n",
    "weights_path = os.path.join(OUTPUT_PATH, \"best_spgr_weights_masked.weights.h5\")  # Fixed: correct extension\n",
    "log_dir = os.path.join(OUTPUT_PATH, \"logs_spgr_masked\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Custom callback to save both model and weights\n",
    "class ModelAndWeightsSaver(callbacks.Callback):\n",
    "    def __init__(self, model_path, weights_path, monitor='val_masked_iou_score', mode='max'):\n",
    "        super().__init__()\n",
    "        self.model_path = model_path\n",
    "        self.weights_path = weights_path\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best_value = -np.inf if mode == 'max' else np.inf\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        if current_value is None:\n",
    "            return\n",
    "            \n",
    "        if (self.mode == 'max' and current_value > self.best_value) or \\\n",
    "           (self.mode == 'min' and current_value < self.best_value):\n",
    "            self.best_value = current_value\n",
    "            \n",
    "            # Save both model and weights\n",
    "            try:\n",
    "                self.model.save(self.model_path)\n",
    "                self.model.save_weights(self.weights_path)\n",
    "                print(f\"\\n Saved best model and weights (epoch {epoch+1}, {self.monitor}: {current_value:.4f})\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n Warning: Could not save model: {e}\")\n",
    "                # At least save the weights\n",
    "                try:\n",
    "                    self.model.save_weights(self.weights_path)\n",
    "                    print(f\" Saved weights only (epoch {epoch+1})\")\n",
    "                except Exception as we:\n",
    "                    print(f\" Failed to save weights: {we}\")\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelAndWeightsSaver(checkpoint_path, weights_path),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_masked_iou_score',\n",
    "        patience=70,\n",
    "        restore_best_weights=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        profile_batch=0\n",
    "    ),\n",
    "    callbacks.CSVLogger(\n",
    "        os.path.join(OUTPUT_PATH, 'training_log_spgr_masked.csv'),\n",
    "        separator=',',\n",
    "        append=False\n",
    "    ),\n",
    "    lr_callback\n",
    "]\n",
    "\n",
    "print(f\"\\n Training SPGR-Enhanced ResUNet...\")\n",
    "print(f\"Initial LR: {initial_lr}, Min LR: {COSINE_ANNEALING_CONFIG['min_lr']}\")\n",
    "\n",
    "# Train model\n",
    "epochs = 20  # Reduced due to increased model complexity\n",
    "history = model.fit(\n",
    "    train_dataset_prepared,\n",
    "    validation_data=val_dataset_prepared,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "print(\"Saving trained model...\")\n",
    "try:\n",
    "    model.save(os.path.join(OUTPUT_PATH, 'spgr_resunet_model_masked.keras'))\n",
    "    print(\" Model saved successfully\")\n",
    "except Exception as e:\n",
    "    print(f\" Warning: Could not save full model: {e}\")\n",
    "\n",
    "# Save weights separately\n",
    "try:\n",
    "    model.save_weights(os.path.join(OUTPUT_PATH, 'spgr_training_weights.weights.h5'))  # Fixed: correct extension\n",
    "    print(\" Training weights saved successfully\")\n",
    "except Exception as e:\n",
    "    print(f\" Warning: Could not save training weights: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" SPGR-ENHANCED RESUNET TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\" Spatial Pyramid Graph Reasoning successfully integrated\")\n",
    "print(\" Multi-scale graph convolution with Chebyshev polynomials\")\n",
    "print(\"Progressive feature fusion across pyramid levels\")\n",
    "print(\" Masked training excluding invalid ground truth pixels\")\n",
    "print(f\" Model saved to: {OUTPUT_PATH}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load and evaluate best model\n",
    "print(\"Loading best SPGR model...\")\n",
    "try:\n",
    "    # Try to load the full model with custom objects\n",
    "    best_model = models.load_model(checkpoint_path, custom_objects={\n",
    "        'masked_dice_coefficient_metric': masked_dice_coefficient_metric,\n",
    "        'masked_focal_tversky_loss': masked_focal_tversky_loss,\n",
    "        'masked_iou_score': masked_iou_score,\n",
    "        'masked_binary_accuracy': masked_binary_accuracy,\n",
    "        'masked_f1_score_metric': masked_f1_score_metric,\n",
    "        'masked_precision_metric': masked_precision_metric,\n",
    "        'masked_recall_metric': masked_recall_metric,\n",
    "        'SPGR': SPGR,\n",
    "        'GraphConvLayer': GraphConvLayer\n",
    "    })\n",
    "    print(\" Successfully loaded model from checkpoint\")\n",
    "except Exception as e:\n",
    "    print(f\" Failed to load from checkpoint: {e}\")\n",
    "    print(\" Rebuilding model and loading weights...\")\n",
    "    \n",
    "    # Rebuild the model architecture\n",
    "    best_model = build_spgr_attention_resunet(input_shape)\n",
    "    best_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=masked_focal_tversky_loss,\n",
    "        metrics=[\n",
    "            masked_dice_coefficient_metric,\n",
    "            masked_iou_score,\n",
    "            masked_binary_accuracy,\n",
    "            masked_f1_score_metric,\n",
    "            masked_precision_metric,\n",
    "            masked_recall_metric\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Load weights from the saved model\n",
    "    try:\n",
    "        # First, we need to build the model by running a forward pass\n",
    "        dummy_input = tf.zeros((1, 256, 256, 3))\n",
    "        _ = best_model(dummy_input)\n",
    "        \n",
    "        # Now load the weights\n",
    "        best_model.load_weights(weights_path)  # Using the weights_path which has correct extension\n",
    "        print(\" Successfully loaded weights\")\n",
    "    except Exception as weight_error:\n",
    "        print(f\" Failed to load weights: {weight_error}\")\n",
    "        print(\"Using the last trained model instead...\")\n",
    "        best_model = model\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating SPGR model on test set...\")\n",
    "test_steps = max(1, test_size // BATCH_SIZE)\n",
    "test_results = best_model.evaluate(test_dataset_prepared, steps=test_steps)\n",
    "\n",
    "print(\"\\nSPGR Test Results (Invalid pixels excluded):\")\n",
    "for metric_name, value in zip(best_model.metrics_names, test_results):\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Save test results\n",
    "test_metrics = {metric_name: float(value) for metric_name, value in zip(best_model.metrics_names, test_results)}\n",
    "test_metrics['spgr_enhanced'] = True\n",
    "test_metrics['cosine_annealing_config'] = COSINE_ANNEALING_CONFIG\n",
    "test_metrics['masked_training'] = True\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'spgr_test_metrics_masked.json'), 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=4)\n",
    "\n",
    "# Also save model weights separately for easier loading\n",
    "print(\"Saving final model weights separately...\")\n",
    "try:\n",
    "    best_model.save_weights(os.path.join(OUTPUT_PATH, 'spgr_final_model_weights.weights.h5'))  # Fixed: correct extension\n",
    "    print(\" Final model weights saved separately\")\n",
    "except Exception as e:\n",
    "    print(f\" Warning: Could not save final model weights: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
