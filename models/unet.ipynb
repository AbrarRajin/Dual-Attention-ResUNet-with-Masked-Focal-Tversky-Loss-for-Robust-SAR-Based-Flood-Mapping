{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d73a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#dataset preprocessing with newband1 and 2\n",
    "\n",
    "!pip install rasterio\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "\n",
    "class ResUNetPreprocessor:\n",
    "    def __init__(self, base_path, output_path, img_size=512):  # Changed from 256 to 512\n",
    "        self.base_path = base_path\n",
    "        self.output_path = output_path\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Initialize normalization parameters (will be calculated from data)\n",
    "        self.norm_means = None\n",
    "        self.norm_stds = None\n",
    "        \n",
    "        self.create_output_dirs()\n",
    "        \n",
    "        # Define ResUNet dataset structure for Kaggle environment\n",
    "        self.image_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'S1Hand')\n",
    "        self.mask_dir = os.path.join('data', 'flood_events', 'HandLabeled', 'LabelHand')\n",
    "        self.splits_dir = os.path.join('splits', 'flood_handlabeled')\n",
    "        \n",
    "        # Statistics dictionary to track dataset properties (only valid pixels)\n",
    "        self.stats = {\n",
    "            'train': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0},\n",
    "            'val': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0},\n",
    "            'test': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0}\n",
    "        }\n",
    "\n",
    "    def create_output_dirs(self):\n",
    "        # In Kaggle, we can write to /kaggle/working\n",
    "        if os.path.exists(self.output_path):\n",
    "            shutil.rmtree(self.output_path)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'masks'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'validity_masks'), exist_ok=True)\n",
    "            \n",
    "        print(f\"Created output directories at {self.output_path}\")\n",
    "\n",
    "    def read_csv_file(self, csv_path):\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "            \n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader, None)  # Skip header\n",
    "            return [(row[0], row[1]) for row in reader]\n",
    "\n",
    "    def compute_bands(self, vh, vv):\n",
    "        \"\"\"\n",
    "        Compute the three bands according to the specified formulas:\n",
    "        Band 1: VV\n",
    "        Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        \"\"\"\n",
    "        eps = 1e-8\n",
    "        \n",
    "        # Band 1: VV\n",
    "        band1 = vv\n",
    "        \n",
    "        # Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        band2 = np.divide(vh - vv, vh + vv + eps)\n",
    "        \n",
    "        # Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        band3 = np.sqrt((vh**2 + vv**2) / 2)\n",
    "        \n",
    "        return band1, band2, band3\n",
    "\n",
    "    def process_image_for_stats(self, im_path):\n",
    "        \"\"\"Process image to collect statistics (first pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions - UPDATED to 512x512\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                return arr_x\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image for stats {im_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_normalization_params(self, train_csv_path):\n",
    "        \"\"\"Calculate mean and std from training data\"\"\"\n",
    "        print(\"Calculating normalization parameters from training data...\")\n",
    "        \n",
    "        file_pairs = self.read_csv_file(train_csv_path)\n",
    "        \n",
    "        # Collect all pixel values for each band\n",
    "        all_pixels = [[] for _ in range(3)]\n",
    "        \n",
    "        for im_fname, _ in tqdm(file_pairs, desc=\"Collecting statistics\"):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path):\n",
    "                continue\n",
    "                \n",
    "            arr_x = self.process_image_for_stats(im_path)\n",
    "            if arr_x is not None:\n",
    "                for i in range(3):\n",
    "                    # Flatten and append pixels\n",
    "                    all_pixels[i].append(arr_x[i].flatten())\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            if all_pixels[i]:\n",
    "                combined_pixels = np.concatenate(all_pixels[i])\n",
    "                means.append(np.mean(combined_pixels))\n",
    "                stds.append(np.std(combined_pixels))\n",
    "            else:\n",
    "                means.append(0.0)\n",
    "                stds.append(1.0)\n",
    "        \n",
    "        self.norm_means = np.array(means)\n",
    "        self.norm_stds = np.array(stds)\n",
    "        \n",
    "        print(f\"Calculated normalization parameters for {self.img_size}×{self.img_size} images:\")\n",
    "        print(f\"Band 1 (VV): mean={self.norm_means[0]:.4f}, std={self.norm_stds[0]:.4f}\")\n",
    "        print(f\"Band 2 (NewBand1): mean={self.norm_means[1]:.4f}, std={self.norm_stds[1]:.4f}\")\n",
    "        print(f\"Band 3 (NewBand2): mean={self.norm_means[2]:.4f}, std={self.norm_stds[2]:.4f}\")\n",
    "        \n",
    "        # Save normalization parameters\n",
    "        norm_params_path = os.path.join(self.output_path, 'normalization_params.npy')\n",
    "        np.save(norm_params_path, {'means': self.norm_means, 'stds': self.norm_stds})\n",
    "        print(f\"Normalization parameters saved to: {norm_params_path}\")\n",
    "\n",
    "    def process_image(self, im_path):\n",
    "        \"\"\"Process image with normalization (second pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values (common in SAR preprocessing)\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions - UPDATED to 512x512\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                # Normalize using calculated means and stds\n",
    "                if self.norm_means is not None and self.norm_stds is not None:\n",
    "                    arr_x = (arr_x - self.norm_means.reshape(3, 1, 1)) / self.norm_stds.reshape(3, 1, 1)\n",
    "                \n",
    "                # Convert to HWC format for saving as image\n",
    "                arr_x = np.transpose(arr_x, (1, 2, 0))\n",
    "                \n",
    "                # Scale to 0-1 range for visualization\n",
    "                eps = 1e-8\n",
    "                arr_x_viz = (arr_x - arr_x.min()) / (arr_x.max() - arr_x.min() + eps)\n",
    "                \n",
    "                return arr_x, arr_x_viz\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {im_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def process_mask(self, mask_path):\n",
    "        \"\"\"\n",
    "        Process mask preserving -1 values and creating validity mask\n",
    "        Returns: (ground_truth_mask, validity_mask)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with rasterio.open(mask_path) as src:\n",
    "                arr_y = src.read(1)\n",
    "            \n",
    "            # Resize to target dimensions using nearest neighbor to preserve labels - UPDATED to 512x512\n",
    "            arr_y = resize(arr_y, (self.img_size, self.img_size), order=0, preserve_range=True)\n",
    "            \n",
    "            # Create validity mask: True for valid pixels (0 or 1), False for invalid (-1)\n",
    "            validity_mask = (arr_y != -1).astype(np.uint8)\n",
    "            \n",
    "            # Create ground truth mask: convert -1 to 0 for network compatibility,\n",
    "            # but we'll use the validity mask to ignore these during training\n",
    "            ground_truth_mask = arr_y.copy()\n",
    "            ground_truth_mask[arr_y == -1] = 0  # Temporary conversion for network\n",
    "            ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n",
    "            \n",
    "            return ground_truth_mask, validity_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing mask {mask_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def save_png(self, arr, save_path, mode='RGB'):\n",
    "        \"\"\"Save array as PNG image\"\"\"\n",
    "        # Scale to 0-255 range for 8-bit image\n",
    "        img = Image.fromarray((arr * 255).astype(np.uint8), mode=mode)\n",
    "        img.save(save_path)\n",
    "\n",
    "    def save_npy(self, arr, save_path):\n",
    "        \"\"\"Save raw array data as NPY file for preserving exact values\"\"\"\n",
    "        np.save(save_path, arr)\n",
    "\n",
    "    def update_stats(self, split, ground_truth_mask, validity_mask):\n",
    "        \"\"\"Update dataset statistics - only count valid pixels\"\"\"\n",
    "        valid_pixels = validity_mask.astype(bool)\n",
    "        \n",
    "        self.stats[split]['count'] += 1\n",
    "        self.stats[split]['flood_pixels'] += ground_truth_mask[valid_pixels].sum()\n",
    "        self.stats[split]['total_valid_pixels'] += valid_pixels.sum()\n",
    "        self.stats[split]['invalid_pixels'] += (~valid_pixels).sum()\n",
    "\n",
    "    def process_dataset(self, split_name, csv_path):\n",
    "        print(f\"Processing {split_name} dataset with {self.img_size}×{self.img_size} resolution...\")\n",
    "        file_pairs = self.read_csv_file(csv_path)\n",
    "        output_dir = os.path.join(self.output_path, split_name)\n",
    "        \n",
    "        for idx, (im_fname, mask_fname) in enumerate(tqdm(file_pairs, desc=f\"Processing {split_name}\")):\n",
    "            im_path = os.path.join(self.base_path, self.image_dir, im_fname)\n",
    "            mask_path = os.path.join(self.base_path, self.mask_dir, mask_fname)\n",
    "            \n",
    "            if not os.path.exists(im_path) or not os.path.exists(mask_path):\n",
    "                print(f\"Warning: Files not found - {im_path} or {mask_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Process image (get both normalized data and visualization)\n",
    "            arr_x, arr_x_viz = self.process_image(im_path)\n",
    "            if arr_x is not None:\n",
    "                # Save visualization as PNG\n",
    "                img_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(arr_x_viz, img_save_path, mode='RGB')\n",
    "                \n",
    "                # Save raw normalized data for exact values\n",
    "                raw_save_path = os.path.join(output_dir, 'images', f'{split_name}_{idx:04d}.npy')\n",
    "                self.save_npy(arr_x, raw_save_path)\n",
    "            \n",
    "            # Process mask - now returns both ground truth and validity masks\n",
    "            result = self.process_mask(mask_path)\n",
    "            if result is not None:\n",
    "                ground_truth_mask, validity_mask = result\n",
    "                \n",
    "                # Save ground truth mask as PNG\n",
    "                mask_save_path = os.path.join(output_dir, 'masks', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(ground_truth_mask, mask_save_path, mode='L')\n",
    "                \n",
    "                # Save validity mask as PNG\n",
    "                validity_save_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{idx:04d}.png')\n",
    "                self.save_png(validity_mask, validity_save_path, mode='L')\n",
    "                \n",
    "                # Also save as NPY for exact values\n",
    "                mask_npy_path = os.path.join(output_dir, 'masks', f'{split_name}_{idx:04d}.npy')\n",
    "                validity_npy_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{idx:04d}.npy')\n",
    "                self.save_npy(ground_truth_mask, mask_npy_path)\n",
    "                self.save_npy(validity_mask, validity_npy_path)\n",
    "                \n",
    "                # Update statistics\n",
    "                self.update_stats(split_name, ground_truth_mask, validity_mask)\n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"Print dataset statistics\"\"\"\n",
    "        print(f\"\\nDataset Statistics for {self.img_size}×{self.img_size} images (Only Valid Pixels):\")\n",
    "        print(\"=\" * 70)\n",
    "        for split, stat in self.stats.items():\n",
    "            if stat['count'] > 0:\n",
    "                flood_percentage = 100 * stat['flood_pixels'] / stat['total_valid_pixels'] if stat['total_valid_pixels'] > 0 else 0\n",
    "                invalid_percentage = 100 * stat['invalid_pixels'] / (stat['total_valid_pixels'] + stat['invalid_pixels'])\n",
    "                print(f\"{split.upper()} set: {stat['count']} samples\")\n",
    "                print(f\"  Valid pixels: {stat['total_valid_pixels']:,} ({100-invalid_percentage:.1f}%)\")\n",
    "                print(f\"  Invalid pixels: {stat['invalid_pixels']:,} ({invalid_percentage:.1f}%)\")\n",
    "                print(f\"  Flood pixels (of valid): {stat['flood_pixels']:,} ({flood_percentage:.2f}%)\")\n",
    "                print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights to handle imbalance (only for valid pixels)\"\"\"\n",
    "        if self.stats['train']['total_valid_pixels'] > 0:\n",
    "            pos_ratio = self.stats['train']['flood_pixels'] / self.stats['train']['total_valid_pixels']\n",
    "            neg_ratio = 1 - pos_ratio\n",
    "            \n",
    "            # Class weights inversely proportional to class frequency\n",
    "            weight_non_flood = 1.0\n",
    "            weight_flood = neg_ratio / pos_ratio if pos_ratio > 0 else 1.0\n",
    "            \n",
    "            print(f\"\\nClass weights for handling imbalance (valid pixels only, {self.img_size}×{self.img_size}):\")\n",
    "            print(f\"Weight for non-flood (0): {weight_non_flood:.4f}\")\n",
    "            print(f\"Weight for flood (1): {weight_flood:.4f}\")\n",
    "            \n",
    "            # Save weights for model training\n",
    "            return np.array([weight_non_flood, weight_flood])\n",
    "        return np.array([1.0, 1.0])\n",
    "\n",
    "# Kaggle environment setup\n",
    "print(\"Input path:\", \"/kaggle/input/sen1floods11-essentials/v1.2\")\n",
    "print(\"Output path:\", \"/kaggle/working/preprocessed_512\")\n",
    "print(\"\\nBand Configuration:\")\n",
    "print(\"Band 1: VV\")\n",
    "print(\"Band 2: NewBand1 = (VH - VV) / (VH + VV)\")\n",
    "print(\"Band 3: NewBand2 = sqrt((VH² + VV²) / 2)\")\n",
    "\n",
    "\n",
    "# Kaggle paths\n",
    "base_path = \"/kaggle/input/sen1floods11-essentials/v1.2\"\n",
    "output_path = \"/kaggle/working/preprocessed_512\"  # Updated output path\n",
    "\n",
    "# Initialize preprocessor with 512×512 resolution\n",
    "preprocessor = ResUNetPreprocessor(base_path, output_path, img_size=512)\n",
    "\n",
    "# Step 1: Calculate normalization parameters from training data\n",
    "train_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_train_data.csv')\n",
    "preprocessor.calculate_normalization_params(train_csv_path)\n",
    "\n",
    "print(f\"\\nStarting dataset preprocessing with 512×512 resolution and calculated normalization parameters...\")\n",
    "\n",
    "# Step 2: Process all datasets using calculated normalization\n",
    "# Process train set\n",
    "preprocessor.process_dataset('train', train_csv_path)\n",
    "\n",
    "# Process validation set\n",
    "val_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_val_data.csv')\n",
    "preprocessor.process_dataset('val', val_csv_path)\n",
    "\n",
    "# Process test set\n",
    "test_csv_path = os.path.join(base_path, 'splits', 'flood_handlabeled', 'flood_test_data.csv')\n",
    "preprocessor.process_dataset('test', test_csv_path)\n",
    "\n",
    "# Print statistics and calculate class weights\n",
    "preprocessor.print_stats()\n",
    "weights = preprocessor.calculate_class_weights()\n",
    "\n",
    "# Save class weights for later use\n",
    "weights_path = os.path.join(output_path, 'class_weights.npy')\n",
    "np.save(weights_path, weights)\n",
    "print(f\"\\nClass weights saved to: {weights_path}\")\n",
    "\n",
    "print(f\"\\nPreprocessing complete! 512×512 processed data saved to: {output_path}\")\n",
    "print(\"\\nOutput structure:\")\n",
    "print(\"preprocessed_512/\")\n",
    "print(\"├── train/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files - 512×512)\")\n",
    "print(\"│   ├── masks/ (PNG and NPY files - ground truth - 512×512)\")\n",
    "print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators - 512×512)\")\n",
    "print(\"├── val/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files - 512×512)\")\n",
    "print(\"│   ├── masks/ (PNG and NPY files - ground truth - 512×512)\")\n",
    "print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators - 512×512)\")\n",
    "print(\"├── test/\")\n",
    "print(\"│   ├── images/ (PNG and NPY files - 512×512)\")\n",
    "print(\"│   ├── masks/ (PNG and NPY files - ground truth - 512×512)\")\n",
    "print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators - 512×512)\")\n",
    "print(\"├── class_weights.npy\")\n",
    "print(\"└── normalization_params.npy\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n MEMORY USAGE NOTE:\")\n",
    "print(f\"512×512 images use 4x more memory than 256×256\")\n",
    "print(f\"You may need to reduce batch size during training\")\n",
    "print(f\"Recommended batch size: 16-24 instead of 32 depending on GPU memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7061f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# UNet for 512x512 - Standard Architecture\n",
    "# Optimized for Tesla P100 16GB GPU\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from tensorflow.keras import mixed_precision\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "# Enable mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Configuration\n",
    "INPUT_SIZE = 512\n",
    "INPUT_CHANNELS = 2\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"/kaggle/working/preprocessed_512\"\n",
    "OUTPUT_PATH = \"/kaggle/working/unet_standard\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def check_gpu_memory():\n",
    "    try:\n",
    "        gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "        if gpu_devices:\n",
    "            print(f\"GPU detected: {len(gpu_devices)} device(s)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No GPU detected\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Could not check GPU: {e}\")\n",
    "        return False\n",
    "\n",
    "gpu_available = check_gpu_memory()\n",
    "\n",
    "def load_data_batch_by_batch(base_path, split, max_samples=None):\n",
    "    print(f\"Loading {split} data from {base_path}/{split}\")\n",
    "    \n",
    "    img_files = sorted(glob.glob(os.path.join(base_path, split, 'images', '*.npy')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(base_path, split, 'masks', '*.npy')))\n",
    "    \n",
    "    if len(img_files) == 0:\n",
    "        raise ValueError(f\"No data found in {base_path}/{split}\")\n",
    "    \n",
    "    if max_samples:\n",
    "        img_files = img_files[:max_samples]\n",
    "        mask_files = mask_files[:max_samples]\n",
    "    \n",
    "    print(f\"Processing {len(img_files)} files for {split}\")\n",
    "    \n",
    "    batch_size = 20\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    \n",
    "    for i in range(0, len(img_files), batch_size):\n",
    "        batch_img_files = img_files[i:i+batch_size]\n",
    "        batch_mask_files = mask_files[i:i+batch_size]\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "        \n",
    "        for img_file, mask_file in zip(batch_img_files, batch_mask_files):\n",
    "            img = np.load(img_file).astype(np.float16)\n",
    "            img = img[:, :, :INPUT_CHANNELS]\n",
    "            \n",
    "            mask = np.load(mask_file).astype(np.float16)\n",
    "            \n",
    "            batch_images.append(img)\n",
    "            batch_masks.append(mask)\n",
    "        \n",
    "        all_images.extend(batch_images)\n",
    "        all_masks.extend(batch_masks)\n",
    "        \n",
    "        del batch_images, batch_masks\n",
    "        gc.collect()\n",
    "    \n",
    "    images = np.array(all_images, dtype=np.float16)\n",
    "    masks = np.array(all_masks, dtype=np.float16)\n",
    "    \n",
    "    print(f\"{split} shape: images {images.shape}, masks {masks.shape}\")\n",
    "    return images, masks\n",
    "\n",
    "class MemoryEfficientGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, masks, batch_size=2, shuffle=True, augment=False):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(self.images))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.images))\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "        \n",
    "        batch_images = self.images[batch_indices].astype(np.float32)\n",
    "        batch_masks = self.masks[batch_indices].astype(np.float32)\n",
    "        \n",
    "        if self.augment:\n",
    "            batch_images, batch_masks = self.augment_batch(batch_images, batch_masks)\n",
    "        \n",
    "        batch_masks = np.expand_dims(batch_masks, axis=-1)\n",
    "        \n",
    "        return batch_images, batch_masks\n",
    "    \n",
    "    def augment_batch(self, images, masks):\n",
    "        augmented_images = []\n",
    "        augmented_masks = []\n",
    "        \n",
    "        for img, mask in zip(images, masks):\n",
    "            if np.random.random() > 0.5:\n",
    "                img = np.fliplr(img)\n",
    "                mask = np.fliplr(mask)\n",
    "            \n",
    "            if np.random.random() > 0.5:\n",
    "                img = np.flipud(img)\n",
    "                mask = np.flipud(mask)\n",
    "            \n",
    "            augmented_images.append(img)\n",
    "            augmented_masks.append(mask)\n",
    "        \n",
    "        return np.array(augmented_images), np.array(augmented_masks)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def build_unet(input_shape=(512, 512, 2)):\n",
    "    \"\"\"Standard U-Net architecture\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape, dtype='float32')\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same', dtype='float32')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same', dtype='float32')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same', dtype='float32')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same', dtype='float32')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same', dtype='float32')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same', dtype='float32')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same', dtype='float32')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same', dtype='float32')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bottom\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', dtype='float32')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same', dtype='float32')(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same', dtype='float32')(conv5)\n",
    "    up6 = layers.concatenate([up6, conv4])\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', dtype='float32')(up6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same', dtype='float32')(conv6)\n",
    "    \n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same', dtype='float32')(conv6)\n",
    "    up7 = layers.concatenate([up7, conv3])\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', dtype='float32')(up7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same', dtype='float32')(conv7)\n",
    "    \n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same', dtype='float32')(conv7)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', dtype='float32')(up8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same', dtype='float32')(conv8)\n",
    "    \n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same', dtype='float32')(conv8)\n",
    "    up9 = layers.concatenate([up9, conv1])\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', dtype='float32')(up9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same', dtype='float32')(conv9)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid', dtype='float32')(conv9)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name='UNet')\n",
    "    return model\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_images, train_masks = load_data_batch_by_batch(DATA_PATH, 'train')\n",
    "val_images, val_masks = load_data_batch_by_batch(DATA_PATH, 'val')\n",
    "test_images, test_masks = load_data_batch_by_batch(DATA_PATH, 'test')\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Train: {train_images.shape[0]} samples\")\n",
    "print(f\"Val: {val_images.shape[0]} samples\")\n",
    "print(f\"Test: {test_images.shape[0]} samples\")\n",
    "\n",
    "train_gen = MemoryEfficientGenerator(train_images, train_masks, BATCH_SIZE, shuffle=True, augment=True)\n",
    "val_gen = MemoryEfficientGenerator(val_images, val_masks, BATCH_SIZE, shuffle=False, augment=False)\n",
    "test_gen = MemoryEfficientGenerator(test_images, test_masks, BATCH_SIZE, shuffle=False, augment=False)\n",
    "\n",
    "print(f\"\\nBatches per epoch: Train={len(train_gen)}, Val={len(val_gen)}\")\n",
    "\n",
    "print(\"\\nBuilding U-Net model...\")\n",
    "model = build_unet(input_shape=(INPUT_SIZE, INPUT_SIZE, INPUT_CHANNELS))\n",
    "\n",
    "print(f\"Model parameters: {model.count_params():,}\")\n",
    "\n",
    "optimizer = mixed_precision.LossScaleOptimizer(\n",
    "    optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(OUTPUT_PATH, \"best_model.keras\")\n",
    "log_dir = os.path.join(OUTPUT_PATH, \"logs\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=30,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.CSVLogger(\n",
    "        os.path.join(OUTPUT_PATH, 'training_log.csv')\n",
    "    ),\n",
    "    callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch, logs: gc.collect()\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Training completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nEvaluating model...\")\n",
    "\n",
    "best_model = models.load_model(checkpoint_path)\n",
    "test_results = best_model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "for metric_name, value in zip(best_model.metrics_names, test_results):\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "test_metrics = {\n",
    "    'configuration': 'standard_unet',\n",
    "    'input_size': INPUT_SIZE,\n",
    "    'input_channels': INPUT_CHANNELS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'mixed_precision': True,\n",
    "    'model_parameters': int(model.count_params())\n",
    "}\n",
    "\n",
    "for metric_name, value in zip(best_model.metrics_names, test_results):\n",
    "    test_metrics[metric_name] = float(value)\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, 'test_results.json'), 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=4)\n",
    "\n",
    "def visualize_sample_predictions(model, images, masks, num_samples=3):\n",
    "    plt.figure(figsize=(15, 5*num_samples))\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images[i:i+1]\n",
    "        mask = masks[i]\n",
    "        \n",
    "        pred = model.predict(img, verbose=0)[0].squeeze()\n",
    "        \n",
    "        img_display = img[0]\n",
    "        img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min() + 1e-8)\n",
    "        \n",
    "        plt.subplot(num_samples, 4, i*4 + 1)\n",
    "        plt.imshow(img_display[:, :, 0], cmap='gray')\n",
    "        plt.title(f'Sample {i+1} - VV')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 4, i*4 + 2)\n",
    "        plt.imshow(img_display[:, :, 1], cmap='gray')\n",
    "        plt.title(f'Sample {i+1} - VH')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 4, i*4 + 3)\n",
    "        plt.imshow(mask, cmap='Blues')\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_samples, 4, i*4 + 4)\n",
    "        plt.imshow(pred, cmap='Blues')\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'sample_predictions.png'), dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "visualize_sample_predictions(best_model, test_images, test_masks, num_samples=3)\n",
    "\n",
    "del train_images, val_images, test_images\n",
    "del train_masks, val_masks, test_masks\n",
    "gc.collect()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb58ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive Model Evaluation\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import gc\n",
    "\n",
    "\n",
    "# Paths\n",
    "MODEL_PATH = \"/kaggle/working/unet_paper_memory_optimized/best_model_memory_opt.keras\"\n",
    "DATA_PATH = \"/kaggle/working/preprocessed_512\"\n",
    "OUTPUT_PATH = \"/kaggle/working/comprehensive_evaluation\"\n",
    "\n",
    "# Alternative paths to check if primary paths don't exist\n",
    "ALTERNATIVE_MODEL_PATHS = [\n",
    "    \"/kaggle/working/unet_paper_memory_optimized/best_model_memory_opt.keras\",\n",
    "    \"/kaggle/working/flood_unet_paper_config_512/best_unet_model_paper_config_cosine_annealing.keras\",\n",
    "    \"/kaggle/working/unet_paper_exact/best_unet_paper_model.keras\"\n",
    "]\n",
    "\n",
    "ALTERNATIVE_DATA_PATHS = [\n",
    "    \"/kaggle/working/preprocessed_512\",\n",
    "    \"/kaggle/working/preprocessed_256\",\n",
    "    \"/kaggle/working/preprocessed\"\n",
    "]\n",
    "\n",
    "# Find working paths\n",
    "print(\" Searching for model and data...\")\n",
    "\n",
    "# Find model\n",
    "working_model_path = None\n",
    "for path in ALTERNATIVE_MODEL_PATHS:\n",
    "    if os.path.exists(path):\n",
    "        working_model_path = path\n",
    "        print(f\" Found model: {path}\")\n",
    "        break\n",
    "\n",
    "if working_model_path is None:\n",
    "    print(\" No model found. Please check these locations:\")\n",
    "    for path in ALTERNATIVE_MODEL_PATHS:\n",
    "        print(f\"   • {path}\")\n",
    "    raise FileNotFoundError(\"No trained model found\")\n",
    "\n",
    "MODEL_PATH = working_model_path\n",
    "\n",
    "# Find data\n",
    "working_data_path = None\n",
    "for path in ALTERNATIVE_DATA_PATHS:\n",
    "    test_dir = os.path.join(path, 'test')\n",
    "    if os.path.exists(test_dir):\n",
    "        working_data_path = path\n",
    "        print(f\" Found data: {path}\")\n",
    "        break\n",
    "\n",
    "if working_data_path is None:\n",
    "    print(\" No test data found. Please check these locations:\")\n",
    "    for path in ALTERNATIVE_DATA_PATHS:\n",
    "        print(f\"   • {path}/test/\")\n",
    "    raise FileNotFoundError(\"No test data found\")\n",
    "\n",
    "DATA_PATH = working_data_path\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "INPUT_SIZE = 512\n",
    "INPUT_CHANNELS = 2\n",
    "BATCH_SIZE = 2  # Same as training for consistency\n",
    "THRESHOLD = 0.5  # Binary classification threshold\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\" Model: {MODEL_PATH}\")\n",
    "print(f\" Data: {DATA_PATH}\")\n",
    "print(f\" Output: {OUTPUT_PATH}\")\n",
    "print(f\" Input Size: {INPUT_SIZE}×{INPUT_SIZE}\")\n",
    "print(f\" Threshold: {THRESHOLD}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =====================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# =====================================================\n",
    "\n",
    "def load_test_data(base_path):\n",
    "    \"\"\"Load test dataset with better error handling\"\"\"\n",
    "    print(\"Loading test dataset...\")\n",
    "    \n",
    "    img_files = sorted(glob.glob(os.path.join(base_path, 'test', 'images', '*.npy')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(base_path, 'test', 'masks', '*.npy')))\n",
    "    \n",
    "    if len(img_files) == 0:\n",
    "        raise ValueError(f\"No test images found in {base_path}/test/images/\")\n",
    "    \n",
    "    if len(mask_files) == 0:\n",
    "        raise ValueError(f\"No test masks found in {base_path}/test/masks/\")\n",
    "    \n",
    "    if len(img_files) != len(mask_files):\n",
    "        print(f\" Warning: {len(img_files)} images but {len(mask_files)} masks\")\n",
    "        # Use minimum of both\n",
    "        min_len = min(len(img_files), len(mask_files))\n",
    "        img_files = img_files[:min_len]\n",
    "        mask_files = mask_files[:min_len]\n",
    "    \n",
    "    print(f\"Found {len(img_files)} test samples\")\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "    valid_samples = 0\n",
    "    \n",
    "    for i, (img_file, mask_file) in enumerate(zip(img_files, mask_files)):\n",
    "        try:\n",
    "            # Load image\n",
    "            img = np.load(img_file).astype(np.float32)\n",
    "            \n",
    "            # Validate image shape\n",
    "            if len(img.shape) != 3:\n",
    "                print(f\" Skipping {img_file}: invalid shape {img.shape}\")\n",
    "                continue\n",
    "                \n",
    "            img = img[:, :, :INPUT_CHANNELS]  # Take VV, VH channels\n",
    "            \n",
    "            # Load mask\n",
    "            mask = np.load(mask_file).astype(np.float32)\n",
    "            \n",
    "            # Validate mask shape\n",
    "            if len(mask.shape) != 2:\n",
    "                print(f\" Skipping {mask_file}: invalid shape {mask.shape}\")\n",
    "                continue\n",
    "            \n",
    "            # Validate shapes match\n",
    "            if img.shape[:2] != mask.shape:\n",
    "                print(f\" Skipping sample {i}: shape mismatch img{img.shape[:2]} vs mask{mask.shape}\")\n",
    "                continue\n",
    "            \n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "            valid_samples += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error loading sample {i}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(img_files)} files, {valid_samples} valid\")\n",
    "    \n",
    "    if valid_samples == 0:\n",
    "        raise ValueError(\"No valid test samples loaded!\")\n",
    "    \n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    print(f\" Test data loaded: {valid_samples} samples\")\n",
    "    print(f\"Images shape: {images.shape}, Masks shape: {masks.shape}\")\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "class EvaluationGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Simple and robust data generator for evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, images, masks, batch_size=2):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.batch_size = batch_size\n",
    "        self.n_samples = len(images)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, self.n_samples)\n",
    "        \n",
    "        batch_images = self.images[start_idx:end_idx]\n",
    "        batch_masks = self.masks[start_idx:end_idx]\n",
    "        \n",
    "        # Ensure masks have channel dimension\n",
    "        if len(batch_masks.shape) == 3:  # (batch, height, width)\n",
    "            batch_masks = np.expand_dims(batch_masks, axis=-1)\n",
    "        \n",
    "        return batch_images, batch_masks\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        \"\"\"Return all data at once - useful for evaluation\"\"\"\n",
    "        if len(self.masks.shape) == 3:\n",
    "            masks_with_channel = np.expand_dims(self.masks, axis=-1)\n",
    "        else:\n",
    "            masks_with_channel = self.masks\n",
    "        \n",
    "        return self.images, masks_with_channel\n",
    "\n",
    "# =====================================================\n",
    "# COMPREHENSIVE METRICS CALCULATION\n",
    "# =====================================================\n",
    "\n",
    "def calculate_pixel_metrics(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculate pixel-wise metrics\"\"\"\n",
    "    \n",
    "    # Flatten arrays\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    \n",
    "    # Apply threshold to predictions\n",
    "    y_pred_binary = (y_pred_flat >= threshold).astype(np.float32)\n",
    "    y_true_binary = (y_true_flat >= threshold).astype(np.float32)\n",
    "    \n",
    "    # Calculate confusion matrix components\n",
    "    tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "    tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "    fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "    fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['true_positives'] = int(tp)\n",
    "    metrics['true_negatives'] = int(tn)\n",
    "    metrics['false_positives'] = int(fp)\n",
    "    metrics['false_negatives'] = int(fn)\n",
    "    \n",
    "    # Accuracy\n",
    "    metrics['accuracy'] = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n",
    "    \n",
    "    # Precision (Positive Predictive Value)\n",
    "    metrics['precision'] = tp / (tp + fp + 1e-8)\n",
    "    \n",
    "    # Recall (Sensitivity, True Positive Rate)\n",
    "    metrics['recall'] = tp / (tp + fn + 1e-8)\n",
    "    \n",
    "    # Specificity (True Negative Rate)\n",
    "    metrics['specificity'] = tn / (tn + fp + 1e-8)\n",
    "    \n",
    "    # F1 Score\n",
    "    metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'] + 1e-8)\n",
    "    \n",
    "    # IoU (Intersection over Union)\n",
    "    intersection = tp\n",
    "    union = tp + fp + fn\n",
    "    metrics['iou'] = intersection / (union + 1e-8)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    metrics['dice'] = 2 * tp / (2 * tp + fp + fn + 1e-8)\n",
    "    \n",
    "    # Jaccard Index (same as IoU)\n",
    "    metrics['jaccard'] = metrics['iou']\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_sample_wise_metrics(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculate metrics for each sample separately\"\"\"\n",
    "    \n",
    "    sample_metrics = []\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        sample_true = y_true[i]\n",
    "        sample_pred = y_pred[i]\n",
    "        \n",
    "        metrics = calculate_pixel_metrics(sample_true, sample_pred, threshold)\n",
    "        metrics['sample_id'] = i\n",
    "        sample_metrics.append(metrics)\n",
    "    \n",
    "    return sample_metrics\n",
    "\n",
    "def calculate_class_distribution(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculate class distribution statistics\"\"\"\n",
    "    \n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    \n",
    "    y_pred_binary = (y_pred_flat >= threshold).astype(np.float32)\n",
    "    y_true_binary = (y_true_flat >= threshold).astype(np.float32)\n",
    "    \n",
    "    stats = {\n",
    "        'total_pixels': len(y_true_flat),\n",
    "        'true_flood_pixels': int(np.sum(y_true_binary)),\n",
    "        'true_non_flood_pixels': int(np.sum(1 - y_true_binary)),\n",
    "        'pred_flood_pixels': int(np.sum(y_pred_binary)),\n",
    "        'pred_non_flood_pixels': int(np.sum(1 - y_pred_binary)),\n",
    "        'true_flood_percentage': float(np.mean(y_true_binary) * 100),\n",
    "        'pred_flood_percentage': float(np.mean(y_pred_binary) * 100)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# =====================================================\n",
    "# LOAD MODEL AND DATA\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n Loading trained model...\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\" Model not found at {MODEL_PATH}\")\n",
    "    print(\"Available models:\")\n",
    "    model_dir = os.path.dirname(MODEL_PATH)\n",
    "    if os.path.exists(model_dir):\n",
    "        for f in os.listdir(model_dir):\n",
    "            if f.endswith('.keras') or f.endswith('.h5'):\n",
    "                print(f\"   • {os.path.join(model_dir, f)}\")\n",
    "    raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
    "\n",
    "try:\n",
    "    model = models.load_model(MODEL_PATH)\n",
    "    print(f\" Model loaded successfully\")\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "    print(f\"Model parameters: {model.count_params():,}\")\n",
    "except Exception as e:\n",
    "    print(f\" Failed to load model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load test data\n",
    "try:\n",
    "    test_images, test_masks = load_test_data(DATA_PATH)\n",
    "    print(f\" Test data loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\" Failed to load test data: {e}\")\n",
    "    print(f\"Check if path exists: {DATA_PATH}\")\n",
    "    print(f\"Expected structure: {DATA_PATH}/test/images/*.npy and {DATA_PATH}/test/masks/*.npy\")\n",
    "    raise\n",
    "\n",
    "# Validate data compatibility\n",
    "print(f\"\\n Data validation:\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test masks shape: {test_masks.shape}\")\n",
    "print(f\"Model expects: {model.input_shape}\")\n",
    "\n",
    "if test_images.shape[1:] != model.input_shape[1:]:\n",
    "    print(f\" Warning: Input shape mismatch!\")\n",
    "    print(f\"Model expects: {model.input_shape[1:]}\")\n",
    "    print(f\"Data provides: {test_images.shape[1:]}\")\n",
    "\n",
    "# Create evaluation generator (keeping for compatibility)\n",
    "test_gen = EvaluationGenerator(test_images, test_masks, BATCH_SIZE)\n",
    "\n",
    "print(f\"Test samples: {len(test_images)}\")\n",
    "print(f\"Evaluation batches: {len(test_gen)}\")\n",
    "\n",
    "# Test a small prediction to ensure everything works\n",
    "print(f\"\\n Testing model prediction...\")\n",
    "try:\n",
    "    test_batch = test_images[:min(BATCH_SIZE, len(test_images))]\n",
    "    test_pred = model.predict(test_batch, verbose=0)\n",
    "    print(f\" Test prediction successful: {test_pred.shape}\")\n",
    "    print(f\"Prediction range: [{test_pred.min():.3f}, {test_pred.max():.3f}]\")\n",
    "except Exception as e:\n",
    "    print(f\" Test prediction failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# =====================================================\n",
    "# GENERATE PREDICTIONS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n Generating predictions...\")\n",
    "\n",
    "# Method 1: Direct prediction (more reliable)\n",
    "print(\"Using direct prediction method...\")\n",
    "\n",
    "try:\n",
    "    # Predict directly on all test images\n",
    "    predictions = model.predict(test_images, batch_size=BATCH_SIZE, verbose=1)\n",
    "    predictions = predictions.squeeze()  # Remove channel dimension if present\n",
    "    \n",
    "    print(f\" Predictions generated: {predictions.shape}\")\n",
    "    print(f\"Prediction range: [{predictions.min():.3f}, {predictions.max():.3f}]\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Direct prediction failed: {e}\")\n",
    "    print(\" Trying batch-by-batch prediction...\")\n",
    "    \n",
    "    # Method 2: Batch-by-batch prediction (fallback)\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i in range(0, len(test_images), BATCH_SIZE):\n",
    "        batch_end = min(i + BATCH_SIZE, len(test_images))\n",
    "        batch_images = test_images[i:batch_end]\n",
    "        \n",
    "        batch_predictions = model.predict(batch_images, verbose=0)\n",
    "        all_predictions.append(batch_predictions)\n",
    "        \n",
    "        if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "            print(f\"Processed {i // BATCH_SIZE + 1} batches\")\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    predictions = np.concatenate(all_predictions, axis=0)\n",
    "    predictions = predictions.squeeze()  # Remove channel dimension\n",
    "    \n",
    "    print(f\" Predictions generated: {predictions.shape}\")\n",
    "    print(f\"Prediction range: [{predictions.min():.3f}, {predictions.max():.3f}]\")\n",
    "\n",
    "# Verify predictions shape matches masks\n",
    "if predictions.shape != test_masks.shape:\n",
    "    print(f\" Shape mismatch: predictions {predictions.shape} vs masks {test_masks.shape}\")\n",
    "    # Fix shape if needed\n",
    "    if len(predictions.shape) == 3 and predictions.shape[-1] == 1:\n",
    "        predictions = predictions.squeeze(-1)\n",
    "    print(f\" Fixed predictions shape: {predictions.shape}\")\n",
    "\n",
    "# =====================================================\n",
    "# CALCULATE COMPREHENSIVE METRICS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n Calculating comprehensive metrics...\")\n",
    "\n",
    "# Overall metrics\n",
    "overall_metrics = calculate_pixel_metrics(test_masks, predictions, THRESHOLD)\n",
    "\n",
    "# Sample-wise metrics\n",
    "sample_metrics = calculate_sample_wise_metrics(test_masks, predictions, THRESHOLD)\n",
    "\n",
    "# Class distribution\n",
    "class_stats = calculate_class_distribution(test_masks, predictions, THRESHOLD)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "sample_df = pd.DataFrame(sample_metrics)\n",
    "\n",
    "print(\" Metrics calculated successfully\")\n",
    "\n",
    "# =====================================================\n",
    "# PRINT RESULTS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPREHENSIVE EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n OVERALL PERFORMANCE:\")\n",
    "print(f\"   • Accuracy: {overall_metrics['accuracy']:.4f} ({overall_metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"   • IoU Score: {overall_metrics['iou']:.4f} ({overall_metrics['iou']*100:.2f}%)\")\n",
    "print(f\"   • Dice Coefficient: {overall_metrics['dice']:.4f} ({overall_metrics['dice']*100:.2f}%)\")\n",
    "print(f\"   • F1 Score: {overall_metrics['f1_score']:.4f} ({overall_metrics['f1_score']*100:.2f}%)\")\n",
    "print(f\"   • Precision: {overall_metrics['precision']:.4f} ({overall_metrics['precision']*100:.2f}%)\")\n",
    "print(f\"   • Recall: {overall_metrics['recall']:.4f} ({overall_metrics['recall']*100:.2f}%)\")\n",
    "print(f\"   • Specificity: {overall_metrics['specificity']:.4f} ({overall_metrics['specificity']*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n CONFUSION MATRIX:\")\n",
    "print(f\"   • True Positives: {overall_metrics['true_positives']:,}\")\n",
    "print(f\"   • True Negatives: {overall_metrics['true_negatives']:,}\")\n",
    "print(f\"   • False Positives: {overall_metrics['false_positives']:,}\")\n",
    "print(f\"   • False Negatives: {overall_metrics['false_negatives']:,}\")\n",
    "\n",
    "print(\"\\n CLASS DISTRIBUTION:\")\n",
    "print(f\"   • Total Pixels: {class_stats['total_pixels']:,}\")\n",
    "print(f\"   • True Flood Pixels: {class_stats['true_flood_pixels']:,} ({class_stats['true_flood_percentage']:.2f}%)\")\n",
    "print(f\"   • Predicted Flood Pixels: {class_stats['pred_flood_pixels']:,} ({class_stats['pred_flood_percentage']:.2f}%)\")\n",
    "\n",
    "print(\"\\n SAMPLE-WISE STATISTICS:\")\n",
    "print(f\"   • Mean IoU: {sample_df['iou'].mean():.4f} ± {sample_df['iou'].std():.4f}\")\n",
    "print(f\"   • Mean Dice: {sample_df['dice'].mean():.4f} ± {sample_df['dice'].std():.4f}\")\n",
    "print(f\"   • Mean F1: {sample_df['f1_score'].mean():.4f} ± {sample_df['f1_score'].std():.4f}\")\n",
    "print(f\"   • Best Sample IoU: {sample_df['iou'].max():.4f}\")\n",
    "print(f\"   • Worst Sample IoU: {sample_df['iou'].min():.4f}\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# SAVE RESULTS\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\n Saving results...\")\n",
    "\n",
    "# Save overall metrics\n",
    "overall_results = {\n",
    "    'model_path': MODEL_PATH,\n",
    "    'test_samples': len(test_images),\n",
    "    'threshold': THRESHOLD,\n",
    "    'overall_metrics': overall_metrics,\n",
    "    'class_statistics': class_stats,\n",
    "    'paper_comparison': {\n",
    "        'paper_iou': paper_results['iou'],\n",
    "        'paper_accuracy': paper_results['accuracy'],\n",
    "        'paper_f1': paper_results['f1_score'],\n",
    "        'our_iou': overall_metrics['iou'],\n",
    "        'our_accuracy': overall_metrics['accuracy'],\n",
    "        'our_f1': overall_metrics['f1_score'],\n",
    "        'iou_difference': overall_metrics['iou'] - paper_results['iou'],\n",
    "        'accuracy_difference': overall_metrics['accuracy'] - paper_results['accuracy'],\n",
    "        'f1_difference': overall_metrics['f1_score'] - paper_results['f1_score']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(os.path.join(OUTPUT_PATH, 'comprehensive_results.json'), 'w') as f:\n",
    "    json.dump(overall_results, f, indent=4)\n",
    "\n",
    "# Save sample-wise results to CSV\n",
    "sample_df.to_csv(os.path.join(OUTPUT_PATH, 'sample_wise_metrics.csv'), index=False)\n",
    "\n",
    "print(f\" Results saved to {OUTPUT_PATH}\")\n",
    "\n",
    "# =====================================================\n",
    "# VISUALIZATIONS\n",
    "# =====================================================\n",
    "\n",
    "def create_comprehensive_visualizations():\n",
    "    \"\"\"Create comprehensive evaluation visualizations\"\"\"\n",
    "    \n",
    "    # 1. Metrics comparison bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    metrics_names = ['Accuracy', 'IoU', 'Dice', 'F1-Score', 'Precision', 'Recall', 'Specificity']\n",
    "    our_values = [\n",
    "        overall_metrics['accuracy'],\n",
    "        overall_metrics['iou'],\n",
    "        overall_metrics['dice'],\n",
    "        overall_metrics['f1_score'],\n",
    "        overall_metrics['precision'],\n",
    "        overall_metrics['recall'],\n",
    "        overall_metrics['specificity']\n",
    "    ]\n",
    "    \n",
    "    paper_values = [\n",
    "        paper_results['accuracy'],\n",
    "        paper_results['iou'],\n",
    "        np.nan,  # Dice not reported in paper\n",
    "        paper_results['f1_score'],\n",
    "        np.nan,  # Precision not reported\n",
    "        np.nan,  # Recall not reported\n",
    "        np.nan   # Specificity not reported\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, our_values, width, label='Our Model', color='skyblue', alpha=0.8)\n",
    "    \n",
    "    # Only plot paper values where available\n",
    "    paper_indices = [0, 1, 3]  # Accuracy, IoU, F1\n",
    "    paper_x = [x[i] for i in paper_indices]\n",
    "    paper_vals = [paper_values[i] for i in paper_indices]\n",
    "    \n",
    "    plt.bar([px + width/2 for px in paper_x], paper_vals, width, label='Paper Results', color='lightcoral', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Performance Comparison: Our Model vs Paper')\n",
    "    plt.xticks(x, metrics_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(our_values):\n",
    "        plt.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    for i, v in zip(paper_indices, paper_vals):\n",
    "        plt.text(i + width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'metrics_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Sample-wise IoU distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(sample_df['iou'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(sample_df['iou'].mean(), color='red', linestyle='--', label=f'Mean: {sample_df[\"iou\"].mean():.3f}')\n",
    "    plt.xlabel('IoU Score')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Distribution of Sample-wise IoU Scores')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot([sample_df['iou'], sample_df['dice'], sample_df['f1_score']], \n",
    "                labels=['IoU', 'Dice', 'F1'])\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Sample-wise Metrics Distribution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'sample_distributions.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create confusion matrix for visualization\n",
    "    cm = np.array([[overall_metrics['true_negatives'], overall_metrics['false_positives']],\n",
    "                   [overall_metrics['false_negatives'], overall_metrics['true_positives']]])\n",
    "    \n",
    "    # Normalize to percentages\n",
    "    cm_percent = cm / cm.sum() * 100\n",
    "    \n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=['Predicted Non-Flood', 'Predicted Flood'],\n",
    "                yticklabels=['Actual Non-Flood', 'Actual Flood'],\n",
    "                cbar_kws={'label': 'Percentage of Total Pixels'})\n",
    "    \n",
    "    plt.title('Confusion Matrix (% of Total Pixels)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Sample predictions visualization\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Show 6 samples with worst and best IoU scores\n",
    "    worst_samples = sample_df.nsmallest(3, 'iou')['sample_id'].values\n",
    "    best_samples = sample_df.nlargest(3, 'iou')['sample_id'].values\n",
    "    \n",
    "    sample_indices = np.concatenate([worst_samples, best_samples])\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        # Original image (VV channel)\n",
    "        plt.subplot(2, 9, i*3 + 1)\n",
    "        img_display = test_images[idx][:, :, 0]  # VV channel\n",
    "        img_display = (img_display - img_display.min()) / (img_display.max() - img_display.min() + 1e-8)\n",
    "        plt.imshow(img_display, cmap='gray')\n",
    "        plt.title(f'Sample {idx}\\nVV Channel')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Ground truth\n",
    "        plt.subplot(2, 9, i*3 + 2)\n",
    "        plt.imshow(test_masks[idx], cmap='Blues', vmin=0, vmax=1)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        plt.subplot(2, 9, i*3 + 3)\n",
    "        plt.imshow(predictions[idx], cmap='Blues', vmin=0, vmax=1)\n",
    "        iou_score = sample_df.loc[sample_df['sample_id'] == idx, 'iou'].iloc[0]\n",
    "        plt.title(f'Prediction\\nIoU: {iou_score:.3f}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Worst 3 Samples (top) vs Best 3 Samples (bottom)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n Creating visualizations...\")\n",
    "create_comprehensive_visualizations()\n",
    "\n",
    "# =====================================================\n",
    "# THRESHOLD ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "def threshold_analysis():\n",
    "    \"\"\"Analyze performance across different thresholds\"\"\"\n",
    "    print(\"\\n Performing threshold analysis...\")\n",
    "    \n",
    "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "    threshold_results = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        metrics = calculate_pixel_metrics(test_masks, predictions, thresh)\n",
    "        metrics['threshold'] = thresh\n",
    "        threshold_results.append(metrics)\n",
    "    \n",
    "    threshold_df = pd.DataFrame(threshold_results)\n",
    "    \n",
    "    # Plot threshold analysis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    metrics_to_plot = ['accuracy', 'iou', 'dice', 'f1_score', 'precision', 'recall']\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        plt.plot(threshold_df['threshold'], threshold_df[metric], marker='o', label=metric.replace('_', ' ').title())\n",
    "    \n",
    "    plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Default Threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Performance vs Classification Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim(0.1, 0.9)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'threshold_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save threshold analysis\n",
    "    threshold_df.to_csv(os.path.join(OUTPUT_PATH, 'threshold_analysis.csv'), index=False)\n",
    "    \n",
    "    # Find optimal threshold for IoU\n",
    "    optimal_idx = threshold_df['iou'].idxmax()\n",
    "    optimal_threshold = threshold_df.loc[optimal_idx, 'threshold']\n",
    "    optimal_iou = threshold_df.loc[optimal_idx, 'iou']\n",
    "    \n",
    "    print(f\" Optimal threshold for IoU: {optimal_threshold:.1f} (IoU: {optimal_iou:.4f})\")\n",
    "    print(f\" Default threshold (0.5) IoU: {threshold_df.loc[threshold_df['threshold'] == 0.5, 'iou'].iloc[0]:.4f}\")\n",
    "    \n",
    "    return threshold_df\n",
    "\n",
    "threshold_results = threshold_analysis()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
