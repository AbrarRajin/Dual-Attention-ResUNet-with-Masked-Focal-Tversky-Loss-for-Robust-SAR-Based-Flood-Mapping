{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b67551-6320-4941-b300-5375832a370c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4186b-f1ea-4013-9b40-6355d2bfc644",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Unified Dataset Preprocessor for Otsu and Hand labelled SEN1FLOODS11 dataset\n",
    "\n",
    "\n",
    "!pip install rasterio\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import json\n",
    "\n",
    "class UnifiedSARFloodPreprocessor:\n",
    "    def __init__(self, otsu_path, sen1floods_path, output_path, img_size=256, \n",
    "                 test_size=0.2, val_size=0.2, random_seed=42):\n",
    "        \"\"\"\n",
    "        Unified preprocessor for both S1F11-Otsu and Sen1Floods11 datasets\n",
    "        \n",
    "        Args:\n",
    "            otsu_path: Path to S1F11-Otsu dataset\n",
    "            sen1floods_path: Path to Sen1Floods11 dataset  \n",
    "            output_path: Output directory for processed data\n",
    "            img_size: Target image size (default 256)\n",
    "            test_size: Test split ratio (default 0.2)\n",
    "            val_size: Validation split ratio (default 0.2)\n",
    "            random_seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.otsu_path = otsu_path\n",
    "        self.sen1floods_path = sen1floods_path\n",
    "        self.output_path = output_path\n",
    "        self.img_size = img_size\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # Set random seed for reproducible splits\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        # Initialize normalization parameters (calculated from combined training data)\n",
    "        self.norm_means = None\n",
    "        self.norm_stds = None\n",
    "        \n",
    "        # Dataset paths\n",
    "        self.setup_dataset_paths()\n",
    "        \n",
    "        # Create output directories\n",
    "        self.create_output_dirs()\n",
    "        \n",
    "        # Statistics for tracking combined dataset properties\n",
    "        self.stats = {\n",
    "            'train': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0, 'otsu_count': 0, 'sen1floods_count': 0},\n",
    "            'val': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0, 'otsu_count': 0, 'sen1floods_count': 0},\n",
    "            'test': {'count': 0, 'flood_pixels': 0, 'total_valid_pixels': 0, 'invalid_pixels': 0, 'otsu_count': 0, 'sen1floods_count': 0}\n",
    "        }\n",
    "\n",
    "    def setup_dataset_paths(self):\n",
    "        \"\"\"Setup paths for both datasets\"\"\"\n",
    "        # Otsu dataset paths\n",
    "        self.otsu_image_dir = os.path.join(self.otsu_path, 'S1Weak')\n",
    "        self.otsu_label_dir = os.path.join(self.otsu_path, 'S1OtsuLabelWeak')\n",
    "        \n",
    "        # Sen1Floods11 dataset paths\n",
    "        self.sen1floods_image_dir = os.path.join(self.sen1floods_path, 'data', 'flood_events', 'HandLabeled', 'S1Hand')\n",
    "        self.sen1floods_mask_dir = os.path.join(self.sen1floods_path, 'data', 'flood_events', 'HandLabeled', 'LabelHand')\n",
    "        self.sen1floods_splits_dir = os.path.join(self.sen1floods_path, 'splits', 'flood_handlabeled')\n",
    "\n",
    "    def create_output_dirs(self):\n",
    "        \"\"\"Create output directory structure\"\"\"\n",
    "        if os.path.exists(self.output_path):\n",
    "            shutil.rmtree(self.output_path)\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'masks'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_path, split, 'validity_masks'), exist_ok=True)\n",
    "            \n",
    "        print(f\"Created output directories at {self.output_path}\")\n",
    "\n",
    "    def find_otsu_pairs(self):\n",
    "        \"\"\"Find matching SAR images and labels for Otsu dataset\"\"\"\n",
    "        print(\"Finding Otsu dataset pairs...\")\n",
    "        \n",
    "        sar_files = glob.glob(os.path.join(self.otsu_image_dir, '*_S1Weak.tif'))\n",
    "        label_files = glob.glob(os.path.join(self.otsu_label_dir, '*_S1OtsuLabelWeak.tif'))\n",
    "        \n",
    "        print(f\"Found {len(sar_files)} Otsu SAR images\")\n",
    "        print(f\"Found {len(label_files)} Otsu label files\")\n",
    "        \n",
    "        # Create dictionaries for quick lookup\n",
    "        sar_dict = {}\n",
    "        label_dict = {}\n",
    "        \n",
    "        for sar_file in sar_files:\n",
    "            basename = os.path.basename(sar_file)\n",
    "            base_id = '_'.join(basename.split('_')[:-1])\n",
    "            sar_dict[base_id] = sar_file\n",
    "            \n",
    "        for label_file in label_files:\n",
    "            basename = os.path.basename(label_file)\n",
    "            base_id = '_'.join(basename.split('_')[:-1])\n",
    "            label_dict[base_id] = label_file\n",
    "        \n",
    "        # Find matching pairs\n",
    "        matching_pairs = []\n",
    "        for base_id in sar_dict:\n",
    "            if base_id in label_dict:\n",
    "                matching_pairs.append(('otsu', base_id, sar_dict[base_id], label_dict[base_id]))\n",
    "            else:\n",
    "                print(f\"Warning: No Otsu label found for SAR image {base_id}\")\n",
    "        \n",
    "        print(f\"Found {len(matching_pairs)} Otsu matching pairs\")\n",
    "        return matching_pairs\n",
    "\n",
    "    def read_sen1floods_csv(self, csv_path):\n",
    "        \"\"\"Read Sen1Floods11 CSV file\"\"\"\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"Warning: CSV file not found: {csv_path}\")\n",
    "            return []\n",
    "            \n",
    "        with open(csv_path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader, None)  # Skip header\n",
    "            pairs = []\n",
    "            for row in reader:\n",
    "                if len(row) >= 2:\n",
    "                    im_path = os.path.join(self.sen1floods_image_dir, row[0])\n",
    "                    mask_path = os.path.join(self.sen1floods_mask_dir, row[1])\n",
    "                    pairs.append(('sen1floods', f\"sen1floods_{len(pairs)}\", im_path, mask_path))\n",
    "            return pairs\n",
    "\n",
    "    def get_all_dataset_pairs(self):\n",
    "        \"\"\"Get all pairs from both datasets\"\"\"\n",
    "        print(\"Collecting all dataset pairs...\")\n",
    "        \n",
    "        # Get Otsu pairs\n",
    "        otsu_pairs = self.find_otsu_pairs()\n",
    "        \n",
    "        # Get Sen1Floods11 pairs\n",
    "        sen1floods_pairs = []\n",
    "        for split_name in ['flood_train_data.csv', 'flood_val_data.csv', 'flood_test_data.csv']:\n",
    "            csv_path = os.path.join(self.sen1floods_splits_dir, split_name)\n",
    "            pairs = self.read_sen1floods_csv(csv_path)\n",
    "            sen1floods_pairs.extend(pairs)\n",
    "        \n",
    "        all_pairs = otsu_pairs + sen1floods_pairs\n",
    "        \n",
    "        print(f\"Total dataset pairs:\")\n",
    "        print(f\"  Otsu: {len(otsu_pairs)} pairs\")\n",
    "        print(f\"  Sen1Floods11: {len(sen1floods_pairs)} pairs\")\n",
    "        print(f\"  Combined: {len(all_pairs)} pairs\")\n",
    "        \n",
    "        return all_pairs\n",
    "\n",
    "    def create_unified_splits(self, all_pairs):\n",
    "        \"\"\"Create unified train/val/test splits from combined datasets\"\"\"\n",
    "        print(f\"Creating unified splits with test_size={self.test_size}, val_size={self.val_size}\")\n",
    "        \n",
    "        # Separate by dataset type for balanced splitting\n",
    "        otsu_pairs = [p for p in all_pairs if p[0] == 'otsu']\n",
    "        sen1floods_pairs = [p for p in all_pairs if p[0] == 'sen1floods']\n",
    "        \n",
    "        # Split each dataset separately to ensure representation\n",
    "        if len(otsu_pairs) > 0:\n",
    "            otsu_train_val, otsu_test = train_test_split(\n",
    "                otsu_pairs, test_size=self.test_size, random_state=self.random_seed\n",
    "            )\n",
    "            adjusted_val_size = self.val_size / (1 - self.test_size)\n",
    "            otsu_train, otsu_val = train_test_split(\n",
    "                otsu_train_val, test_size=adjusted_val_size, random_state=self.random_seed\n",
    "            )\n",
    "        else:\n",
    "            otsu_train = otsu_val = otsu_test = []\n",
    "        \n",
    "        if len(sen1floods_pairs) > 0:\n",
    "            sen1floods_train_val, sen1floods_test = train_test_split(\n",
    "                sen1floods_pairs, test_size=self.test_size, random_state=self.random_seed\n",
    "            )\n",
    "            adjusted_val_size = self.val_size / (1 - self.test_size)\n",
    "            sen1floods_train, sen1floods_val = train_test_split(\n",
    "                sen1floods_train_val, test_size=adjusted_val_size, random_state=self.random_seed\n",
    "            )\n",
    "        else:\n",
    "            sen1floods_train = sen1floods_val = sen1floods_test = []\n",
    "        \n",
    "        # Combine splits\n",
    "        splits = {\n",
    "            'train': otsu_train + sen1floods_train,\n",
    "            'val': otsu_val + sen1floods_val,\n",
    "            'test': otsu_test + sen1floods_test\n",
    "        }\n",
    "        \n",
    "        print(f\"Unified split sizes:\")\n",
    "        for split_name, pairs in splits.items():\n",
    "            otsu_count = len([p for p in pairs if p[0] == 'otsu'])\n",
    "            sen1floods_count = len([p for p in pairs if p[0] == 'sen1floods'])\n",
    "            total = len(pairs)\n",
    "            percentage = 100 * total / len(all_pairs)\n",
    "            print(f\"  {split_name.upper()}: {total} samples ({percentage:.1f}%) - Otsu: {otsu_count}, Sen1Floods11: {sen1floods_count}\")\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def compute_bands(self, vh, vv):\n",
    "        \"\"\"\n",
    "        Compute the three bands according to the specified formulas:\n",
    "        Band 1: VV\n",
    "        Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        \"\"\"\n",
    "        eps = 1e-8\n",
    "        \n",
    "        # Band 1: VV\n",
    "        band1 = vv\n",
    "        \n",
    "        # Band 2: NewBand1 = (VH - VV) / (VH + VV)\n",
    "        band2 = np.divide(vh - vv, vh + vv + eps)\n",
    "        \n",
    "        # Band 3: NewBand2 = sqrt((VH^2 + VV^2) / 2)\n",
    "        band3 = np.sqrt((vh**2 + vv**2) / 2)\n",
    "        \n",
    "        return band1, band2, band3\n",
    "\n",
    "    def process_image_for_stats(self, im_path):\n",
    "        \"\"\"Process image to collect statistics (first pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                if src.count < 2:\n",
    "                    print(f\"Warning: Image {im_path} has only {src.count} band(s). Expected at least 2 (VH, VV)\")\n",
    "                    return None\n",
    "                \n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                if vh.size == 0 or vv.size == 0:\n",
    "                    print(f\"Warning: Empty arrays in {im_path}\")\n",
    "                    return None\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                return arr_x\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image for stats {im_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_normalization_params(self, train_pairs):\n",
    "        \"\"\"Calculate mean and std from combined training data\"\"\"\n",
    "        print(\"Calculating normalization parameters from combined training data...\")\n",
    "        \n",
    "        # Collect all pixel values for each band\n",
    "        all_pixels = [[] for _ in range(3)]\n",
    "        \n",
    "        for dataset_type, base_id, im_path, _ in tqdm(train_pairs, desc=\"Collecting statistics\"):\n",
    "            if not os.path.exists(im_path):\n",
    "                continue\n",
    "                \n",
    "            arr_x = self.process_image_for_stats(im_path)\n",
    "            if arr_x is not None:\n",
    "                for i in range(3):\n",
    "                    all_pixels[i].append(arr_x[i].flatten())\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        means = []\n",
    "        stds = []\n",
    "        \n",
    "        for i in range(3):\n",
    "            if all_pixels[i]:\n",
    "                combined_pixels = np.concatenate(all_pixels[i])\n",
    "                means.append(np.mean(combined_pixels))\n",
    "                stds.append(np.std(combined_pixels))\n",
    "            else:\n",
    "                means.append(0.0)\n",
    "                stds.append(1.0)\n",
    "        \n",
    "        self.norm_means = np.array(means)\n",
    "        self.norm_stds = np.array(stds)\n",
    "        \n",
    "        print(f\"Calculated normalization parameters from combined datasets:\")\n",
    "        print(f\"Band 1 (VV): mean={self.norm_means[0]:.4f}, std={self.norm_stds[0]:.4f}\")\n",
    "        print(f\"Band 2 (NewBand1): mean={self.norm_means[1]:.4f}, std={self.norm_stds[1]:.4f}\")\n",
    "        print(f\"Band 3 (NewBand2): mean={self.norm_means[2]:.4f}, std={self.norm_stds[2]:.4f}\")\n",
    "        \n",
    "        # Save normalization parameters\n",
    "        norm_params_path = os.path.join(self.output_path, 'normalization_params.npy')\n",
    "        np.save(norm_params_path, {'means': self.norm_means, 'stds': self.norm_stds})\n",
    "        print(f\"Normalization parameters saved to: {norm_params_path}\")\n",
    "\n",
    "    def process_image(self, im_path):\n",
    "        \"\"\"Process image with normalization (second pass)\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(im_path) as src:\n",
    "                if src.count < 2:\n",
    "                    print(f\"Warning: Image {im_path} has only {src.count} band(s). Expected at least 2 (VH, VV)\")\n",
    "                    return None, None\n",
    "                \n",
    "                # Read VH and VV bands\n",
    "                vh = src.read(1)\n",
    "                vv = src.read(2)\n",
    "                \n",
    "                # Handle NaN and infinite values\n",
    "                vh = np.nan_to_num(vh)\n",
    "                vv = np.nan_to_num(vv)\n",
    "                \n",
    "                # Compute the three bands\n",
    "                band1, band2, band3 = self.compute_bands(vh, vv)\n",
    "                \n",
    "                # Create 3-channel image\n",
    "                arr_x = np.stack([band1, band2, band3], axis=0)\n",
    "                \n",
    "                # Clip extreme values\n",
    "                for i in range(3):\n",
    "                    v_min, v_max = np.percentile(arr_x[i], [1, 99])\n",
    "                    arr_x[i] = np.clip(arr_x[i], v_min, v_max)\n",
    "                \n",
    "                # Resize to target dimensions\n",
    "                arr_x = np.stack([\n",
    "                    resize(arr_x[0], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[1], (self.img_size, self.img_size), preserve_range=True),\n",
    "                    resize(arr_x[2], (self.img_size, self.img_size), preserve_range=True)\n",
    "                ], axis=0)\n",
    "                \n",
    "                # Normalize using calculated means and stds\n",
    "                if self.norm_means is not None and self.norm_stds is not None:\n",
    "                    arr_x = (arr_x - self.norm_means.reshape(3, 1, 1)) / self.norm_stds.reshape(3, 1, 1)\n",
    "                \n",
    "                # Convert to HWC format for saving as image\n",
    "                arr_x = np.transpose(arr_x, (1, 2, 0))\n",
    "                \n",
    "                # Scale to 0-1 range for visualization\n",
    "                eps = 1e-8\n",
    "                arr_x_viz = (arr_x - arr_x.min()) / (arr_x.max() - arr_x.min() + eps)\n",
    "                \n",
    "                return arr_x, arr_x_viz\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {im_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def process_mask(self, dataset_type, mask_path):\n",
    "        \"\"\"\n",
    "        Process mask from both dataset types with unified handling\n",
    "        Returns: (ground_truth_mask, validity_mask)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with rasterio.open(mask_path) as src:\n",
    "                arr_y = src.read(1)\n",
    "            \n",
    "            # Resize to target dimensions using nearest neighbor to preserve labels\n",
    "            arr_y = resize(arr_y, (self.img_size, self.img_size), order=0, preserve_range=True)\n",
    "            \n",
    "            if dataset_type == 'otsu':\n",
    "                # Otsu dataset: binary masks (0/1), all pixels are valid\n",
    "                ground_truth_mask = (arr_y > 0).astype(np.uint8)\n",
    "                validity_mask = np.ones_like(ground_truth_mask, dtype=np.uint8)  # All pixels valid\n",
    "                \n",
    "            elif dataset_type == 'sen1floods':\n",
    "                # Sen1Floods11 dataset: has invalid pixels (-1)\n",
    "                validity_mask = (arr_y != -1).astype(np.uint8)\n",
    "                ground_truth_mask = arr_y.copy()\n",
    "                ground_truth_mask[arr_y == -1] = 0  # Convert -1 to 0 for network compatibility\n",
    "                ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dataset type: {dataset_type}\")\n",
    "            \n",
    "            return ground_truth_mask, validity_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {dataset_type} mask {mask_path}: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def save_png(self, arr, save_path, mode='RGB'):\n",
    "        \"\"\"Save array as PNG image\"\"\"\n",
    "        img = Image.fromarray((arr * 255).astype(np.uint8), mode=mode)\n",
    "        img.save(save_path)\n",
    "\n",
    "    def save_npy(self, arr, save_path):\n",
    "        \"\"\"Save raw array data as NPY file for preserving exact values\"\"\"\n",
    "        np.save(save_path, arr)\n",
    "\n",
    "    def update_stats(self, split, dataset_type, ground_truth_mask, validity_mask):\n",
    "        \"\"\"Update dataset statistics\"\"\"\n",
    "        valid_pixels = validity_mask.astype(bool)\n",
    "        \n",
    "        self.stats[split]['count'] += 1\n",
    "        self.stats[split]['flood_pixels'] += ground_truth_mask[valid_pixels].sum()\n",
    "        self.stats[split]['total_valid_pixels'] += valid_pixels.sum()\n",
    "        self.stats[split]['invalid_pixels'] += (~valid_pixels).sum()\n",
    "        \n",
    "        if dataset_type == 'otsu':\n",
    "            self.stats[split]['otsu_count'] += 1\n",
    "        elif dataset_type == 'sen1floods':\n",
    "            self.stats[split]['sen1floods_count'] += 1\n",
    "\n",
    "    def process_unified_dataset(self, split_name, pairs):\n",
    "        \"\"\"Process a unified dataset split\"\"\"\n",
    "        print(f\"Processing unified {split_name} dataset...\")\n",
    "        output_dir = os.path.join(self.output_path, split_name)\n",
    "        \n",
    "        successful_count = 0\n",
    "        \n",
    "        for dataset_type, base_id, im_path, mask_path in tqdm(pairs, desc=f\"Processing {split_name}\"):\n",
    "            \n",
    "            if not os.path.exists(im_path) or not os.path.exists(mask_path):\n",
    "                print(f\"Warning: Files not found - {im_path} or {mask_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Process image (get both normalized data and visualization)\n",
    "            arr_x, arr_x_viz = self.process_image(im_path)\n",
    "            if arr_x is None:\n",
    "                print(f\"Failed to process image: {im_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Process mask with dataset-specific handling\n",
    "            result = self.process_mask(dataset_type, mask_path)\n",
    "            if result is None:\n",
    "                print(f\"Failed to process mask: {mask_path}\")\n",
    "                continue\n",
    "            \n",
    "            ground_truth_mask, validity_mask = result\n",
    "            \n",
    "            # Save visualization as PNG\n",
    "            img_save_path = os.path.join(output_dir, 'images', f'{split_name}_{successful_count:04d}.png')\n",
    "            self.save_png(arr_x_viz, img_save_path, mode='RGB')\n",
    "            \n",
    "            # Save raw normalized data for exact values\n",
    "            raw_save_path = os.path.join(output_dir, 'images', f'{split_name}_{successful_count:04d}.npy')\n",
    "            self.save_npy(arr_x, raw_save_path)\n",
    "            \n",
    "            # Save ground truth mask as PNG and NPY\n",
    "            mask_save_path = os.path.join(output_dir, 'masks', f'{split_name}_{successful_count:04d}.png')\n",
    "            self.save_png(ground_truth_mask, mask_save_path, mode='L')\n",
    "            mask_npy_path = os.path.join(output_dir, 'masks', f'{split_name}_{successful_count:04d}.npy')\n",
    "            self.save_npy(ground_truth_mask, mask_npy_path)\n",
    "            \n",
    "            # Save validity mask as PNG and NPY\n",
    "            validity_save_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{successful_count:04d}.png')\n",
    "            self.save_png(validity_mask, validity_save_path, mode='L')\n",
    "            validity_npy_path = os.path.join(output_dir, 'validity_masks', f'{split_name}_{successful_count:04d}.npy')\n",
    "            self.save_npy(validity_mask, validity_npy_path)\n",
    "            \n",
    "            # Update statistics\n",
    "            self.update_stats(split_name, dataset_type, ground_truth_mask, validity_mask)\n",
    "            \n",
    "            successful_count += 1\n",
    "        \n",
    "        print(f\"Successfully processed {successful_count} samples for {split_name}\")\n",
    "\n",
    "    def print_stats(self):\n",
    "        \"\"\"Print comprehensive dataset statistics\"\"\"\n",
    "        print(\"\\nUnified Dataset Statistics (Valid Pixels Only):\")\n",
    "        print(\"=\" * 80)\n",
    "        total_samples = sum(stat['count'] for stat in self.stats.values())\n",
    "        for split, stat in self.stats.items():\n",
    "            if stat['count'] > 0:\n",
    "                flood_percentage = 100 * stat['flood_pixels'] / stat['total_valid_pixels'] if stat['total_valid_pixels'] > 0 else 0\n",
    "                invalid_percentage = 100 * stat['invalid_pixels'] / (stat['total_valid_pixels'] + stat['invalid_pixels'])\n",
    "                split_percentage = 100 * stat['count'] / total_samples\n",
    "                \n",
    "                print(f\"{split.upper()} set: {stat['count']} samples ({split_percentage:.1f}%)\")\n",
    "                print(f\"  Dataset composition:\")\n",
    "                print(f\"    Otsu: {stat['otsu_count']} samples\")\n",
    "                print(f\"    Sen1Floods11: {stat['sen1floods_count']} samples\")\n",
    "                print(f\"  Pixel statistics:\")\n",
    "                print(f\"    Valid pixels: {stat['total_valid_pixels']:,} ({100-invalid_percentage:.1f}%)\")\n",
    "                print(f\"    Invalid pixels: {stat['invalid_pixels']:,} ({invalid_percentage:.1f}%)\")\n",
    "                print(f\"    Flood pixels (of valid): {stat['flood_pixels']:,} ({flood_percentage:.2f}%)\")\n",
    "                print()\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    def calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights to handle imbalance (only for valid pixels)\"\"\"\n",
    "        if self.stats['train']['total_valid_pixels'] > 0:\n",
    "            pos_ratio = self.stats['train']['flood_pixels'] / self.stats['train']['total_valid_pixels']\n",
    "            neg_ratio = 1 - pos_ratio\n",
    "            \n",
    "            # Class weights inversely proportional to class frequency\n",
    "            weight_non_flood = 1.0\n",
    "            weight_flood = neg_ratio / pos_ratio if pos_ratio > 0 else 1.0\n",
    "            \n",
    "            print(f\"\\nClass weights for handling imbalance (valid pixels only):\")\n",
    "            print(f\"Weight for non-flood (0): {weight_non_flood:.4f}\")\n",
    "            print(f\"Weight for flood (1): {weight_flood:.4f}\")\n",
    "            \n",
    "            return np.array([weight_non_flood, weight_flood])\n",
    "        return np.array([1.0, 1.0])\n",
    "\n",
    "    def save_unified_splits_info(self, splits):\n",
    "        \"\"\"Save information about the unified splits for reproducibility\"\"\"\n",
    "        splits_info = {}\n",
    "        dataset_info = {\n",
    "            'otsu_path': self.otsu_path,\n",
    "            'sen1floods_path': self.sen1floods_path,\n",
    "            'total_otsu_samples': 0,\n",
    "            'total_sen1floods_samples': 0\n",
    "        }\n",
    "        \n",
    "        for split_name, pairs in splits.items():\n",
    "            splits_info[split_name] = []\n",
    "            for dataset_type, base_id, im_path, mask_path in pairs:\n",
    "                splits_info[split_name].append({\n",
    "                    'dataset_type': dataset_type,\n",
    "                    'base_id': base_id,\n",
    "                    'image_path': im_path,\n",
    "                    'mask_path': mask_path\n",
    "                })\n",
    "                \n",
    "                if dataset_type == 'otsu':\n",
    "                    dataset_info['total_otsu_samples'] += 1\n",
    "                elif dataset_type == 'sen1floods':\n",
    "                    dataset_info['total_sen1floods_samples'] += 1\n",
    "        \n",
    "        unified_info = {\n",
    "            'dataset_info': dataset_info,\n",
    "            'split_config': {\n",
    "                'test_size': self.test_size,\n",
    "                'val_size': self.val_size,\n",
    "                'random_seed': self.random_seed\n",
    "            },\n",
    "            'splits': splits_info\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.output_path, 'unified_splits_info.json'), 'w') as f:\n",
    "            json.dump(unified_info, f, indent=2)\n",
    "        \n",
    "        print(f\"Unified splits information saved to: {os.path.join(self.output_path, 'unified_splits_info.json')}\")\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setting up Unified SAR Flood Dataset Preprocessing...\")\n",
    "    print(\"Combining S1F11-Otsu + Sen1Floods11 datasets\")\n",
    "    print(\"\\nBand Configuration:\")\n",
    "    print(\"Band 1: VV\")\n",
    "    print(\"Band 2: NewBand1 = (VH - VV) / (VH + VV)\")\n",
    "    print(\"Band 3: NewBand2 = sqrt((VH² + VV²) / 2)\")\n",
    "\n",
    "\n",
    "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
    "    otsu_path = \"/kaggle/input/s1f11-otsu\"  # Update this path\n",
    "    sen1floods_path = \"/kaggle/input/sen1floods11-essentials/v1.2\"  # Update this path\n",
    "    output_path = \"/kaggle/working/unified_preprocessed\"\n",
    "\n",
    "    # Initialize unified preprocessor\n",
    "    preprocessor = UnifiedSARFloodPreprocessor(\n",
    "        otsu_path=otsu_path,\n",
    "        sen1floods_path=sen1floods_path,\n",
    "        output_path=output_path,\n",
    "        test_size=0.2,  # 20% for test\n",
    "        val_size=0.2,   # 20% for validation\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    # Step 1: Get all dataset pairs\n",
    "    all_pairs = preprocessor.get_all_dataset_pairs()\n",
    "    \n",
    "    if len(all_pairs) == 0:\n",
    "        print(\"ERROR: No dataset pairs found! Please check the dataset paths.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Step 2: Create unified splits\n",
    "    splits = preprocessor.create_unified_splits(all_pairs)\n",
    "    \n",
    "    # Step 3: Save splits information for reproducibility\n",
    "    preprocessor.save_unified_splits_info(splits)\n",
    "\n",
    "    # Step 4: Calculate normalization parameters from combined training data\n",
    "    preprocessor.calculate_normalization_params(splits['train'])\n",
    "\n",
    "    print(\"\\nStarting unified dataset preprocessing with calculated normalization parameters...\")\n",
    "\n",
    "    # Step 5: Process all unified datasets\n",
    "    # Process train set\n",
    "    preprocessor.process_unified_dataset('train', splits['train'])\n",
    "\n",
    "    # Process validation set\n",
    "    preprocessor.process_unified_dataset('val', splits['val'])\n",
    "\n",
    "    # Process test set\n",
    "    preprocessor.process_unified_dataset('test', splits['test'])\n",
    "\n",
    "    # Print comprehensive statistics and calculate class weights\n",
    "    preprocessor.print_stats()\n",
    "    weights = preprocessor.calculate_class_weights()\n",
    "\n",
    "    # Save class weights for later use\n",
    "    weights_path = os.path.join(output_path, 'class_weights.npy')\n",
    "    np.save(weights_path, weights)\n",
    "    print(f\"\\nClass weights saved to: {weights_path}\")\n",
    "\n",
    "    print(f\"\\nUnified preprocessing complete! Processed data saved to: {output_path}\")\n",
    "    print(\"\\nOutput structure:\")\n",
    "    print(\"unified_preprocessed/\")\n",
    "    print(\"├── train/\")\n",
    "    print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "    print(\"│   ├── masks/ (PNG and NPY files - ground truth)\")\n",
    "    print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "    print(\"├── val/\")\n",
    "    print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "    print(\"│   ├── masks/ (PNG and NPY files - ground truth)\")\n",
    "    print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "    print(\"├── test/\")\n",
    "    print(\"│   ├── images/ (PNG and NPY files)\")\n",
    "    print(\"│   ├── masks/ (PNG and NPY files - ground truth)\")\n",
    "    print(\"│   └── validity_masks/ (PNG and NPY files - valid pixel indicators)\")\n",
    "    print(\"├── class_weights.npy\")\n",
    "    print(\"├── normalization_params.npy\")\n",
    "    print(\"└── unified_splits_info.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d35ea6-b7ca-44cf-b3c4-453b939387aa",
   "metadata": {},
   "source": [
    "## ResUnet Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6276bbc-0f78-4c4a-8118-54ac22c7c789",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import glob\n",
    "from tensorflow.keras import backend as K\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = \"/kaggle/working/unified_preprocessed\"  # Updated to use preprocessed data\n",
    "OUTPUT_PATH = \"/kaggle/working/united_SEN1FLOODS11\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Define helper functions for data loading with validity mask support\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load normalized image data from .npy file\"\"\"\n",
    "    # Convert tensor to string if needed\n",
    "    if isinstance(image_path, tf.Tensor):\n",
    "        image_path = image_path.numpy().decode('utf-8')\n",
    "    # Explicitly convert to float32\n",
    "    return np.load(image_path).astype(np.float32)\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Load mask from NPY file (preserves exact values)\"\"\"\n",
    "    # Convert tensor to string if needed\n",
    "    if isinstance(mask_path, tf.Tensor):\n",
    "        mask_path = mask_path.numpy().decode('utf-8')\n",
    "    mask = np.load(mask_path)\n",
    "    # Explicitly convert to float32\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "def load_validity_mask(validity_path):\n",
    "    \"\"\"Load validity mask from NPY file\"\"\"\n",
    "    # Convert tensor to string if needed\n",
    "    if isinstance(validity_path, tf.Tensor):\n",
    "        validity_path = validity_path.numpy().decode('utf-8')\n",
    "    validity_mask = np.load(validity_path)\n",
    "    # Explicitly convert to float32\n",
    "    return validity_mask.astype(np.float32)\n",
    "\n",
    "def augment_data(image, mask, validity_mask):\n",
    "    \"\"\"Apply data augmentation to image, mask, and validity mask\"\"\"\n",
    "    # Random horizontal flip\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "        validity_mask = tf.image.flip_left_right(validity_mask)\n",
    "    \n",
    "    # Random vertical flip\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        mask = tf.image.flip_up_down(mask)\n",
    "        validity_mask = tf.image.flip_up_down(validity_mask)\n",
    "    \n",
    "    # Random rotation (90, 180, 270 degrees)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        k = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int32)\n",
    "        image = tf.image.rot90(image, k=k)\n",
    "        mask = tf.image.rot90(mask, k=k)\n",
    "        validity_mask = tf.image.rot90(validity_mask, k=k)\n",
    "    \n",
    "    # Random brightness adjustment (only for image)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    \n",
    "    # Random contrast adjustment (only for image)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    \n",
    "    return image, mask, validity_mask\n",
    "\n",
    "def create_dataset(base_path, split, batch_size=16, shuffle=True, augment=False):\n",
    "    \"\"\"Create a TensorFlow dataset for the specified split with validity masks\"\"\"\n",
    "    img_paths = sorted(glob.glob(os.path.join(base_path, split, 'images', '*.npy')))\n",
    "    mask_paths = sorted(glob.glob(os.path.join(base_path, split, 'masks', '*.npy')))\n",
    "    validity_paths = sorted(glob.glob(os.path.join(base_path, split, 'validity_masks', '*.npy')))\n",
    "\n",
    "    if len(img_paths) == 0 or len(mask_paths) == 0 or len(validity_paths) == 0:\n",
    "        raise ValueError(f\"No images, masks, or validity masks found in {base_path}/{split}\")\n",
    "\n",
    "    print(f\"Found {len(img_paths)} images, {len(mask_paths)} masks, and {len(validity_paths)} validity masks for {split}\")\n",
    "\n",
    "    # Create datasets of paths\n",
    "    img_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
    "    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_paths)\n",
    "    validity_dataset = tf.data.Dataset.from_tensor_slices(validity_paths)\n",
    "\n",
    "    # Combine all paths\n",
    "    dataset = tf.data.Dataset.zip((img_dataset, mask_dataset, validity_dataset))\n",
    "\n",
    "    # Shuffle if needed\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(img_paths), seed=42)\n",
    "\n",
    "    # Map loading function to the dataset\n",
    "    dataset = dataset.map(\n",
    "        lambda img_path, mask_path, validity_path: (\n",
    "            tf.py_function(\n",
    "                func=load_image,\n",
    "                inp=[img_path],\n",
    "                Tout=tf.float32\n",
    "            ),\n",
    "            tf.py_function(\n",
    "                func=load_mask,\n",
    "                inp=[mask_path],\n",
    "                Tout=tf.float32\n",
    "            ),\n",
    "            tf.py_function(\n",
    "                func=load_validity_mask,\n",
    "                inp=[validity_path],\n",
    "                Tout=tf.float32\n",
    "            )\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Set shapes\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y, v: (\n",
    "            tf.ensure_shape(x, [256, 256, 3]),\n",
    "            tf.ensure_shape(y, [256, 256]),\n",
    "            tf.ensure_shape(v, [256, 256])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add channel dimension to masks\n",
    "    dataset = dataset.map(lambda x, y, v: (x, tf.expand_dims(y, axis=-1), tf.expand_dims(v, axis=-1)))\n",
    "\n",
    "    # Apply data augmentation for training set\n",
    "    if augment and split == 'train':\n",
    "        print(f\"Applying data augmentation to {split} dataset\")\n",
    "        dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Important: Add repeat to prevent dataset exhaustion\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, len(img_paths)\n",
    "\n",
    "def visualize_samples(dataset, num_samples=3):\n",
    "    \"\"\"Visualize random samples from the dataset with validity masks\"\"\"\n",
    "    plt.figure(figsize=(20, 5*num_samples))\n",
    "\n",
    "    for i, (images, masks, validity_masks) in enumerate(dataset.take(num_samples)):\n",
    "        for j in range(min(images.shape[0], 3)):\n",
    "            # Get image, mask, and validity mask\n",
    "            image = images[j].numpy()\n",
    "            mask = masks[j].numpy().squeeze()\n",
    "            validity_mask = validity_masks[j].numpy().squeeze()\n",
    "\n",
    "            # Normalize image for visualization (0-1 range)\n",
    "            image_viz = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "\n",
    "            # Display RGB channels\n",
    "            plt.subplot(num_samples, 5, i*5+1)\n",
    "            plt.imshow(image_viz[:, :, 0], cmap='gray')\n",
    "            plt.title(f\"VV Channel - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(num_samples, 5, i*5+2)\n",
    "            plt.imshow(image_viz[:, :, 1], cmap='gray')\n",
    "            plt.title(f\"NewBand1 - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(num_samples, 5, i*5+3)\n",
    "            plt.imshow(image_viz[:, :, 2], cmap='gray')\n",
    "            plt.title(f\"NewBand2 - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Display ground truth mask\n",
    "            plt.subplot(num_samples, 5, i*5+4)\n",
    "            plt.imshow(mask, cmap='Blues')\n",
    "            plt.title(f\"Ground Truth - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Display validity mask\n",
    "            plt.subplot(num_samples, 5, i*5+5)\n",
    "            plt.imshow(validity_mask, cmap='Reds')\n",
    "            plt.title(f\"Validity Mask - Sample {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'sample_visualization_with_validity.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Define MASKED custom metrics and loss functions that ignore invalid pixels\n",
    "def masked_dice_coefficient(y_true, y_pred, validity_mask, smooth=1e-6):\n",
    "    \"\"\"Calculate Dice coefficient only for valid pixels\"\"\"\n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    # Only consider valid pixels\n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f)\n",
    "    \n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_dice_loss(y_true_and_validity, y_pred):\n",
    "    \"\"\"Masked Dice loss function that ignores invalid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    return 1 - masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "def masked_focal_tversky_loss(y_true_and_validity, y_pred, alpha=0.7, beta=0.3, gamma=1.5, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Masked Focal Tversky Loss that ignores invalid pixels\n",
    "    \"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    # Flatten the inputs\n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    # Calculate true positives, false negatives, and false positives (only for valid pixels)\n",
    "    true_pos = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    false_neg = K.sum(y_true_f * (1 - y_pred_f) * validity_f)\n",
    "    false_pos = K.sum((1 - y_true_f) * y_pred_f * validity_f)\n",
    "    \n",
    "    # Calculate Tversky index\n",
    "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
    "    \n",
    "    # Apply focal parameter to focus on hard examples\n",
    "    focal_tversky = K.pow((1 - tversky), gamma)\n",
    "    \n",
    "    return focal_tversky\n",
    "\n",
    "def masked_iou_score(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate IoU score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f) - intersection\n",
    "    \n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_binary_accuracy(y_true_and_validity, y_pred):\n",
    "    \"\"\"Calculate binary accuracy only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    # Threshold predictions\n",
    "    y_pred_binary = K.cast(y_pred_masked > 0.5, K.floatx())\n",
    "    \n",
    "    # Calculate accuracy only for valid pixels\n",
    "    correct = K.cast(K.equal(y_true_masked, y_pred_binary), K.floatx()) * validity_mask\n",
    "    total_valid = K.sum(validity_mask)\n",
    "    \n",
    "    return K.sum(correct) / (total_valid + K.epsilon())\n",
    "\n",
    "def masked_f1_score_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate F1 score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    # Calculate precision and recall for valid pixels only\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    return f1\n",
    "\n",
    "def masked_precision_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate precision only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    return precision\n",
    "\n",
    "def masked_recall_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate recall only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    # Apply validity mask\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "    return recall\n",
    "\n",
    "# Wrapper functions to use with compile (need specific names)\n",
    "def masked_dice_coefficient_metric(y_true_and_validity, y_pred):\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    return masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "# Define ResUNet model architecture (unchanged)\n",
    "def conv_block(inputs, filters, kernel_size=3, strides=1, padding='same'):\n",
    "    \"\"\"Convolutional block with batch normalization and activation\"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def channel_attention(inputs, ratio=16):\n",
    "    \"\"\"Squeeze and Excitation Block for channel attention\"\"\"\n",
    "    channels = int(inputs.shape[-1])\n",
    "    reduced_channels = max(channels // ratio, 8)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = layers.Reshape((1, 1, channels))(x)\n",
    "    x = layers.Conv2D(reduced_channels, kernel_size=1, activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    output = layers.Multiply()([inputs, x])\n",
    "    return output\n",
    "\n",
    "def spatial_attention(inputs):\n",
    "    \"\"\"Spatial attention module\"\"\"\n",
    "    avg_pool = layers.Conv2D(1, kernel_size=1, padding='same', use_bias=False, \n",
    "                            kernel_initializer='ones')(inputs)\n",
    "    max_features = layers.Conv2D(1, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_features])\n",
    "    attention_map = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "    output = layers.Multiply()([inputs, attention_map])\n",
    "    return output\n",
    "\n",
    "def attention_residual_block(inputs, filters, kernel_size=3, strides=1):\n",
    "    \"\"\"Residual block with channel and spatial attention\"\"\"\n",
    "    x = conv_block(inputs, filters, kernel_size, strides)\n",
    "    x = conv_block(x, filters, kernel_size, 1)\n",
    "    x = channel_attention(x)\n",
    "    x = spatial_attention(x)\n",
    "    \n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_attention_resunet(input_shape=(256, 256, 3), num_classes=1):\n",
    "    \"\"\"Build ResUNet model with attention mechanisms\"\"\"\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    x = conv_block(inputs, 64, kernel_size=7, strides=1)\n",
    "\n",
    "    # Encoder blocks\n",
    "    skip1 = attention_residual_block(x, 64)\n",
    "    x = layers.MaxPooling2D(2)(skip1)\n",
    "\n",
    "    skip2 = attention_residual_block(x, 128)\n",
    "    x = layers.MaxPooling2D(2)(skip2)\n",
    "\n",
    "    skip3 = attention_residual_block(x, 256)\n",
    "    x = layers.MaxPooling2D(2)(skip3)\n",
    "\n",
    "    # Bridge\n",
    "    x = attention_residual_block(x, 512)\n",
    "\n",
    "    # Decoder blocks\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = conv_block(x, 256)\n",
    "    x = layers.Concatenate()([x, skip3])\n",
    "    x = attention_residual_block(x, 256)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = layers.Concatenate()([x, skip2])\n",
    "    x = attention_residual_block(x, 128)\n",
    "\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = conv_block(x, 64)\n",
    "    x = layers.Concatenate()([x, skip1])\n",
    "    x = attention_residual_block(x, 64)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(num_classes, kernel_size=1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Cosine Annealing Learning Rate Classes (unchanged from original)\n",
    "class CosineAnnealingCallback(callbacks.Callback):\n",
    "    \"\"\"Custom Cosine Annealing Learning Rate Callback with visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_lr, min_lr, T_max, verbose=1):\n",
    "        super(CosineAnnealingCallback, self).__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.T_max = T_max\n",
    "        self.verbose = verbose\n",
    "        self.learning_rates = []\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.min_lr + (self.initial_lr - self.min_lr) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
    "        \n",
    "        if hasattr(self.model.optimizer, 'learning_rate'):\n",
    "            if hasattr(self.model.optimizer.learning_rate, 'assign'):\n",
    "                self.model.optimizer.learning_rate.assign(lr)\n",
    "            else:\n",
    "                self.model.optimizer.learning_rate = lr\n",
    "        else:\n",
    "            self.model.optimizer.lr = lr\n",
    "            \n",
    "        self.learning_rates.append(lr)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(f\"Epoch {epoch + 1}: Learning rate = {lr:.6f}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(self.learning_rates) + 1), self.learning_rates)\n",
    "        plt.title('Cosine Annealing Learning Rate Schedule')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'cosine_annealing_lr_schedule.png'))\n",
    "        plt.show()\n",
    "\n",
    "def cosine_annealing_warm_restarts(epoch, initial_lr=0.001, min_lr=1e-6, T_0=50, T_mult=2):\n",
    "    \"\"\"Cosine annealing with warm restarts function for LearningRateScheduler\"\"\"\n",
    "    T_cur = epoch\n",
    "    T_i = T_0\n",
    "    \n",
    "    while T_cur >= T_i:\n",
    "        T_cur -= T_i\n",
    "        T_i *= T_mult\n",
    "    \n",
    "    lr = min_lr + (initial_lr - min_lr) * (1 + math.cos(math.pi * T_cur / T_i)) / 2\n",
    "    return lr\n",
    "\n",
    "def plot_history(history, lr_schedule_type=\"cosine_annealing\"):\n",
    "    \"\"\"Plot comprehensive training history with all metrics including learning rate\"\"\"\n",
    "    plt.figure(figsize=(20, 18))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Masked Loss (Invalid Pixels Excluded)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot Dice coefficient\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plt.plot(history.history['masked_dice_coefficient_metric'], label='Training Dice')\n",
    "    plt.plot(history.history['val_masked_dice_coefficient_metric'], label='Validation Dice')\n",
    "    plt.title('Masked Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot IoU\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plt.plot(history.history['masked_iou_score'], label='Training IoU')\n",
    "    plt.plot(history.history['val_masked_iou_score'], label='Validation IoU')\n",
    "    plt.title('Masked IoU Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot binary accuracy\n",
    "    plt.subplot(3, 3, 4)\n",
    "    plt.plot(history.history['masked_binary_accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_masked_binary_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Masked Binary Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.subplot(3, 3, 5)\n",
    "    plt.plot(history.history['masked_f1_score_metric'], label='Training F1')\n",
    "    plt.plot(history.history['val_masked_f1_score_metric'], label='Validation F1')\n",
    "    plt.title('Masked F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot Precision and Recall\n",
    "    plt.subplot(3, 3, 6)\n",
    "    plt.plot(history.history['masked_precision_metric'], label='Training Precision')\n",
    "    plt.plot(history.history['val_masked_precision_metric'], label='Validation Precision')\n",
    "    plt.plot(history.history['masked_recall_metric'], label='Training Recall')\n",
    "    plt.plot(history.history['val_masked_recall_metric'], label='Validation Recall')\n",
    "    plt.title('Masked Precision and Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Plot Learning Rate\n",
    "    plt.subplot(3, 3, 7)\n",
    "    if 'lr' in history.history:\n",
    "        plt.plot(history.history['lr'], label='Learning Rate', color='red')\n",
    "        plt.title(f'Learning Rate Schedule ({lr_schedule_type})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.yscale('log')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Learning Rate\\nNot Available', \n",
    "                horizontalalignment='center', verticalalignment='center', \n",
    "                transform=plt.gca().transAxes, fontsize=12)\n",
    "        plt.title('Learning Rate Schedule')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, f'training_history_{lr_schedule_type}_masked.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, dataset, num_samples=5):\n",
    "    \"\"\"Visualize model predictions with complete validity mask information\"\"\"\n",
    "    plt.figure(figsize=(30, 6*num_samples))\n",
    "\n",
    "    sample_count = 0\n",
    "    for images, combined_masks in dataset:\n",
    "        if sample_count >= num_samples:\n",
    "            break\n",
    "\n",
    "        # Get predictions\n",
    "        preds = model.predict(images, verbose=0)\n",
    "\n",
    "        for j in range(min(images.shape[0], num_samples - sample_count)):\n",
    "            # Get image, masks, and prediction\n",
    "            image = images[j].numpy()\n",
    "            gt_mask = combined_masks[j, ..., 0].numpy()  # Ground truth\n",
    "            validity_mask = combined_masks[j, ..., 1].numpy()  # Validity mask\n",
    "            pred = preds[j].squeeze()\n",
    "\n",
    "            # Normalize image for visualization\n",
    "            image_viz = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "\n",
    "            # Create RGB composite\n",
    "            rgb_viz = np.stack([\n",
    "                image_viz[:, :, 0],  # VV as R\n",
    "                image_viz[:, :, 1],  # NewBand1 as G\n",
    "                image_viz[:, :, 2]   # NewBand2 as B\n",
    "            ], axis=-1)\n",
    "            rgb_viz = np.clip(rgb_viz, 0, 1)\n",
    "\n",
    "            # Calculate masked metrics for this sample (only valid pixels)\n",
    "            valid_pixels = validity_mask > 0.5\n",
    "            invalid_pixels = validity_mask <= 0.5\n",
    "            \n",
    "            if np.sum(valid_pixels) > 0:\n",
    "                gt_valid = gt_mask[valid_pixels]\n",
    "                pred_valid = pred[valid_pixels]\n",
    "                pred_binary_valid = (pred_valid > 0.5).astype(np.float32)\n",
    "                gt_binary_valid = (gt_valid > 0.5).astype(np.float32)\n",
    "                \n",
    "                dice = np.sum(2 * gt_binary_valid * pred_binary_valid) / (np.sum(gt_binary_valid) + np.sum(pred_binary_valid) + 1e-8)\n",
    "                intersection = np.sum(gt_binary_valid * pred_binary_valid)\n",
    "                union = np.sum(gt_binary_valid) + np.sum(pred_binary_valid) - intersection\n",
    "                iou = intersection / (union + 1e-8)\n",
    "            else:\n",
    "                dice = iou = 0.0\n",
    "\n",
    "            valid_percentage = 100 * np.sum(valid_pixels) / valid_pixels.size\n",
    "            invalid_percentage = 100 * np.sum(invalid_pixels) / invalid_pixels.size\n",
    "\n",
    "            row = sample_count\n",
    "            \n",
    "            # 1. Original SAR composite\n",
    "            plt.subplot(num_samples, 6, row * 6 + 1)\n",
    "            plt.imshow(rgb_viz)\n",
    "            plt.title(f'Sample {sample_count+1}\\nSAR Composite\\n(VV, NewBand1, NewBand2)')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 2. Ground truth with invalid areas grayed out\n",
    "            plt.subplot(num_samples, 6, row * 6 + 2)\n",
    "            gt_display = np.ones_like(gt_mask) * 0.5  # Gray for invalid areas\n",
    "            gt_display[valid_pixels] = gt_mask[valid_pixels]  # Valid GT values\n",
    "            plt.imshow(gt_display, cmap='Blues', vmin=0, vmax=1)\n",
    "            plt.title(f'Ground Truth\\n(Gray = Invalid)\\nValid: {valid_percentage:.1f}%')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 3. Validity mask\n",
    "            plt.subplot(num_samples, 6, row * 6 + 3)\n",
    "            plt.imshow(validity_mask, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "            plt.title(f'Validity Mask\\n(Red = Invalid: {invalid_percentage:.1f}%)\\n(Green = Valid: {valid_percentage:.1f}%)')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 4. Model prediction (all pixels)\n",
    "            plt.subplot(num_samples, 6, row * 6 + 4)\n",
    "            plt.imshow(pred, cmap='Blues', vmin=0, vmax=1)\n",
    "            plt.title(f'Model Prediction\\n(All pixels)')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 5. Masked prediction (only valid areas shown)\n",
    "            plt.subplot(num_samples, 6, row * 6 + 5)\n",
    "            pred_masked = pred.copy()\n",
    "            pred_masked[invalid_pixels] = 0.5  # Gray out invalid areas\n",
    "            plt.imshow(pred_masked, cmap='Blues', vmin=0, vmax=1)\n",
    "            plt.title(f'Masked Prediction\\n(Only valid areas)')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # 6. Error map (only for valid pixels)\n",
    "            plt.subplot(num_samples, 6, row * 6 + 6)\n",
    "            error = np.abs(gt_mask - pred) * validity_mask\n",
    "            error[invalid_pixels] = 0  # No error contribution from invalid pixels\n",
    "            plt.imshow(error, cmap='Reds', vmin=0, vmax=1)\n",
    "            plt.title(f'Error Map (Valid Only)\\nDice: {dice:.3f}, IoU: {iou:.3f}\\nNo invalid pixel bias!')\n",
    "            plt.axis('off')\n",
    "\n",
    "            sample_count += 1\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "        \n",
    "        if sample_count >= num_samples:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'masked_predictions_with_validity.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ==================== MAIN EXECUTION WITH MASKED LOSS ====================\n",
    "\n",
    "# Configuration for Cosine Annealing\n",
    "COSINE_ANNEALING_CONFIG = {\n",
    "    \"method\": \"warm_restarts_scheduler\",\n",
    "    \"initial_lr\": 0.0005,\n",
    "    \"min_lr\": 5e-7,\n",
    "    \"T_max\": 200,\n",
    "    \"T_0\": 50,\n",
    "    \"T_mult\": 2,\n",
    "}\n",
    "\n",
    "print(f\"Using Cosine Annealing method: {COSINE_ANNEALING_CONFIG['method']}\")\n",
    "print(\"🔧 TRAINING WITH MASKED LOSS AND METRICS\")\n",
    "print(\"✅ Invalid ground truth pixels (-1) will be COMPLETELY EXCLUDED from:\")\n",
    "print(\"   • Loss calculation\")\n",
    "print(\"   • All metric calculations\")\n",
    "print(\"   • Model learning\")\n",
    "\n",
    "# Use a batch size that fits in GPU memory\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "# Create datasets with validity masks\n",
    "print(\"Creating datasets with validity mask support...\")\n",
    "train_dataset, train_size = create_dataset(BASE_PATH, 'train', batch_size=BATCH_SIZE, augment=True)\n",
    "val_dataset, val_size = create_dataset(BASE_PATH, 'val', batch_size=BATCH_SIZE, augment=False)\n",
    "test_dataset, test_size = create_dataset(BASE_PATH, 'test', batch_size=BATCH_SIZE, augment=False)\n",
    "\n",
    "print(f\"Training dataset size: {train_size} images\")\n",
    "print(f\"Validation dataset size: {val_size} images\")\n",
    "print(f\"Test dataset size: {test_size} images\")\n",
    "\n",
    "# Visualize some samples with validity masks\n",
    "visualize_samples(train_dataset, num_samples=2)\n",
    "\n",
    "# Build model\n",
    "input_shape = (256, 256, 3)\n",
    "model = build_attention_resunet(input_shape)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = max(1, train_size // BATCH_SIZE)\n",
    "validation_steps = max(1, val_size // BATCH_SIZE)\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "\n",
    "# Setup cosine annealing\n",
    "method = COSINE_ANNEALING_CONFIG[\"method\"]\n",
    "initial_lr = COSINE_ANNEALING_CONFIG[\"initial_lr\"]\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=initial_lr)\n",
    "lr_schedule_func = lambda epoch: cosine_annealing_warm_restarts(\n",
    "    epoch,\n",
    "    initial_lr=initial_lr,\n",
    "    min_lr=COSINE_ANNEALING_CONFIG[\"min_lr\"],\n",
    "    T_0=COSINE_ANNEALING_CONFIG[\"T_0\"],\n",
    "    T_mult=COSINE_ANNEALING_CONFIG[\"T_mult\"]\n",
    ")\n",
    "lr_callback = callbacks.LearningRateScheduler(lr_schedule_func, verbose=1)\n",
    "\n",
    "print(f\" Successfully configured cosine annealing method: {method}\")\n",
    "\n",
    "# Custom data preparation function to combine ground truth and validity masks\n",
    "def prepare_labels_for_training(dataset):\n",
    "    \"\"\"Prepare dataset to combine ground truth and validity masks for masked loss\"\"\"\n",
    "    def combine_masks(image, gt_mask, validity_mask):\n",
    "        # Combine ground truth and validity masks into a single tensor\n",
    "        combined_mask = tf.concat([gt_mask, validity_mask], axis=-1)\n",
    "        return image, combined_mask\n",
    "    \n",
    "    return dataset.map(combine_masks)\n",
    "\n",
    "# Prepare datasets for training with combined masks\n",
    "print(\"Preparing datasets for masked training...\")\n",
    "train_dataset_prepared = prepare_labels_for_training(train_dataset)\n",
    "val_dataset_prepared = prepare_labels_for_training(val_dataset)\n",
    "test_dataset_prepared = prepare_labels_for_training(test_dataset)\n",
    "\n",
    "# Compile model with masked loss and metrics\n",
    "print(\"Compiling model with MASKED loss and metrics...\")\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=masked_focal_tversky_loss,  # Masked loss that ignores invalid pixels\n",
    "    metrics=[\n",
    "        masked_dice_coefficient_metric,\n",
    "        masked_iou_score,\n",
    "        masked_binary_accuracy,\n",
    "        masked_f1_score_metric,\n",
    "        masked_precision_metric,\n",
    "        masked_recall_metric\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_path = os.path.join(OUTPUT_PATH, \"best_model_masked_cosine_annealing.keras\")\n",
    "log_dir = os.path.join(OUTPUT_PATH, \"logs_masked_cosine_annealing\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_masked_iou_score',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_masked_iou_score',\n",
    "        patience=70,\n",
    "        restore_best_weights=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        profile_batch=0\n",
    "    ),\n",
    "    callbacks.CSVLogger(\n",
    "        os.path.join(OUTPUT_PATH, f'training_log_masked_cosine_{method}.csv'),\n",
    "        separator=',',\n",
    "        append=False\n",
    "    ),\n",
    "    lr_callback\n",
    "]\n",
    "\n",
    "print(f\"Training with {method} cosine annealing and MASKED loss/metrics...\")\n",
    "print(f\"Initial LR: {initial_lr}, Min LR: {COSINE_ANNEALING_CONFIG['min_lr']}\")\n",
    "\n",
    "# Train model with masked datasets\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_dataset_prepared,\n",
    "    validation_data=val_dataset_prepared,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plot_history(history, lr_schedule_type=f\"masked_cosine_{method}\")\n",
    "\n",
    "# Load best model\n",
    "best_model = models.load_model(checkpoint_path, custom_objects={\n",
    "    'masked_dice_coefficient_metric': masked_dice_coefficient_metric,\n",
    "    'masked_focal_tversky_loss': masked_focal_tversky_loss,\n",
    "    'masked_iou_score': masked_iou_score,\n",
    "    'masked_binary_accuracy': masked_binary_accuracy,\n",
    "    'masked_f1_score_metric': masked_f1_score_metric,\n",
    "    'masked_precision_metric': masked_precision_metric,\n",
    "    'masked_recall_metric': masked_recall_metric\n",
    "})\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set with MASKED metrics...\")\n",
    "test_steps = max(1, test_size // BATCH_SIZE)\n",
    "test_results = best_model.evaluate(test_dataset_prepared, steps=test_steps)\n",
    "print(\"\\nTest Results (Invalid pixels excluded):\")\n",
    "for metric_name, value in zip(best_model.metrics_names, test_results):\n",
    "    print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "# Save test results\n",
    "test_metrics = {metric_name: float(value) for metric_name, value in zip(best_model.metrics_names, test_results)}\n",
    "test_metrics['cosine_annealing_method'] = method\n",
    "test_metrics['cosine_annealing_config'] = COSINE_ANNEALING_CONFIG\n",
    "test_metrics['masked_training'] = True\n",
    "\n",
    "with open(os.path.join(OUTPUT_PATH, f'test_metrics_masked_cosine_{method}.json'), 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=4)\n",
    "print(\"Test metrics saved to JSON file\")\n",
    "\n",
    "def training_consistent_masked_iou_score_eval(combined_masks, y_pred, threshold=0.5, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate IoU using the EXACT same method as during training for consistency\n",
    "    \"\"\"\n",
    "    # Extract masks\n",
    "    y_true = combined_masks[..., 0:1]  # Ground truth\n",
    "    validity_mask = combined_masks[..., 1:2]  # Validity mask\n",
    "    \n",
    "    # Apply threshold to predictions (convert to binary)\n",
    "    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)\n",
    "    y_true_binary = tf.cast(y_true > threshold, tf.float32)\n",
    "    \n",
    "    # Apply validity mask - COMPLETELY exclude invalid pixels\n",
    "    y_true_masked = y_true_binary * validity_mask\n",
    "    y_pred_masked = y_pred_binary * validity_mask\n",
    "    \n",
    "    # Flatten (same as training)\n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    # Calculate intersection and union ONLY for valid pixels\n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f) - intersection\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "def calculate_masked_metrics(model, dataset, num_batches=None, threshold=0.5):\n",
    "    \"\"\"\n",
    "    FIXED: Calculate comprehensive metrics using TRAINING-CONSISTENT methods\n",
    "    Ensures COMPLETE exclusion of invalid pixels (-1) from all calculations\n",
    "    \"\"\"\n",
    "    print(f\"\\n COMPREHENSIVE MASKED EVALUATION (TRAINING-CONSISTENT)\")\n",
    "    print(f\" Invalid pixels (-1) COMPLETELY EXCLUDED from ALL calculations\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Collect data using training-consistent methods\n",
    "    training_consistent_ious = []  # Per-batch IoU (matches training exactly)\n",
    "    all_y_true_valid = []\n",
    "    all_y_pred_valid = []\n",
    "    image_metrics = []\n",
    "    total_valid_pixels = 0\n",
    "    total_invalid_pixels = 0\n",
    "    \n",
    "    batch_count = 0\n",
    "    \n",
    "    for images, combined_masks in dataset:\n",
    "        if num_batches is not None and batch_count >= num_batches:\n",
    "            break\n",
    "            \n",
    "        batch_count += 1\n",
    "        print(f\"Processing batch {batch_count}...\")\n",
    "        \n",
    "        # Get predictions\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        \n",
    "        # METHOD 1: Calculate IoU the SAME way as training (per-batch)\n",
    "        batch_iou = training_consistent_masked_iou_score_eval(combined_masks, preds, threshold)\n",
    "        training_consistent_ious.append(float(batch_iou))\n",
    "        \n",
    "        # METHOD 2: Process individual images for detailed metrics\n",
    "        gt_masks = combined_masks[..., 0]  # Ground truth\n",
    "        validity_masks = combined_masks[..., 1]  # Validity mask\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            gt_mask = gt_masks[i].numpy()\n",
    "            pred = preds[i].squeeze()\n",
    "            validity_mask = validity_masks[i].numpy()\n",
    "            \n",
    "            # Count pixels\n",
    "            valid_pixels_mask = validity_mask > 0.5\n",
    "            invalid_pixels_mask = validity_mask <= 0.5\n",
    "            \n",
    "            num_valid = np.sum(valid_pixels_mask)\n",
    "            num_invalid = np.sum(invalid_pixels_mask)\n",
    "            \n",
    "            total_valid_pixels += num_valid\n",
    "            total_invalid_pixels += num_invalid\n",
    "            \n",
    "            if num_valid == 0:\n",
    "                print(f\"Warning: Image {i} has no valid pixels, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Extract ONLY valid pixels\n",
    "            gt_valid = gt_mask[valid_pixels_mask]\n",
    "            pred_valid = pred[valid_pixels_mask]\n",
    "            \n",
    "            # Apply threshold\n",
    "            pred_binary = (pred_valid > threshold).astype(np.int32)\n",
    "            gt_binary = (gt_valid > threshold).astype(np.int32)\n",
    "            \n",
    "            # Add to overall collection\n",
    "            all_y_true_valid.extend(gt_binary)\n",
    "            all_y_pred_valid.extend(pred_binary)\n",
    "            \n",
    "            # Calculate per-image metrics\n",
    "            intersection = np.sum(gt_binary * pred_binary)\n",
    "            union = np.sum(gt_binary) + np.sum(pred_binary) - intersection\n",
    "            \n",
    "            img_iou = (intersection + 1e-8) / (union + 1e-8)\n",
    "            img_dice = (2 * intersection + 1e-8) / (np.sum(gt_binary) + np.sum(pred_binary) + 1e-8)\n",
    "            \n",
    "            # Confusion matrix for valid pixels only\n",
    "            try:\n",
    "                cm = confusion_matrix(gt_binary, pred_binary, labels=[0, 1])\n",
    "                if cm.shape == (2, 2):\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                else:\n",
    "                    tn = fp = fn = tp = 0\n",
    "            except:\n",
    "                tn = fp = fn = tp = 0\n",
    "            \n",
    "            # Per-image metrics\n",
    "            img_precision = tp / (tp + fp + 1e-8)\n",
    "            img_recall = tp / (tp + fn + 1e-8)\n",
    "            img_f1 = 2 * (img_precision * img_recall) / (img_precision + img_recall + 1e-8)\n",
    "            img_accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n",
    "            \n",
    "            image_metrics.append({\n",
    "                'iou': img_iou,\n",
    "                'dice': img_dice,\n",
    "                'precision': img_precision,\n",
    "                'recall': img_recall,\n",
    "                'f1': img_f1,\n",
    "                'accuracy': img_accuracy,\n",
    "                'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn),\n",
    "                'valid_pixels': int(num_valid),\n",
    "                'invalid_pixels': int(num_invalid),\n",
    "                'valid_percentage': 100 * num_valid / (num_valid + num_invalid)\n",
    "            })\n",
    "    \n",
    "    if len(all_y_true_valid) == 0:\n",
    "        print(\" No valid pixels found!\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\n PIXEL STATISTICS:\")\n",
    "    print(f\"Total valid pixels: {total_valid_pixels:,}\")\n",
    "    print(f\"Total invalid pixels: {total_invalid_pixels:,}\")\n",
    "    total_pixels = total_valid_pixels + total_invalid_pixels\n",
    "    print(f\"Valid pixel percentage: {100 * total_valid_pixels / total_pixels:.2f}%\")\n",
    "    print(f\"Invalid pixel percentage: {100 * total_invalid_pixels / total_pixels:.2f}%\")\n",
    "    \n",
    "    # Calculate overall metrics from ALL valid pixels\n",
    "    try:\n",
    "        cm = confusion_matrix(all_y_true_valid, all_y_pred_valid, labels=[0, 1])\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        else:\n",
    "            print(\"Warning: Unusual confusion matrix shape\")\n",
    "            tp = fp = fn = tn = 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error in confusion matrix: {e}\")\n",
    "        tp = fp = fn = tn = 0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "    \n",
    "    # IoU from confusion matrix\n",
    "    intersection_cm = tp\n",
    "    union_cm = tp + fp + fn\n",
    "    iou_from_cm = intersection_cm / (union_cm + 1e-8)\n",
    "    \n",
    "    # TRAINING-CONSISTENT IoU (this should match your validation IoU during training)\n",
    "    training_consistent_iou = np.mean(training_consistent_ious)\n",
    "    \n",
    "    # Per-image averages\n",
    "    mean_dice = np.mean([m['dice'] for m in image_metrics]) if image_metrics else 0.0\n",
    "    mean_iou_per_image = np.mean([m['iou'] for m in image_metrics]) if image_metrics else 0.0\n",
    "    \n",
    "    print(f\"\\n======== COMPLETE Masked Metrics (Valid Pixels Only) ========\")\n",
    "    print(f\" TRAINING-CONSISTENT IoU: {training_consistent_iou:.4f} <- Should match validation IoU!\")\n",
    "    print(f\"\")\n",
    "    print(f\"Overall Metrics (pixel-level):\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall/Sensitivity: {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"IoU: {iou_from_cm:.4f}\")\n",
    "    print(f\"Dice Coefficient: {(2 * tp) / (2 * tp + fp + fn + 1e-8):.4f}\")\n",
    "    \n",
    "    print(f\"\\nMean Per-Image Metrics:\")\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou_per_image:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix (Valid Pixels Only):\")\n",
    "    print(f\"True Positives: {tp:,}\")\n",
    "    print(f\"False Positives: {fp:,}\")\n",
    "    print(f\"True Negatives: {tn:,}\")\n",
    "    print(f\"False Negatives: {fn:,}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    bg_precision = tn / (tn + fn + 1e-8)\n",
    "    bg_recall = tn / (tn + fp + 1e-8)\n",
    "    bg_f1 = 2 * (bg_precision * bg_recall) / (bg_precision + bg_recall + 1e-8)\n",
    "    \n",
    "    print(f\"\\nPer-Class Metrics:\")\n",
    "    print(f\"Background - Precision: {bg_precision:.4f}, Recall: {bg_recall:.4f}, F1: {bg_f1:.4f}\")\n",
    "    print(f\"Flood - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    if image_metrics:\n",
    "        img_metrics_df = pd.DataFrame(image_metrics)\n",
    "        img_metrics_df.to_csv(os.path.join(OUTPUT_PATH, 'per_image_metrics_FIXED_COMPLETE.csv'), index_label='image_id')\n",
    "        print(f\"\\n Per-image metrics saved to CSV file\")\n",
    "    \n",
    "    return {\n",
    "        'overall': {\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'specificity': float(specificity),\n",
    "            'f1': float(f1),\n",
    "            'iou_training_consistent': float(training_consistent_iou),  # KEY METRIC!\n",
    "            'iou_confusion_matrix': float(iou_from_cm),\n",
    "            'dice': float((2 * tp) / (2 * tp + fp + fn + 1e-8))\n",
    "        },\n",
    "        'per_image_mean': {\n",
    "            'dice': float(mean_dice),\n",
    "            'iou': float(mean_iou_per_image)\n",
    "        },\n",
    "        'confusion_matrix': {\n",
    "            'tn': int(tn), 'fp': int(fp), 'fn': int(fn), 'tp': int(tp)\n",
    "        },\n",
    "        'per_class': {\n",
    "            'background': {'precision': float(bg_precision), 'recall': float(bg_recall), 'f1': float(bg_f1)},\n",
    "            'flood': {'precision': float(precision), 'recall': float(recall), 'f1': float(f1)}\n",
    "        },\n",
    "        'pixel_statistics': {\n",
    "            'total_valid_pixels': int(total_valid_pixels),\n",
    "            'total_invalid_pixels': int(total_invalid_pixels),\n",
    "            'valid_percentage': float(100 * total_valid_pixels / total_pixels),\n",
    "            'invalid_percentage': float(100 * total_invalid_pixels / total_pixels)\n",
    "        },\n",
    "        'evaluation_info': {\n",
    "            'num_images_evaluated': len(image_metrics),\n",
    "            'num_batches_processed': len(training_consistent_ious),\n",
    "            'threshold_used': threshold,\n",
    "            'completely_masked': True\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Visualize predictions with validity masks\n",
    "print(\"\\n  VISUALIZING PREDICTIONS WITH VALIDITY MASKS...\")\n",
    "try:\n",
    "    # Try with prepared dataset first\n",
    "    visualize_predictions(best_model, test_dataset_prepared, num_samples=5)\n",
    "except Exception as e:\n",
    "    print(f\"  Error with prepared dataset: {e}\")\n",
    "    print(\" Trying with original dataset format...\")\n",
    "    try:\n",
    "        visualize_predictions(best_model, test_dataset, num_samples=5)\n",
    "    except Exception as e2:\n",
    "        print(f\" Error with original dataset: {e2}\")\n",
    "        print(\"Skipping visualization...\")\n",
    "\n",
    "# Calculate comprehensive masked metrics on test set (limit to a reasonable number of batches)\n",
    "# Calculate comprehensive masked metrics on test set (limit to a reasonable number of batches)\n",
    "test_batches_for_eval = min(10, test_size // BATCH_SIZE)\n",
    "print(f\"\\nCalculating detailed masked metrics on {test_batches_for_eval} test batches...\")\n",
    "detailed_metrics = calculate_masked_metrics(best_model, test_dataset_prepared, num_batches=test_batches_for_eval)\n",
    "\n",
    "# Add training configuration to detailed metrics\n",
    "if detailed_metrics:\n",
    "    detailed_metrics['training_config'] = {\n",
    "        'masked_training': True,\n",
    "        'cosine_annealing_method': method,\n",
    "        'cosine_annealing_params': COSINE_ANNEALING_CONFIG,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'invalid_pixels_excluded': True\n",
    "    }\n",
    "\n",
    "    # Save detailed metrics to file\n",
    "    with open(os.path.join(OUTPUT_PATH, f'detailed_masked_metrics_cosine_{method}.json'), 'w') as f:\n",
    "        json.dump(detailed_metrics, f, indent=4)\n",
    "\n",
    "    print(\"Detailed masked metrics saved!\")\n",
    "else:\n",
    "    print(\" Could not calculate detailed metrics - no valid data found!\")\n",
    "\n",
    "# Save model\n",
    "best_model.save(os.path.join(OUTPUT_PATH, f'flood_resunet_model_masked_cosine_{method}.keras'))\n",
    "\n",
    "print(\"Model and metrics saved!\")\n",
    "print(f\"All outputs are saved to: {OUTPUT_PATH}\")\n",
    "print(f\"Cosine Annealing method used: {method}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MASKED TRAINING COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a8e27-60cd-460a-a852-dfab776ef793",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d480268-e20b-4606-a5c5-1665340afcd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Unified Dataset Inference Script\n",
    "# Tests trained model on 10 samples each from Otsu and Sen1Floods11 datasets\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "\n",
    "# ==================== DEFINE SAME CUSTOM FUNCTIONS AS TRAINING ====================\n",
    "\n",
    "def masked_dice_coefficient(y_true, y_pred, validity_mask, smooth=1e-6):\n",
    "    \"\"\"Calculate Dice coefficient only for valid pixels\"\"\"\n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f)\n",
    "    \n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_dice_loss(y_true_and_validity, y_pred):\n",
    "    \"\"\"Masked Dice loss function that ignores invalid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    return 1 - masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "def masked_focal_tversky_loss(y_true_and_validity, y_pred, alpha=0.7, beta=0.3, gamma=1.5, smooth=1e-6):\n",
    "    \"\"\"Masked Focal Tversky Loss that ignores invalid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    true_pos = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    false_neg = K.sum(y_true_f * (1 - y_pred_f) * validity_f)\n",
    "    false_pos = K.sum((1 - y_true_f) * y_pred_f * validity_f)\n",
    "    \n",
    "    tversky = (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
    "    focal_tversky = K.pow((1 - tversky), gamma)\n",
    "    \n",
    "    return focal_tversky\n",
    "\n",
    "def masked_iou_score(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate IoU score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    union = K.sum(y_true_f * validity_f) + K.sum(y_pred_f * validity_f) - intersection\n",
    "    \n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def masked_binary_accuracy(y_true_and_validity, y_pred):\n",
    "    \"\"\"Calculate binary accuracy only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_pred_binary = K.cast(y_pred_masked > 0.5, K.floatx())\n",
    "    \n",
    "    correct = K.cast(K.equal(y_true_masked, y_pred_binary), K.floatx()) * validity_mask\n",
    "    total_valid = K.sum(validity_mask)\n",
    "    \n",
    "    return K.sum(correct) / (total_valid + K.epsilon())\n",
    "\n",
    "def masked_f1_score_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate F1 score only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + smooth)\n",
    "    return f1\n",
    "\n",
    "def masked_precision_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate precision only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    predicted_positives = K.sum(y_pred_f * validity_f)\n",
    "\n",
    "    precision = (true_positives + smooth) / (predicted_positives + smooth)\n",
    "    return precision\n",
    "\n",
    "def masked_recall_metric(y_true_and_validity, y_pred, smooth=1e-6):\n",
    "    \"\"\"Calculate recall only for valid pixels\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    \n",
    "    y_true_masked = y_true * validity_mask\n",
    "    y_pred_masked = y_pred * validity_mask\n",
    "    \n",
    "    y_true_f = K.flatten(y_true_masked)\n",
    "    y_pred_f = K.flatten(y_pred_masked)\n",
    "    validity_f = K.flatten(validity_mask)\n",
    "\n",
    "    true_positives = K.sum(y_true_f * y_pred_f * validity_f)\n",
    "    actual_positives = K.sum(y_true_f * validity_f)\n",
    "\n",
    "    recall = (true_positives + smooth) / (actual_positives + smooth)\n",
    "    return recall\n",
    "\n",
    "def masked_dice_coefficient_metric(y_true_and_validity, y_pred):\n",
    "    \"\"\"Wrapper for masked dice coefficient\"\"\"\n",
    "    y_true = y_true_and_validity[..., 0:1]\n",
    "    validity_mask = y_true_and_validity[..., 1:2]\n",
    "    return masked_dice_coefficient(y_true, y_pred, validity_mask)\n",
    "\n",
    "# ==================== INFERENCE CLASS ====================\n",
    "\n",
    "class UnifiedDatasetInference:\n",
    "    def __init__(self, model_path, data_path, output_path, samples_per_dataset=10):\n",
    "        \"\"\"\n",
    "        Initialize inference for unified dataset\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to trained model\n",
    "            data_path: Path to preprocessed unified dataset\n",
    "            output_path: Path to save inference results\n",
    "            samples_per_dataset: Number of samples to test per dataset type\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.samples_per_dataset = samples_per_dataset\n",
    "        \n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # Load model\n",
    "        self.model = self.load_model()\n",
    "        \n",
    "        # Load dataset info\n",
    "        self.dataset_info = self.load_dataset_info()\n",
    "        \n",
    "        # Select samples\n",
    "        self.selected_samples = self.select_samples()\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load trained model with custom objects\"\"\"\n",
    "        print(\"Loading trained model...\")\n",
    "        \n",
    "        custom_objects = {\n",
    "            'masked_dice_coefficient_metric': masked_dice_coefficient_metric,\n",
    "            'masked_focal_tversky_loss': masked_focal_tversky_loss,\n",
    "            'masked_iou_score': masked_iou_score,\n",
    "            'masked_binary_accuracy': masked_binary_accuracy,\n",
    "            'masked_f1_score_metric': masked_f1_score_metric,\n",
    "            'masked_precision_metric': masked_precision_metric,\n",
    "            'masked_recall_metric': masked_recall_metric\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            model = models.load_model(self.model_path, custom_objects=custom_objects)\n",
    "            print(\" Model loaded successfully\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load_dataset_info(self):\n",
    "        \"\"\"Load unified dataset split information\"\"\"\n",
    "        splits_info_path = os.path.join(self.data_path, 'unified_splits_info.json')\n",
    "        \n",
    "        if not os.path.exists(splits_info_path):\n",
    "            print(f\" Dataset info not found: {splits_info_path}\")\n",
    "            raise FileNotFoundError(\"Unified splits info not found\")\n",
    "        \n",
    "        with open(splits_info_path, 'r') as f:\n",
    "            info = json.load(f)\n",
    "        \n",
    "        print(\" Dataset info loaded successfully\")\n",
    "        print(f\"Total Otsu samples: {info['dataset_info']['total_otsu_samples']}\")\n",
    "        print(f\"Total Sen1Floods11 samples: {info['dataset_info']['total_sen1floods_samples']}\")\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def select_samples(self):\n",
    "        \"\"\"Select samples from each dataset type for inference\"\"\"\n",
    "        print(f\"\\nSelecting {self.samples_per_dataset} samples from each dataset...\")\n",
    "        \n",
    "        selected = {'otsu': [], 'sen1floods': []}\n",
    "        \n",
    "        # Check test split for samples from each dataset\n",
    "        test_samples = self.dataset_info['splits']['test']\n",
    "        \n",
    "        otsu_samples = [s for s in test_samples if s['dataset_type'] == 'otsu']\n",
    "        sen1floods_samples = [s for s in test_samples if s['dataset_type'] == 'sen1floods']\n",
    "        \n",
    "        print(f\"Available test samples - Otsu: {len(otsu_samples)}, Sen1Floods11: {len(sen1floods_samples)}\")\n",
    "        \n",
    "        # Randomly select samples\n",
    "        if len(otsu_samples) >= self.samples_per_dataset:\n",
    "            selected['otsu'] = random.sample(otsu_samples, self.samples_per_dataset)\n",
    "        else:\n",
    "            selected['otsu'] = otsu_samples\n",
    "            print(f\"  Only {len(otsu_samples)} Otsu samples available\")\n",
    "        \n",
    "        if len(sen1floods_samples) >= self.samples_per_dataset:\n",
    "            selected['sen1floods'] = random.sample(sen1floods_samples, self.samples_per_dataset)\n",
    "        else:\n",
    "            selected['sen1floods'] = sen1floods_samples\n",
    "            print(f\"  Only {len(sen1floods_samples)} Sen1Floods11 samples available\")\n",
    "        \n",
    "        print(f\"Selected samples - Otsu: {len(selected['otsu'])}, Sen1Floods11: {len(selected['sen1floods'])}\")\n",
    "        \n",
    "        return selected\n",
    "\n",
    "    def load_sample_data(self, split='test'):\n",
    "        \"\"\"Load actual image and mask data for selected samples\"\"\"\n",
    "        print(\"Loading sample data...\")\n",
    "        \n",
    "        sample_data = {'otsu': [], 'sen1floods': []}\n",
    "        \n",
    "        # Get all test files\n",
    "        img_files = sorted(glob.glob(os.path.join(self.data_path, split, 'images', '*.npy')))\n",
    "        mask_files = sorted(glob.glob(os.path.join(self.data_path, split, 'masks', '*.npy')))\n",
    "        validity_files = sorted(glob.glob(os.path.join(self.data_path, split, 'validity_masks', '*.npy')))\n",
    "        \n",
    "        if len(img_files) == 0:\n",
    "            raise ValueError(f\"No image files found in {self.data_path}/{split}/images/\")\n",
    "        \n",
    "        # Map sample indices to actual files\n",
    "        all_test_samples = self.dataset_info['splits']['test']\n",
    "        \n",
    "        for dataset_type in ['otsu', 'sen1floods']:\n",
    "            for sample_info in self.selected_samples[dataset_type]:\n",
    "                # Find the index of this sample in the test split\n",
    "                sample_idx = None\n",
    "                for idx, test_sample in enumerate(all_test_samples):\n",
    "                    if (test_sample['dataset_type'] == sample_info['dataset_type'] and \n",
    "                        test_sample['base_id'] == sample_info['base_id']):\n",
    "                        sample_idx = idx\n",
    "                        break\n",
    "                \n",
    "                if sample_idx is not None and sample_idx < len(img_files):\n",
    "                    # Load the actual data\n",
    "                    img_data = np.load(img_files[sample_idx])\n",
    "                    mask_data = np.load(mask_files[sample_idx])\n",
    "                    validity_data = np.load(validity_files[sample_idx])\n",
    "                    \n",
    "                    sample_data[dataset_type].append({\n",
    "                        'image': img_data,\n",
    "                        'mask': mask_data,\n",
    "                        'validity': validity_data,\n",
    "                        'info': sample_info,\n",
    "                        'file_idx': sample_idx\n",
    "                    })\n",
    "        \n",
    "        print(f\"Loaded data - Otsu: {len(sample_data['otsu'])}, Sen1Floods11: {len(sample_data['sen1floods'])}\")\n",
    "        \n",
    "        return sample_data\n",
    "\n",
    "    def run_inference(self, sample_data):\n",
    "        \"\"\"Run inference on selected samples\"\"\"\n",
    "        print(\"Running inference...\")\n",
    "        \n",
    "        results = {'otsu': [], 'sen1floods': []}\n",
    "        \n",
    "        for dataset_type in ['otsu', 'sen1floods']:\n",
    "            print(f\"Processing {dataset_type} samples...\")\n",
    "            \n",
    "            for sample in sample_data[dataset_type]:\n",
    "                # Prepare input\n",
    "                img = sample['image']\n",
    "                img_batch = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "                \n",
    "                # Run prediction\n",
    "                pred = self.model.predict(img_batch, verbose=0)[0].squeeze()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                gt_mask = sample['mask']\n",
    "                validity_mask = sample['validity']\n",
    "                \n",
    "                metrics = self.calculate_sample_metrics(gt_mask, pred, validity_mask)\n",
    "                \n",
    "                results[dataset_type].append({\n",
    "                    'image': img,\n",
    "                    'ground_truth': gt_mask,\n",
    "                    'validity_mask': validity_mask,\n",
    "                    'prediction': pred,\n",
    "                    'metrics': metrics,\n",
    "                    'info': sample['info'],\n",
    "                    'file_idx': sample['file_idx']\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def calculate_sample_metrics(self, gt_mask, pred, validity_mask, threshold=0.5):\n",
    "        \"\"\"Calculate metrics for a single sample\"\"\"\n",
    "        # Apply validity mask\n",
    "        valid_pixels = validity_mask > 0.5\n",
    "        invalid_pixels = ~valid_pixels\n",
    "        \n",
    "        if np.sum(valid_pixels) == 0:\n",
    "            return {\n",
    "                'dice': 0.0, 'iou': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0,\n",
    "                'accuracy': 0.0, 'valid_pixels': 0, 'invalid_pixels': int(np.sum(invalid_pixels)),\n",
    "                'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0\n",
    "            }\n",
    "        \n",
    "        # Extract valid pixels only\n",
    "        gt_valid = gt_mask[valid_pixels]\n",
    "        pred_valid = pred[valid_pixels]\n",
    "        \n",
    "        # Apply threshold\n",
    "        pred_binary = (pred_valid > threshold).astype(np.int32)\n",
    "        gt_binary = (gt_valid > threshold).astype(np.int32)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        try:\n",
    "            cm = confusion_matrix(gt_binary, pred_binary, labels=[0, 1])\n",
    "            if cm.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "            else:\n",
    "                tn = fp = fn = tp = 0\n",
    "        except:\n",
    "            tn = fp = fn = tp = 0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        intersection = tp\n",
    "        union = tp + fp + fn\n",
    "        \n",
    "        dice = (2 * intersection + 1e-8) / (2 * intersection + fp + fn + 1e-8)\n",
    "        iou = (intersection + 1e-8) / (union + 1e-8)\n",
    "        precision = (tp + 1e-8) / (tp + fp + 1e-8)\n",
    "        recall = (tp + 1e-8) / (tp + fn + 1e-8)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        accuracy = (tp + tn + 1e-8) / (tp + tn + fp + fn + 1e-8)\n",
    "        \n",
    "        return {\n",
    "            'dice': float(dice),\n",
    "            'iou': float(iou),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1': float(f1),\n",
    "            'accuracy': float(accuracy),\n",
    "            'valid_pixels': int(np.sum(valid_pixels)),\n",
    "            'invalid_pixels': int(np.sum(invalid_pixels)),\n",
    "            'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn)\n",
    "        }\n",
    "\n",
    "    def visualize_results(self, results):\n",
    "        \"\"\"Create comprehensive visualizations\"\"\"\n",
    "        print(\"Creating visualizations...\")\n",
    "        \n",
    "        # Calculate total samples for visualization\n",
    "        total_otsu = len(results['otsu'])\n",
    "        total_sen1floods = len(results['sen1floods'])\n",
    "        total_samples = total_otsu + total_sen1floods\n",
    "        \n",
    "        if total_samples == 0:\n",
    "            print(\"❌ No samples to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        fig_height = 6 * total_samples\n",
    "        fig, axes = plt.subplots(total_samples, 6, figsize=(30, fig_height))\n",
    "        \n",
    "        if total_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        row = 0\n",
    "        \n",
    "        # Plot Otsu samples\n",
    "        for i, sample in enumerate(results['otsu']):\n",
    "            self.plot_sample_row(axes, row, sample, 'Otsu', i)\n",
    "            row += 1\n",
    "        \n",
    "        # Plot Sen1Floods11 samples\n",
    "        for i, sample in enumerate(results['sen1floods']):\n",
    "            self.plot_sample_row(axes, row, sample, 'Sen1Floods11', i)\n",
    "            row += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_path, 'inference_results.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_sample_row(self, axes, row, sample, dataset_name, sample_idx):\n",
    "        \"\"\"Plot a single sample across 6 columns\"\"\"\n",
    "        img = sample['image']\n",
    "        gt = sample['ground_truth']\n",
    "        validity = sample['validity_mask']\n",
    "        pred = sample['prediction']\n",
    "        metrics = sample['metrics']\n",
    "        \n",
    "        # Normalize image for visualization\n",
    "        img_viz = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        \n",
    "        # Create RGB composite\n",
    "        rgb_viz = np.stack([\n",
    "            img_viz[:, :, 0],  # VV as R\n",
    "            img_viz[:, :, 1],  # NewBand1 as G  \n",
    "            img_viz[:, :, 2]   # NewBand2 as B\n",
    "        ], axis=-1)\n",
    "        rgb_viz = np.clip(rgb_viz, 0, 1)\n",
    "        \n",
    "        valid_pixels = validity > 0.5\n",
    "        invalid_pixels = ~valid_pixels\n",
    "        \n",
    "        # 1. SAR Composite\n",
    "        axes[row, 0].imshow(rgb_viz)\n",
    "        axes[row, 0].set_title(f'{dataset_name} Sample {sample_idx+1}\\nSAR Composite\\n(VV, NewBand1, NewBand2)')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # 2. Ground Truth with invalid areas\n",
    "        gt_display = np.ones_like(gt) * 0.5  # Gray for invalid\n",
    "        gt_display[valid_pixels] = gt[valid_pixels]\n",
    "        axes[row, 1].imshow(gt_display, cmap='Blues', vmin=0, vmax=1)\n",
    "        axes[row, 1].set_title(f'Ground Truth\\n(Gray = Invalid)\\nValid: {metrics[\"valid_pixels\"]:,} px')\n",
    "        axes[row, 1].axis('off')\n",
    "        \n",
    "        # 3. Validity Mask\n",
    "        axes[row, 2].imshow(validity, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "        invalid_pct = 100 * metrics['invalid_pixels'] / (metrics['valid_pixels'] + metrics['invalid_pixels'])\n",
    "        axes[row, 2].set_title(f'Validity Mask\\nInvalid: {invalid_pct:.1f}%\\nDataset: {dataset_name}')\n",
    "        axes[row, 2].axis('off')\n",
    "        \n",
    "        # 4. Model Prediction\n",
    "        axes[row, 3].imshow(pred, cmap='Blues', vmin=0, vmax=1)\n",
    "        axes[row, 3].set_title(f'Model Prediction\\n(All pixels)')\n",
    "        axes[row, 3].axis('off')\n",
    "        \n",
    "        # 5. Masked Prediction\n",
    "        pred_masked = pred.copy()\n",
    "        pred_masked[invalid_pixels] = 0.5  # Gray out invalid\n",
    "        axes[row, 4].imshow(pred_masked, cmap='Blues', vmin=0, vmax=1)\n",
    "        axes[row, 4].set_title(f'Masked Prediction\\n(Valid pixels only)')\n",
    "        axes[row, 4].axis('off')\n",
    "        \n",
    "        # 6. Metrics Display\n",
    "        axes[row, 5].text(0.1, 0.9, f'Dataset: {dataset_name}', fontsize=12, weight='bold', transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.8, f'IoU: {metrics[\"iou\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.7, f'Dice: {metrics[\"dice\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.6, f'F1: {metrics[\"f1\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.5, f'Precision: {metrics[\"precision\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.4, f'Recall: {metrics[\"recall\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.3, f'Accuracy: {metrics[\"accuracy\"]:.3f}', fontsize=11, transform=axes[row, 5].transAxes)\n",
    "        \n",
    "        # Confusion matrix info\n",
    "        axes[row, 5].text(0.1, 0.2, f'TP: {metrics[\"tp\"]}, FP: {metrics[\"fp\"]}', fontsize=10, transform=axes[row, 5].transAxes)\n",
    "        axes[row, 5].text(0.1, 0.1, f'TN: {metrics[\"tn\"]}, FN: {metrics[\"fn\"]}', fontsize=10, transform=axes[row, 5].transAxes)\n",
    "        \n",
    "        axes[row, 5].set_xlim(0, 1)\n",
    "        axes[row, 5].set_ylim(0, 1)\n",
    "        axes[row, 5].axis('off')\n",
    "\n",
    "    def calculate_dataset_statistics(self, results):\n",
    "        \"\"\"Calculate and display statistics for each dataset\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📊 DATASET-SPECIFIC INFERENCE RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        for dataset_type in ['otsu', 'sen1floods']:\n",
    "            if len(results[dataset_type]) == 0:\n",
    "                continue\n",
    "                \n",
    "            metrics_list = [sample['metrics'] for sample in results[dataset_type]]\n",
    "            \n",
    "            # Calculate averages\n",
    "            avg_metrics = {}\n",
    "            for metric in ['dice', 'iou', 'f1', 'precision', 'recall', 'accuracy']:\n",
    "                avg_metrics[metric] = np.mean([m[metric] for m in metrics_list])\n",
    "            \n",
    "            # Calculate totals\n",
    "            total_tp = sum(m['tp'] for m in metrics_list)\n",
    "            total_fp = sum(m['fp'] for m in metrics_list)\n",
    "            total_tn = sum(m['tn'] for m in metrics_list)\n",
    "            total_fn = sum(m['fn'] for m in metrics_list)\n",
    "            total_valid = sum(m['valid_pixels'] for m in metrics_list)\n",
    "            total_invalid = sum(m['invalid_pixels'] for m in metrics_list)\n",
    "            \n",
    "            # Overall metrics from combined confusion matrix\n",
    "            overall_precision = (total_tp + 1e-8) / (total_tp + total_fp + 1e-8)\n",
    "            overall_recall = (total_tp + 1e-8) / (total_tp + total_fn + 1e-8)\n",
    "            overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall + 1e-8)\n",
    "            overall_accuracy = (total_tp + total_tn + 1e-8) / (total_tp + total_tn + total_fp + total_fn + 1e-8)\n",
    "            overall_iou = (total_tp + 1e-8) / (total_tp + total_fp + total_fn + 1e-8)\n",
    "            \n",
    "            stats[dataset_type] = {\n",
    "                'sample_count': len(results[dataset_type]),\n",
    "                'average_metrics': avg_metrics,\n",
    "                'overall_metrics': {\n",
    "                    'precision': float(overall_precision),\n",
    "                    'recall': float(overall_recall), \n",
    "                    'f1': float(overall_f1),\n",
    "                    'accuracy': float(overall_accuracy),\n",
    "                    'iou': float(overall_iou)\n",
    "                },\n",
    "                'confusion_matrix': {\n",
    "                    'tp': total_tp, 'fp': total_fp, 'tn': total_tn, 'fn': total_fn\n",
    "                },\n",
    "                'pixel_stats': {\n",
    "                    'total_valid': total_valid,\n",
    "                    'total_invalid': total_invalid,\n",
    "                    'invalid_percentage': 100 * total_invalid / (total_valid + total_invalid)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            dataset_display = 'S1F11-Otsu' if dataset_type == 'otsu' else 'Sen1Floods11'\n",
    "            print(f\"\\n {dataset_display} Dataset Results ({len(results[dataset_type])} samples):\")\n",
    "            print(f\"{'─'*50}\")\n",
    "            print(f\"Average Per-Sample Metrics:\")\n",
    "            print(f\"  IoU: {avg_metrics['iou']:.4f}\")\n",
    "            print(f\"  Dice: {avg_metrics['dice']:.4f}\")\n",
    "            print(f\"  F1: {avg_metrics['f1']:.4f}\")\n",
    "            print(f\"  Precision: {avg_metrics['precision']:.4f}\")\n",
    "            print(f\"  Recall: {avg_metrics['recall']:.4f}\")\n",
    "            print(f\"  Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "            \n",
    "            print(f\"\\nOverall Metrics (Combined Confusion Matrix):\")\n",
    "            print(f\"  IoU: {overall_iou:.4f}\")\n",
    "            print(f\"  F1: {overall_f1:.4f}\")\n",
    "            print(f\"  Precision: {overall_precision:.4f}\")\n",
    "            print(f\"  Recall: {overall_recall:.4f}\")\n",
    "            print(f\"  Accuracy: {overall_accuracy:.4f}\")\n",
    "            \n",
    "            print(f\"\\nPixel Statistics:\")\n",
    "            print(f\"  Valid pixels: {total_valid:,}\")\n",
    "            print(f\"  Invalid pixels: {total_invalid:,} ({stats[dataset_type]['pixel_stats']['invalid_percentage']:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nConfusion Matrix:\")\n",
    "            print(f\"  TP: {total_tp:,}, FP: {total_fp:,}\")\n",
    "            print(f\"  TN: {total_tn:,}, FN: {total_fn:,}\")\n",
    "        \n",
    "        # Compare datasets\n",
    "        if 'otsu' in stats and 'sen1floods' in stats:\n",
    "            print(f\"\\n DATASET COMPARISON:\")\n",
    "            print(f\"{'─'*50}\")\n",
    "            \n",
    "            otsu_iou = stats['otsu']['overall_metrics']['iou']\n",
    "            sen1floods_iou = stats['sen1floods']['overall_metrics']['iou']\n",
    "            iou_diff = otsu_iou - sen1floods_iou\n",
    "            \n",
    "            print(f\"IoU Difference (Otsu - Sen1Floods11): {iou_diff:+.4f}\")\n",
    "            if abs(iou_diff) < 0.01:\n",
    "                print(\"→ Similar performance on both datasets\")\n",
    "            elif iou_diff > 0:\n",
    "                print(\"→ Better performance on Otsu dataset\")\n",
    "            else:\n",
    "                print(\"→ Better performance on Sen1Floods11 dataset\")\n",
    "            \n",
    "            otsu_invalid = stats['otsu']['pixel_stats']['invalid_percentage']\n",
    "            sen1floods_invalid = stats['sen1floods']['pixel_stats']['invalid_percentage']\n",
    "            print(f\"Invalid pixel % - Otsu: {otsu_invalid:.1f}%, Sen1Floods11: {sen1floods_invalid:.1f}%\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return stats\n",
    "\n",
    "    def save_results(self, results, stats):\n",
    "        \"\"\"Save detailed results to files\"\"\"\n",
    "        print(\"Saving results...\")\n",
    "        \n",
    "        # Save individual sample results\n",
    "        all_results = []\n",
    "        for dataset_type in ['otsu', 'sen1floods']:\n",
    "            for i, sample in enumerate(results[dataset_type]):\n",
    "                result_row = {\n",
    "                    'dataset': dataset_type,\n",
    "                    'sample_idx': i,\n",
    "                    'file_idx': sample['file_idx'],\n",
    "                    **sample['metrics']\n",
    "                }\n",
    "                all_results.append(result_row)\n",
    "        \n",
    "        # Save to CSV\n",
    "        df = pd.DataFrame(all_results)\n",
    "        df.to_csv(os.path.join(self.output_path, 'inference_results.csv'), index=False)\n",
    "        \n",
    "        # Save summary statistics\n",
    "        with open(os.path.join(self.output_path, 'inference_statistics.json'), 'w') as f:\n",
    "            json.dump(stats, f, indent=4)\n",
    "        \n",
    "        print(f\"✅ Results saved to {self.output_path}\")\n",
    "\n",
    "    def run_complete_inference(self):\n",
    "        \"\"\"Run the complete inference pipeline\"\"\"\n",
    "        print(\"\\n STARTING UNIFIED DATASET INFERENCE\")\n",
    "        \n",
    "        # Load sample data\n",
    "        sample_data = self.load_sample_data()\n",
    "        \n",
    "        # Run inference\n",
    "        results = self.run_inference(sample_data)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = self.calculate_dataset_statistics(results)\n",
    "        \n",
    "        # Create visualizations\n",
    "        self.visualize_results(results)\n",
    "        \n",
    "        # Save results\n",
    "        self.save_results(results, stats)\n",
    "        \n",
    "        print(\"\\n✅ INFERENCE COMPLETE!\")\n",
    "        return results, stats\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration - UPDATE THESE PATHS\n",
    "    MODEL_PATH = \"/kaggle/working/united_SEN1FLOODS11/best_model_masked_cosine_annealing.keras\"  # Update this\n",
    "    DATA_PATH = \"/kaggle/working/unified_preprocessed\"  # Update this\n",
    "    OUTPUT_PATH = \"/kaggle/working/inference_results\"\n",
    "    SAMPLES_PER_DATASET = 10\n",
    "    \n",
    "    print(\" UNIFIED DATASET INFERENCE SETUP\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Model path: {MODEL_PATH}\")\n",
    "    print(f\"Data path: {DATA_PATH}\")\n",
    "    print(f\"Output path: {OUTPUT_PATH}\")\n",
    "    print(f\"Samples per dataset: {SAMPLES_PER_DATASET}\")\n",
    "    \n",
    "    # Check if paths exist\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\" Model not found: {MODEL_PATH}\")\n",
    "        print(\"Please update MODEL_PATH to your trained model\")\n",
    "        exit(1)\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\" Data not found: {DATA_PATH}\")\n",
    "        print(\"Please update DATA_PATH to your preprocessed data\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Initialize and run inference\n",
    "    inference = UnifiedDatasetInference(\n",
    "        model_path=MODEL_PATH,\n",
    "        data_path=DATA_PATH,\n",
    "        output_path=OUTPUT_PATH,\n",
    "        samples_per_dataset=SAMPLES_PER_DATASET\n",
    "    )\n",
    "    \n",
    "    # Run complete inference\n",
    "    results, stats = inference.run_complete_inference()\n",
    "    \n",
    "    print(f\"\\n All outputs saved to: {OUTPUT_PATH}\")\n",
    "    print(\" Files created:\")\n",
    "    print(\"  - inference_results.png (visualizations)\")\n",
    "    print(\"  - inference_results.csv (detailed metrics)\")\n",
    "    print(\"  - inference_statistics.json (summary stats)\")\n",
    "\n",
    "    # fixed msg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
